{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base models Qwen3-06B and Gemini API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a **baseline evaluation** to assess the performance of pre-trained models (`Qwen3-065B` and `gemini-2.0-flash-exp` API) on the real estate price prediction task. \n",
    "\n",
    "The notebook performs the following steps:\n",
    "\n",
    "1. Load dataset from remote (Kaggle/Hugging Face).\n",
    "2. Preprocess dataset.\n",
    "3. Evaluate **pre-trained base** `Qwen\\Qwen3-0.6B` model using regression metrics.\n",
    "4. Evaluate Gemini **API** using regression metrics.\n",
    "5. Evaluate the performance of the **fine-tuned** `Qwen-Lora-Estate` model using regression metrics\n",
    "6. Save and compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZU5_1OLopMUy"
   },
   "source": [
    "---\n",
    "## Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4v0D3WgVvB8"
   },
   "source": [
    "### **Install Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-12T18:17:41.489137Z",
     "iopub.status.busy": "2025-05-12T18:17:41.488517Z",
     "iopub.status.idle": "2025-05-12T18:17:45.359136Z",
     "shell.execute_reply": "2025-05-12T18:17:45.358126Z",
     "shell.execute_reply.started": "2025-05-12T18:17:41.489110Z"
    },
    "id": "Yj6qTXvPpwyk",
    "outputId": "9bd2220a-0e37-4a3f-b594-7b1bdf031cae",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -qU transformers wandb google-generativeai huggingface_hub[hf_xet]\n",
    "!pip install -qU  json_repair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_l-cfEqOVzuF"
   },
   "source": [
    "### **Import Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:33.424779Z",
     "iopub.status.busy": "2025-05-12T18:19:33.424026Z",
     "iopub.status.idle": "2025-05-12T18:19:33.428727Z",
     "shell.execute_reply": "2025-05-12T18:19:33.427980Z",
     "shell.execute_reply.started": "2025-05-12T18:19:33.424755Z"
    },
    "id": "mAre3Yb9TEj9",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import json_repair\n",
    "import pandas as pd\n",
    "from IPython.display import JSON\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import google.generativeai as genai\n",
    "\n",
    "# my custom modules\n",
    "from utils import logging_config, evaluate_model, timeit\n",
    "from fine_tuning_helpers import apply_prompt_template, decode_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:20:01.079793Z",
     "iopub.status.busy": "2025-05-12T18:20:01.079231Z",
     "iopub.status.idle": "2025-05-12T18:20:01.087973Z",
     "shell.execute_reply": "2025-05-12T18:20:01.087461Z",
     "shell.execute_reply.started": "2025-05-12T18:20:01.079771Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_Logger utils (INFO)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['LOGS'] = '/kaggle/working/logs'\n",
    "os.environ['RESULTS'] = '/kaggle/working/results'\n",
    "\n",
    "os.makedirs(os.environ['LOGS'], exist_ok=True )\n",
    "os.makedirs(os.environ['RESULTS'], exist_ok=True )\n",
    "\n",
    "LOGGER = logging_config(log_dir=os.environ['LOGS'])\n",
    "LOGGER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Define Tokens and Authenticate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:20:04.293252Z",
     "iopub.status.busy": "2025-05-12T18:20:04.292964Z",
     "iopub.status.idle": "2025-05-12T18:20:04.620022Z",
     "shell.execute_reply": "2025-05-12T18:20:04.619307Z",
     "shell.execute_reply.started": "2025-05-12T18:20:04.293231Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# If using kaggle \n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "hf_token = user_secrets.get_secret(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "gemini_token = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# uncomment if using colab\n",
    "# from google.colab import userdata\n",
    "# hf_token = userdata.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "# gemini_token = userdata.get(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:36.651964Z",
     "iopub.status.busy": "2025-05-12T18:19:36.651730Z",
     "iopub.status.idle": "2025-05-12T18:19:36.743022Z",
     "shell.execute_reply": "2025-05-12T18:19:36.742366Z",
     "shell.execute_reply.started": "2025-05-12T18:19:36.651946Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import whoami, login\n",
    "\n",
    "# !huggingface-cli login --token {mytoken} # another method\n",
    "login(token = hf_token)\n",
    "genai.configure(api_key=gemini_token)\n",
    "# JSON(whoami())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "ca360e1b101d4395af434fc52908477b",
      "da45d9a4491f4bb49a94d3a6f390e904",
      "6edbbdb4f52b4a4d84c5ae9c986ce926",
      "ff752a123aec447cbc4ee24fd02fa347",
      "9ec64b1bfc0647bb96bf803c2068d7b5",
      "535e2f372f74492dbdfccf95fa2ccc51",
      "949aca8fdc584623b1e7d456d4f33bd9",
      "504a7821b59d4524b299cd127e34865c",
      "1c3f73d6e7d64e568520935df91bc862",
      "b198176b8666463bb22fc74613ca81c7",
      "85a6a112fef043869b3f3f26a9afde08",
      "290db3966a504b47bf6e23814a0b59c7",
      "7bca60effe184c59a2f2f9722f402d49",
      "0fc862d1f32d4222a9eab0d3d3363952",
      "9593f1f003a64cf9a96900362576b76a",
      "bca663d78c5b48c3a8a5cbab44403501",
      "e56dc41c9e1a4922849bb6f3ac85385d",
      "4f924d63bc0243798fcc0dcf91f640ae",
      "74c6f83c2e6f41c9aeb0ba8cfd0c1e3d",
      "5ca49aef822a4aa8acd9a7d8efa73235",
      "0b16163efaa3467aac8c6c3a381acc04",
      "33466bd6149a4381b88c4fd4f96d441f",
      "88bd985ff0b241d29edf9d93f83fb6ce"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:36.744341Z",
     "iopub.status.busy": "2025-05-12T18:19:36.744132Z",
     "iopub.status.idle": "2025-05-12T18:19:36.747309Z",
     "shell.execute_reply": "2025-05-12T18:19:36.746605Z",
     "shell.execute_reply.started": "2025-05-12T18:19:36.744326Z"
    },
    "id": "-PA52fS9nN3f",
    "outputId": "53053baf-1b08-4315-b578-df27ae312e89",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# uncomment if using colab\n",
    "# import kagglehub\n",
    "# kagglehub.login(validate_credentials=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-B1psKPpKQ9"
   },
   "source": [
    "---\n",
    "## Load Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from remote (Kaggle/Hugging Face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ix7pknmVppL"
   },
   "source": [
    "**Download the dataset from Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0L9nwgUziDkG",
    "outputId": "8654634a-1dd1-4b11-9f73-ba03b9f14ec0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Uncomment if using colab\n",
    "\n",
    "# kagglehub.dataset_download('hebamo7amed/real-estate-data-for-llm-fine-tuning')\n",
    "# tabular_data_path = f\"{data_path}/tabular_data\"\n",
    "# text_data_path = f\"{data_path}/text_data\"\n",
    "# text_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPq5gXZvZ-5x"
   },
   "source": [
    "**Read Text Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e38k8TCHUkf6",
    "outputId": "38acf928-6ee3-465b-ff27-2d48fc413361",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# with open(f\"{text_data_path}/text_train_data.jsonl\", \"r\") as f:\n",
    "#   train_data = json.load(f)\n",
    "\n",
    "# with open(f\"{text_data_path}/text_val_data.jsonl\", \"r\") as f:\n",
    "#   val_data = json.load(f)\n",
    "\n",
    "# with open(f\"{text_data_path}/sample_50.jsonl\", \"r\") as f:\n",
    "#   sample_data = json.load(f)\n",
    "\n",
    "# print(\"Training data size = \", len(train_data))\n",
    "# print(\"Validation data size = \", len(val_data))\n",
    "# print(\"Sample data size = \", len(sample_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Dataset Sample from hugging Face Hub**\n",
    "\n",
    "A data sample that was created from structured real estate data and uploaded to Hugging Face in the first notebook. It is formatted for ion-based fine-tuning an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T16:47:22.039929Z",
     "iopub.status.busy": "2025-05-12T16:47:22.039279Z",
     "iopub.status.idle": "2025-05-12T16:47:23.634507Z",
     "shell.execute_reply": "2025-05-12T16:47:23.633670Z",
     "shell.execute_reply.started": "2025-05-12T16:47:22.039900Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319bf0f2d43b498d9dc6719415c6e3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fca17afc18d4bcdad1a614461f41dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_train_data.jsonl:   0%|          | 0.00/5.54M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492a417347714fd4b22ce78257b1f33a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_val_data.jsonl:   0%|          | 0.00/222k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb39065e6e84906aed0e74e555d0db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6daf6f370c34871b6e5127dd48b1f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'instruction', 'input', 'output', 'history'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['system', 'instruction', 'input', 'output', 'history'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\n",
    "    path  ='heba1998/real-estate-data-sample-for-llm-fine-tuning'\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert data to list of jsons or ``jsonl``\n",
    "val_data = [sample for sample in dataset['validation']]\n",
    "house_price = lambda sample : json_repair.loads(sample['output'])['estimated_house_price']\n",
    "true_labels = [ house_price(sample) for sample in dataset['validation']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQQ4gDLjLJ8V"
   },
   "source": [
    "---\n",
    "## Evaluate Responses of `gemini-2.0-flash` Model\n",
    "---\n",
    "\n",
    "Evaluate the responses from Gemini API using regression metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Helper Function to get responses from `genai` SDK API**\n",
    "\n",
    "This function uses another function from the `fine_tuning_helpers.py` and `utils` utility scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T16:47:30.450109Z",
     "iopub.status.busy": "2025-05-12T16:47:30.449516Z",
     "iopub.status.idle": "2025-05-12T16:47:30.456817Z",
     "shell.execute_reply": "2025-05-12T16:47:30.455972Z",
     "shell.execute_reply.started": "2025-05-12T16:47:30.450088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from fine_tuning_helpers import extract_house_price\n",
    "\n",
    "@timeit\n",
    "def batch_api_generate(model, data):\n",
    "    llm_predictions = []\n",
    "    tokens_history = []\n",
    "    bar_format = '{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'\n",
    "    \n",
    "    for idx, sample in enumerate(tqdm(data, total=len(data),\n",
    "                                 desc=\"Get response from pre-trained `Qwen3-0.6B` model\",\n",
    "                                 ncols=100, colour='green')):\n",
    "        LOGGER.info(\"-\"*50)\n",
    "        LOGGER.info(f\"Sample id {idx}\")\n",
    "        LOGGER.info(\"-\"*50)\n",
    "        # 1. PREPROCESSING: \n",
    "        # build the system and user prompt with the model chat template\n",
    "        prompt= apply_prompt_template(sample)\n",
    "\n",
    "        # 2. GENERATION: Generate response\n",
    "        response = model.generate_content(prompt)\n",
    "        text_response = response.candidates[0].content.parts[0].text\n",
    "\n",
    "        # 4. POSTPROCESSING:  return only the output tokens and  exclude input ids\n",
    "        LOGGER.info(f\"Response text for sample id={idx} \\n {text_response}\" )\n",
    "        \n",
    "        # Clean response\n",
    "        house_price = extract_house_price(text_response)\n",
    "        LOGGER.info(f\"\\t>> Predicted price: {house_price}\")\n",
    "        llm_predictions.append(int(house_price))\n",
    "        \n",
    "        # Store metadata for expenses calculation\n",
    "        tokens_history.append({\n",
    "                'id': idx,\n",
    "                'input_tokens': response.usage_metadata.prompt_token_count, \n",
    "                'output_tokens': response.usage_metadata.candidates_token_count,\n",
    "                'total_tokens': response.usage_metadata.total_token_count\n",
    "            })\n",
    "            \n",
    "        LOGGER.debug(f\"Updated tokens history for {idx}\")\n",
    "\n",
    "    return llm_predictions, tokens_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-09T12:23:06.908612Z",
     "iopub.status.busy": "2025-05-09T12:23:06.908242Z",
     "iopub.status.idle": "2025-05-09T12:23:07.186377Z",
     "shell.execute_reply": "2025-05-09T12:23:07.185489Z",
     "shell.execute_reply.started": "2025-05-09T12:23:06.908588Z"
    },
    "id": "iBkMuyuKB7Jg",
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/chat-bison-001',\n",
       " 'models/text-bison-001',\n",
       " 'models/embedding-gecko-001',\n",
       " 'models/gemini-1.0-pro-vision-latest',\n",
       " 'models/gemini-pro-vision',\n",
       " 'models/gemini-1.5-pro-latest',\n",
       " 'models/gemini-1.5-pro-001',\n",
       " 'models/gemini-1.5-pro-002',\n",
       " 'models/gemini-1.5-pro',\n",
       " 'models/gemini-1.5-flash-latest',\n",
       " 'models/gemini-1.5-flash-001',\n",
       " 'models/gemini-1.5-flash-001-tuning',\n",
       " 'models/gemini-1.5-flash',\n",
       " 'models/gemini-1.5-flash-002',\n",
       " 'models/gemini-1.5-flash-8b',\n",
       " 'models/gemini-1.5-flash-8b-001',\n",
       " 'models/gemini-1.5-flash-8b-latest',\n",
       " 'models/gemini-1.5-flash-8b-exp-0827',\n",
       " 'models/gemini-1.5-flash-8b-exp-0924',\n",
       " 'models/gemini-2.5-pro-exp-03-25',\n",
       " 'models/gemini-2.5-pro-preview-03-25',\n",
       " 'models/gemini-2.5-flash-preview-04-17',\n",
       " 'models/gemini-2.5-flash-preview-04-17-thinking',\n",
       " 'models/gemini-2.5-pro-preview-05-06',\n",
       " 'models/gemini-2.0-flash-exp',\n",
       " 'models/gemini-2.0-flash',\n",
       " 'models/gemini-2.0-flash-001',\n",
       " 'models/gemini-2.0-flash-lite-001',\n",
       " 'models/gemini-2.0-flash-lite',\n",
       " 'models/gemini-2.0-flash-lite-preview-02-05',\n",
       " 'models/gemini-2.0-flash-lite-preview',\n",
       " 'models/gemini-2.0-pro-exp',\n",
       " 'models/gemini-2.0-pro-exp-02-05',\n",
       " 'models/gemini-exp-1206',\n",
       " 'models/gemini-2.0-flash-thinking-exp-01-21',\n",
       " 'models/gemini-2.0-flash-thinking-exp',\n",
       " 'models/gemini-2.0-flash-thinking-exp-1219',\n",
       " 'models/learnlm-1.5-pro-experimental',\n",
       " 'models/learnlm-2.0-flash-experimental',\n",
       " 'models/gemma-3-1b-it',\n",
       " 'models/gemma-3-4b-it',\n",
       " 'models/gemma-3-12b-it',\n",
       " 'models/gemma-3-27b-it',\n",
       " 'models/embedding-001',\n",
       " 'models/text-embedding-004',\n",
       " 'models/gemini-embedding-exp-03-07',\n",
       " 'models/gemini-embedding-exp',\n",
       " 'models/aqa',\n",
       " 'models/imagen-3.0-generate-002',\n",
       " 'models/gemini-2.0-flash-live-001']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.name for model in genai.list_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Response using Gemini.**\n",
    "\n",
    "Generate responses from `gemini-2.0-flash-exp` in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:01:55.600585Z",
     "iopub.status.busy": "2025-05-09T14:01:55.600246Z",
     "iopub.status.idle": "2025-05-09T14:04:22.839202Z",
     "shell.execute_reply": "2025-05-09T14:04:22.838157Z",
     "shell.execute_reply.started": "2025-05-09T14:01:55.600511Z"
    },
    "id": "oyp-D90YCdIN",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get response from pre-trained `Qwen3-0.6B` model: 100%|\u001b[32m███████████\u001b[0m| 200/200 [02:27<00:00,  1.36it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data completed in 2.45 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "\n",
    "Configs = genai.GenerationConfig(max_output_tokens=200)\n",
    "\n",
    "model_id = \"models/gemini-2.0-flash-exp\"\n",
    "gemini = genai.GenerativeModel(model_name=model_id,\n",
    "                               generation_config=Configs)\n",
    "\n",
    "gemini_preds, gemini_tokens_history = batch_api_generate(gemini, data = val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3OCT8N8JWBX"
   },
   "source": [
    "### **Evaluation Metrics for `gemini-2.0-flash-exp` Model**\n",
    "\n",
    "This function is implemented in the `utils.py` utility script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:04:22.841117Z",
     "iopub.status.busy": "2025-05-09T14:04:22.840787Z",
     "iopub.status.idle": "2025-05-09T14:04:22.846651Z",
     "shell.execute_reply": "2025-05-09T14:04:22.845687Z",
     "shell.execute_reply.started": "2025-05-09T14:04:22.841094Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Price [2500000.0, 295000.0, 299900.0, 699000.0, 239000.0, 11000.0, 470000.0, 449000.0, 250000.0, 339000.0]\n",
      "Predicted Prices [-1, -1, 345000, -1, -1, -1, -1, -1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Price\", true_labels[:10])\n",
    "print(\"Predicted Prices\", gemini_preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **`-1`** indecate to that gemini didn't produce the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Metrics and Predictions for `gemini-2.0-flash-exp` Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:04:22.848139Z",
     "iopub.status.busy": "2025-05-09T14:04:22.847755Z",
     "iopub.status.idle": "2025-05-09T14:04:22.873172Z",
     "shell.execute_reply": "2025-05-09T14:04:22.872322Z",
     "shell.execute_reply.started": "2025-05-09T14:04:22.848118Z"
    },
    "id": "v0DpDsevIw4p",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gemini_metrics = evaluate_model(true_labels, gemini_preds)\n",
    "\n",
    "gemini_metrics[\"n_samples\"] = len(val_data)\n",
    "gemini_metrics[\"eval_time (min)\"] = 2.45\n",
    "gemini_metrics[\"response_time (min)\"] = 2.45 / len(val_data)\n",
    "gemini_metrics[\"eval_device\"] = \"remote-api\"\n",
    "gemini_metrics[\"model_name\"] = model_id.split('/')[-1]\n",
    "\n",
    "JSON(gemini_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:04:56.673411Z",
     "iopub.status.busy": "2025-05-09T14:04:56.673126Z",
     "iopub.status.idle": "2025-05-09T14:04:56.687456Z",
     "shell.execute_reply": "2025-05-09T14:04:56.686522Z",
     "shell.execute_reply.started": "2025-05-09T14:04:56.673392Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>> Gemini can't predict 72.0% from the given data <<<<<<\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>y_actual</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>78</td>\n",
       "      <td>335</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>77</td>\n",
       "      <td>335</td>\n",
       "      <td>295000.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>104</td>\n",
       "      <td>360</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>78</td>\n",
       "      <td>336</td>\n",
       "      <td>699000.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>78</td>\n",
       "      <td>336</td>\n",
       "      <td>239000.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  input_tokens  output_tokens  total_tokens   y_actual  y_pred\n",
       "0   0           257             78           335  2500000.0      -1\n",
       "1   1           258             77           335   295000.0      -1\n",
       "2   2           256            104           360   299900.0  345000\n",
       "3   3           258             78           336   699000.0      -1\n",
       "4   4           258             78           336   239000.0      -1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_results = pd.DataFrame(gemini_tokens_history)\n",
    "gemini_results['y_actual'] = true_labels\n",
    "gemini_results['y_pred'] = gemini_preds\n",
    "\n",
    "missed_prec = len(gemini_results[gemini_results['y_pred']==-1]) *100 /len(val_data)\n",
    "gemini_metrics[\"missing_pred(%)\"] = missed_prec\n",
    "\n",
    "print(f\">>>>>> Gemini can't predict {missed_prec}% from the given data <<<<<<\")\n",
    "gemini_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save `gemini-2.0-flash-exp` Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:22:42.608285Z",
     "iopub.status.busy": "2025-05-09T14:22:42.607877Z",
     "iopub.status.idle": "2025-05-09T14:22:42.616302Z",
     "shell.execute_reply": "2025-05-09T14:22:42.615312Z",
     "shell.execute_reply.started": "2025-05-09T14:22:42.608259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(f\"{os.environ['RESULTS']}/gemini_metrics.json\", 'w') as json_file:\n",
    "    json.dump(gemini_metrics, json_file, indent=4)\n",
    "\n",
    "gemini_results.to_csv(f\"{os.environ['RESULTS']}/gemini_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XEQiv5qe6yp"
   },
   "source": [
    "---\n",
    "## Evaluate Responses from Pre-Trained Base LM `Qwen3-0.6B`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Helper Function to get responses for base model**\n",
    "\n",
    "This function uses another function from the `fine_tuning_helpers.py` and `utils` utility scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T17:00:00.779392Z",
     "iopub.status.busy": "2025-05-12T17:00:00.778845Z",
     "iopub.status.idle": "2025-05-12T17:00:00.786630Z",
     "shell.execute_reply": "2025-05-12T17:00:00.785717Z",
     "shell.execute_reply.started": "2025-05-12T17:00:00.779369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@timeit\n",
    "def batch_generate(model, tokenizer, data, device):\n",
    "    predictions = []\n",
    "    tokens_history = []\n",
    "    bar_format = '{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'\n",
    "    \n",
    "    for idx, sample in enumerate(tqdm(data, total=len(data),\n",
    "                                 desc=\"Get response from pre-trained `Qwen3-0.6B` model\",\n",
    "                                 ncols=100, colour='green')):\n",
    "        # 1. PREPROCESSING: \n",
    "        # build the system and user prompt with the model chat template\n",
    "        prompt = apply_prompt_template(sample)\n",
    "\n",
    "        # 2. TOKENIZATION: Tokenize the text prompt message\n",
    "        inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "        n_input_tokens = len(inputs.input_ids[0])\n",
    "        LOGGER.info(f\"\\t>> Tokenized to {n_input_tokens} tokens\")\n",
    "        \n",
    "        # 3. GENERATION: Generate response\n",
    "        response_tokens_ids = model.generate(\n",
    "            inputs=inputs.input_ids,\n",
    "            attention_mask=inputs.attention_mask,\n",
    "        )\n",
    "        n_output_tokens = len(response_tokens_ids[0])\n",
    "\n",
    "        # 4. POSTPROCESSING: Return only the output tokens and  exclude input ids and then clean response\n",
    "        response_text = decode_response(response_tokens_ids, inputs.input_ids, tokenizer)\n",
    "        response_dict = json_repair.loads(response_text)            \n",
    "        try:\n",
    "            house_price = response_dict[\"estimated_house_price\"]\n",
    "        except:\n",
    "            try:\n",
    "                house_price = response_dict[0][\"estimated_house_price\"]\n",
    "            except: \n",
    "                print(response_dict)\n",
    "                house_price = -1\n",
    "        predictions.append(int(house_price))\n",
    "        \n",
    "        # Store BAse model metadata for cost calculation\n",
    "        tokens_history.append({\n",
    "                'id': idx,\n",
    "                'input_tokens': n_input_tokens, \n",
    "                'output_tokens': n_output_tokens,\n",
    "                'total_tokens': n_input_tokens + n_output_tokens\n",
    "            })\n",
    "            \n",
    "    return predictions, tokens_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load `Qwen3-0.6B` from Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T16:47:41.800755Z",
     "iopub.status.busy": "2025-05-12T16:47:41.800407Z",
     "iopub.status.idle": "2025-05-12T16:48:12.703557Z",
     "shell.execute_reply": "2025-05-12T16:48:12.702886Z",
     "shell.execute_reply.started": "2025-05-12T16:47:41.800732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen3-0.6B\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer_qwen = AutoTokenizer.from_pretrained(model_id)\n",
    "model_qwen = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=None).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Response using Pre-trained `Qwen3-0.6B`**\n",
    "\n",
    "Generate responses from the base model `Qwen3-0.6B` in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T11:41:56.546687Z",
     "iopub.status.busy": "2025-05-09T11:41:56.545952Z",
     "iopub.status.idle": "2025-05-09T12:01:54.393988Z",
     "shell.execute_reply": "2025-05-09T12:01:54.392517Z",
     "shell.execute_reply.started": "2025-05-09T11:41:56.546655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Make batch prediction or text to number genration \n",
    "base_qwen_preds, base_qwen_tokens_history = batch_generate(model=model_qwen, \n",
    "                                                  tokenizer=tokenizer_qwen, \n",
    "                                                  data = val_data,\n",
    "                                                  device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Prediction for 200 sample takes 2.82 minutes using pretrained `Qwen3-0.6B`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3OCT8N8JWBX"
   },
   "source": [
    "### **Evaluation metrics for Pre-trained `Qwen3-0.6B`**\n",
    "\n",
    "This function is implemented in the `utils.py` utility script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:40:19.129871Z",
     "iopub.status.busy": "2025-05-09T13:40:19.129366Z",
     "iopub.status.idle": "2025-05-09T13:40:19.154883Z",
     "shell.execute_reply": "2025-05-09T13:40:19.153690Z",
     "shell.execute_reply.started": "2025-05-09T13:40:19.129838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Price [2500000.0, 295000.0, 299900.0, 699000.0, 239000.0, 11000.0, 470000.0, 449000.0, 250000.0, 339000.0]\n",
      "Predicted Prices [55000, 128000, 85000, 85000, 85000, 85000, 85000, 85000, 85000, 85000]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Price\", true_labels[:10])\n",
    "print(\"Predicted Prices\", base_qwen_preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Metrics Results for Pre-trained `Qwen3-0.6B`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:50:38.872351Z",
     "iopub.status.busy": "2025-05-09T13:50:38.872037Z",
     "iopub.status.idle": "2025-05-09T13:50:38.879434Z",
     "shell.execute_reply": "2025-05-09T13:50:38.878626Z",
     "shell.execute_reply.started": "2025-05-09T13:50:38.872328Z"
    },
    "id": "v0DpDsevIw4p",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_qwen_metrics = evaluate_model(true_labels, base_qwen_preds)\n",
    "\n",
    "base_qwen_metrics[\"n_samples\"] = len(val_data)\n",
    "base_qwen_metrics[\"eval_time (min)\"] = 2.82\n",
    "base_qwen_metrics[\"response_time (min)\"] = 2.82 / len(val_data)\n",
    "base_qwen_metrics[\"eval_device\"] = \"gpu-t4x2\"\n",
    "base_qwen_metrics[\"model_name\"] = model_id.split('/')[-1]\n",
    "\n",
    "JSON(base_qwen_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKJ7qhbwir3n"
   },
   "source": [
    "> Model produce bad result and don't follow the output schema\n",
    "\n",
    "> Model predict the same value each time `85000` or `8500` because it is bais towards the example of the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:57:33.961209Z",
     "iopub.status.busy": "2025-05-09T13:57:33.960565Z",
     "iopub.status.idle": "2025-05-09T13:57:33.993443Z",
     "shell.execute_reply": "2025-05-09T13:57:33.992657Z",
     "shell.execute_reply.started": "2025-05-09T13:57:33.961180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_qwen_results = pd.DataFrame(base_qwen_tokens_history )\n",
    "base_qwen_results['y_actual'] = true_labels\n",
    "base_qwen_results['y_pred'] = base_qwen_preds\n",
    "\n",
    "missed_prec = len(base_qwen_results[base_qwen_results['y_pred']==-1]) * 100 /len(val_data)\n",
    "base_qwen_metrics[\"missing_pred(%)\"] = missed_prec\n",
    "\n",
    "print(f\">>>>>> Base Qwen can't predict {missed_prec}% from the given data <<<<<<\")\n",
    "base_qwen_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Pre-trained`Qwen3-0.6B` Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:57:36.395729Z",
     "iopub.status.busy": "2025-05-09T13:57:36.395418Z",
     "iopub.status.idle": "2025-05-09T13:57:36.408689Z",
     "shell.execute_reply": "2025-05-09T13:57:36.407735Z",
     "shell.execute_reply.started": "2025-05-09T13:57:36.395684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(f\"{os.environ['RESULTS']}/pretrained_qwen_metrics.json\", 'w') as json_file:\n",
    "    json.dump(base_qwen_metrics, json_file, indent=4)\n",
    "\n",
    "base_qwen_results.to_csv(f\"{os.environ['RESULTS']}/pretrained_qwen_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluate Responses from Fine-Tuned `Qwen3-0.6B`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Helper Function to get responses for base model**\n",
    "\n",
    "This function uses another function from the `fine_tuning_helpers.py` and `utils` utility scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load our Adaptor `Qwen-LoRA-Estate` from Hugging Face**\n",
    "Load the fine-tuned model from Hugging Face. The model is trained on the same dataset and schema as the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T16:49:08.627006Z",
     "iopub.status.busy": "2025-05-12T16:49:08.626278Z",
     "iopub.status.idle": "2025-05-12T16:49:11.253693Z",
     "shell.execute_reply": "2025-05-12T16:49:11.252919Z",
     "shell.execute_reply.started": "2025-05-12T16:49:08.626980Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "adaptor_id = \"heba1998/Qwen-LoRA-Estate\"\n",
    "\n",
    "# Load the LoRA adapter\n",
    "peft_model =  PeftModel.from_pretrained(model_qwen, adaptor_id)\n",
    "\n",
    "# Attach the LoRA adapter to the model\n",
    "qwen_lora_estate = peft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Response using Fine-Tuned `Qwen3-0.6B`.**\n",
    "\n",
    "Generate responses from the Fine-Tuned `Qwen3-0.6B` in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T16:49:45.011281Z",
     "iopub.status.busy": "2025-05-12T16:49:45.010964Z",
     "iopub.status.idle": "2025-05-12T16:52:45.708609Z",
     "shell.execute_reply": "2025-05-12T16:52:45.707829Z",
     "shell.execute_reply.started": "2025-05-12T16:49:45.011259Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get response from pre-trained `Qwen3-0.6B` model: 100%|\u001b[32m███████████\u001b[0m| 200/200 [03:00<00:00,  1.11it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data completed in 3.01 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Make batch prediction or text to number genration\n",
    "qwen_lora_estate_preds, Qwen_lora_estate_tokens_history = batch_generate(model=qwen_lora_estate,\n",
    "                                                            tokenizer=tokenizer_qwen,\n",
    "                                                            data=val_data,\n",
    "                                                            device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Prediction for 200 sample takes 3.01 minutes using our fine-tined lora qwen model `Qwen-lora-estate`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation metrics for Fine-Tuned `Qwen3-0.6B`**\n",
    "\n",
    "This function is implemented in the `utils.py` utility script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T16:53:40.942239Z",
     "iopub.status.busy": "2025-05-12T16:53:40.941575Z",
     "iopub.status.idle": "2025-05-12T16:53:40.947401Z",
     "shell.execute_reply": "2025-05-12T16:53:40.946680Z",
     "shell.execute_reply.started": "2025-05-12T16:53:40.942213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Price [2500000.0, 295000.0, 299900.0, 699000.0, 239000.0, 11000.0, 470000.0, 449000.0, 250000.0, 339000.0]\n",
      "Predicted Prices [1100000, 269000, 315000, 725000, 125000, 140000, 411000, 499900, 319000, 449900]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Price\", true_labels[:10])\n",
    "print(\"Predicted Prices\", qwen_lora_estate_preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Metrics and Predictions for our `Qwen-lora-estate` Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T16:54:22.443057Z",
     "iopub.status.busy": "2025-05-12T16:54:22.442231Z",
     "iopub.status.idle": "2025-05-12T16:54:22.450600Z",
     "shell.execute_reply": "2025-05-12T16:54:22.449819Z",
     "shell.execute_reply.started": "2025-05-12T16:54:22.443031Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "qwen_lora_estate_metrics = evaluate_model(true_labels, qwen_lora_estate_preds)\n",
    "\n",
    "qwen_lora_estate_metrics[\"n_samples\"] = len(val_data)\n",
    "qwen_lora_estate_metrics[\"eval_time (min)\"] = 2.82\n",
    "qwen_lora_estate_metrics[\"response_time (min)\"] = 2.82 / len(val_data)\n",
    "qwen_lora_estate_metrics[\"eval_device\"] = \"gpu-t4x2\"\n",
    "qwen_lora_estate_metrics[\"model_name\"] = model_id.split('/')[-1]\n",
    "\n",
    "JSON(qwen_lora_estate_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T17:18:49.886707Z",
     "iopub.status.busy": "2025-05-12T17:18:49.886111Z",
     "iopub.status.idle": "2025-05-12T17:18:49.900888Z",
     "shell.execute_reply": "2025-05-12T17:18:49.900232Z",
     "shell.execute_reply.started": "2025-05-12T17:18:49.886682Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Qwen_lora_estate_results = pd.DataFrame(Qwen_lora_estate_tokens_history)\n",
    "Qwen_lora_estate_results['y_actual'] = true_labels\n",
    "Qwen_lora_estate_results['y_pred'] = qwen_lora_estate_preds\n",
    "\n",
    "missed_prec = len(Qwen_lora_estate_results[Qwen_lora_estate_results['y_pred']==-1]) * 100 /len(val_data)\n",
    "qwen_lora_estate_metrics[\"missing_pred(%)\"] = missed_prec\n",
    "\n",
    "print(f\">>>>>> Base Qwen can't predict {missed_prec}% from the given data <<<<<<\")\n",
    "\n",
    "Qwen_lora_estate_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Results for our `Qwen-lora-estate` Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T16:55:28.700746Z",
     "iopub.status.busy": "2025-05-12T16:55:28.700415Z",
     "iopub.status.idle": "2025-05-12T16:55:28.714716Z",
     "shell.execute_reply": "2025-05-12T16:55:28.713858Z",
     "shell.execute_reply.started": "2025-05-12T16:55:28.700724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(f\"{os.environ['RESULTS']}/qwen_lora_estate_metrics.json\", 'w') as json_file:\n",
    "    json.dump(qwen_lora_estate_metrics, json_file, indent=4)\n",
    "\n",
    "Qwen_lora_estate_results.to_csv(f\"{os.environ['RESULTS']}/qwen_lora_estate_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T16:55:37.288087Z",
     "iopub.status.busy": "2025-05-12T16:55:37.287292Z",
     "iopub.status.idle": "2025-05-12T16:55:37.487920Z",
     "shell.execute_reply": "2025-05-12T16:55:37.486914Z",
     "shell.execute_reply.started": "2025-05-12T16:55:37.288056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# to be downolad for further comparasions\n",
    "!zip /kaggle/working/results_200.zip /kaggle/working/results/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gemini_metrics.json', 'pretrained_qwen_metrics.json', 'qwen_lora_estate_metrics.json']\n"
     ]
    }
   ],
   "source": [
    "json_files = []\n",
    "\n",
    "for root, dirs, files in os.walk('results'):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            json_files.append(file)\n",
    "\n",
    "print(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for filepath in json_files:\n",
    "    with open(f\"{os.environ['RESULTS']}/{filepath}\", 'r') as f:\n",
    "        results.append(json.load(f))\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.set_index('model_name', inplace=True)\n",
    "\n",
    "df_results.to_csv(f\"{os.environ['RESULTS']}/results_comparisons.csv\", index=False)\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "x4v0D3WgVvB8",
    "_l-cfEqOVzuF",
    "zFlH_4lZ1i6j",
    "EHk9VZ_lEzNG"
   ],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12197011,
     "datasetId": 7348439,
     "sourceId": 11718898,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 8092475,
     "datasetId": 3202774,
     "sourceId": 7981839,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 238764139,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 239326280,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b16163efaa3467aac8c6c3a381acc04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33466bd6149a4381b88c4fd4f96d441f",
      "placeholder": "​",
      "style": "IPY_MODEL_88bd985ff0b241d29edf9d93f83fb6ce",
      "value": "Kaggle credentials successfully validated."
     }
    },
    "0fc862d1f32d4222a9eab0d3d3363952": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c3f73d6e7d64e568520935df91bc862": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "290db3966a504b47bf6e23814a0b59c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33466bd6149a4381b88c4fd4f96d441f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f924d63bc0243798fcc0dcf91f640ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74c6f83c2e6f41c9aeb0ba8cfd0c1e3d",
      "placeholder": "​",
      "style": "IPY_MODEL_5ca49aef822a4aa8acd9a7d8efa73235",
      "value": "Connecting..."
     }
    },
    "504a7821b59d4524b299cd127e34865c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "535e2f372f74492dbdfccf95fa2ccc51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bca663d78c5b48c3a8a5cbab44403501",
      "placeholder": "​",
      "style": "IPY_MODEL_e56dc41c9e1a4922849bb6f3ac85385d",
      "value": "\n<b>Thank You</b></center>"
     }
    },
    "5ca49aef822a4aa8acd9a7d8efa73235": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6edbbdb4f52b4a4d84c5ae9c986ce926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Username:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_b198176b8666463bb22fc74613ca81c7",
      "placeholder": "​",
      "style": "IPY_MODEL_85a6a112fef043869b3f3f26a9afde08",
      "value": "hebamo7amed"
     }
    },
    "74c6f83c2e6f41c9aeb0ba8cfd0c1e3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bca60effe184c59a2f2f9722f402d49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85a6a112fef043869b3f3f26a9afde08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88bd985ff0b241d29edf9d93f83fb6ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "949aca8fdc584623b1e7d456d4f33bd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "9593f1f003a64cf9a96900362576b76a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "9ec64b1bfc0647bb96bf803c2068d7b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_0fc862d1f32d4222a9eab0d3d3363952",
      "style": "IPY_MODEL_9593f1f003a64cf9a96900362576b76a",
      "tooltip": ""
     }
    },
    "b198176b8666463bb22fc74613ca81c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bca663d78c5b48c3a8a5cbab44403501": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca360e1b101d4395af434fc52908477b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0b16163efaa3467aac8c6c3a381acc04"
      ],
      "layout": "IPY_MODEL_949aca8fdc584623b1e7d456d4f33bd9"
     }
    },
    "da45d9a4491f4bb49a94d3a6f390e904": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_504a7821b59d4524b299cd127e34865c",
      "placeholder": "​",
      "style": "IPY_MODEL_1c3f73d6e7d64e568520935df91bc862",
      "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
     }
    },
    "e56dc41c9e1a4922849bb6f3ac85385d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff752a123aec447cbc4ee24fd02fa347": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_290db3966a504b47bf6e23814a0b59c7",
      "placeholder": "​",
      "style": "IPY_MODEL_7bca60effe184c59a2f2f9722f402d49",
      "value": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
