{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base models Qwen3-06B and Gemini API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a **baseline evaluation** to assess the performance of pre-trained models (`Qwen3-065B` and `gemini-2.0-flash-exp` API) on the real estate price prediction task. \n",
    "\n",
    "The notebook performs the following steps:\n",
    "\n",
    "1. Load dataset from remote (Kaggle/Hugging Face).\n",
    "2. Preprocess dataset.\n",
    "3. Evaluate pre-trained `Qwen\\Qwen3-0.6B` model using regression metrics.\n",
    "4. Evaluate Gemini API using regression metrics.\n",
    "5. Save results to compare with the **fine-tuned LoRa `Qwen3-0.6B` model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZU5_1OLopMUy"
   },
   "source": [
    "---\n",
    "## Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4v0D3WgVvB8"
   },
   "source": [
    "### **Install Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T13:55:47.291528Z",
     "iopub.status.busy": "2025-05-09T13:55:47.290895Z",
     "iopub.status.idle": "2025-05-09T13:55:52.427258Z",
     "shell.execute_reply": "2025-05-09T13:55:52.425873Z",
     "shell.execute_reply.started": "2025-05-09T13:55:47.291500Z"
    },
    "id": "Yj6qTXvPpwyk",
    "outputId": "9bd2220a-0e37-4a3f-b594-7b1bdf031cae",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -qU transformers wandb google-generativeai huggingface_hub[hf_xet]\n",
    "!pip install -qU  json_repair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_l-cfEqOVzuF"
   },
   "source": [
    "### **Import Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:55:52.429602Z",
     "iopub.status.busy": "2025-05-09T13:55:52.429311Z",
     "iopub.status.idle": "2025-05-09T13:55:59.503467Z",
     "shell.execute_reply": "2025-05-09T13:55:59.502481Z",
     "shell.execute_reply.started": "2025-05-09T13:55:52.429574Z"
    },
    "id": "mAre3Yb9TEj9",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import json_repair\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, JSON\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import google.generativeai as genai\n",
    "\n",
    "from utils import logging_config, evalute_model, timeit\n",
    "from fine_tuning_helpers import apply_prompt_template, decode_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:10:30.934665Z",
     "iopub.status.busy": "2025-05-09T14:10:30.934084Z",
     "iopub.status.idle": "2025-05-09T14:10:30.944627Z",
     "shell.execute_reply": "2025-05-09T14:10:30.943961Z",
     "shell.execute_reply.started": "2025-05-09T14:10:30.934631Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_Logger utils (INFO)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['LOGS'] = '/kaggle/working/logs'\n",
    "os.environ['RESULTS'] = '/kaggle/working/results'\n",
    "\n",
    "os.makedirs(os.environ['LOGS'], exist_ok=True )\n",
    "os.makedirs(os.environ['RESULTS'], exist_ok=True )\n",
    "\n",
    "LOGGER = logging_config(log_dir=os.environ['LOGS'])\n",
    "LOGGER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Define Tokens and Authenticate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:59:41.223299Z",
     "iopub.status.busy": "2025-05-09T13:59:41.222999Z",
     "iopub.status.idle": "2025-05-09T13:59:41.563036Z",
     "shell.execute_reply": "2025-05-09T13:59:41.562297Z",
     "shell.execute_reply.started": "2025-05-09T13:59:41.223277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# If using kaggle \n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "hf_token = user_secrets.get_secret(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "gemini_token = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# uncomment if using colab\n",
    "# from google.colab import userdata\n",
    "# hf_token = userdata.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "# gemini_token = userdata.get(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:59:43.141677Z",
     "iopub.status.busy": "2025-05-09T13:59:43.141352Z",
     "iopub.status.idle": "2025-05-09T13:59:43.377510Z",
     "shell.execute_reply": "2025-05-09T13:59:43.376615Z",
     "shell.execute_reply.started": "2025-05-09T13:59:43.141653Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "auth": {
        "accessToken": {
         "createdAt": "2025-05-06T20:44:04.749Z",
         "displayName": "fine-tune",
         "fineGrained": {
          "canReadGatedRepos": true,
          "global": [
           "discussion.write",
           "post.write"
          ],
          "scoped": [
           {
            "entity": {
             "_id": "681ada3852431b1769c74a39",
             "name": "heba1998/real-estate-data-for-llm-fine-tuning",
             "type": "dataset"
            },
            "permissions": [
             "repo.content.read",
             "discussion.write",
             "repo.write"
            ]
           },
           {
            "entity": {
             "_id": "64ce9cd07c24890fb4a7417d",
             "name": "heba1998",
             "type": "user"
            },
            "permissions": [
             "user.webhooks.read",
             "repo.content.read",
             "repo.write",
             "inference.serverless.write",
             "inference.endpoints.infer.write",
             "inference.endpoints.write",
             "user.webhooks.write",
             "collection.read",
             "collection.write",
             "discussion.write",
             "user.billing.read"
            ]
           }
          ]
         },
         "role": "fineGrained"
        },
        "type": "access_token"
       },
       "avatarUrl": "/avatars/8145446f31c46dc9df026753db8f5d9c.svg",
       "canPay": false,
       "fullname": "Heba ",
       "id": "64ce9cd07c24890fb4a7417d",
       "isPro": false,
       "name": "heba1998",
       "orgs": [],
       "periodEnd": null,
       "type": "user"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import whoami, login\n",
    "\n",
    "# !huggingface-cli login --token {mytoken} # another method\n",
    "login(token = hf_token)\n",
    "genai.configure(api_key=gemini_token)\n",
    "JSON(whoami())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "ca360e1b101d4395af434fc52908477b",
      "da45d9a4491f4bb49a94d3a6f390e904",
      "6edbbdb4f52b4a4d84c5ae9c986ce926",
      "ff752a123aec447cbc4ee24fd02fa347",
      "9ec64b1bfc0647bb96bf803c2068d7b5",
      "535e2f372f74492dbdfccf95fa2ccc51",
      "949aca8fdc584623b1e7d456d4f33bd9",
      "504a7821b59d4524b299cd127e34865c",
      "1c3f73d6e7d64e568520935df91bc862",
      "b198176b8666463bb22fc74613ca81c7",
      "85a6a112fef043869b3f3f26a9afde08",
      "290db3966a504b47bf6e23814a0b59c7",
      "7bca60effe184c59a2f2f9722f402d49",
      "0fc862d1f32d4222a9eab0d3d3363952",
      "9593f1f003a64cf9a96900362576b76a",
      "bca663d78c5b48c3a8a5cbab44403501",
      "e56dc41c9e1a4922849bb6f3ac85385d",
      "4f924d63bc0243798fcc0dcf91f640ae",
      "74c6f83c2e6f41c9aeb0ba8cfd0c1e3d",
      "5ca49aef822a4aa8acd9a7d8efa73235",
      "0b16163efaa3467aac8c6c3a381acc04",
      "33466bd6149a4381b88c4fd4f96d441f",
      "88bd985ff0b241d29edf9d93f83fb6ce"
     ]
    },
    "id": "-PA52fS9nN3f",
    "outputId": "53053baf-1b08-4315-b578-df27ae312e89",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# uncomment if using colab\n",
    "# import kagglehub\n",
    "# kagglehub.login(validate_credentials=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-B1psKPpKQ9"
   },
   "source": [
    "---\n",
    "## Load Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from remote (Kaggle/Hugging Face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ix7pknmVppL"
   },
   "source": [
    "**Download the dataset from Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0L9nwgUziDkG",
    "outputId": "8654634a-1dd1-4b11-9f73-ba03b9f14ec0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Uncomment if using colab\n",
    "\n",
    "# kagglehub.dataset_download('hebamo7amed/real-estate-data-for-llm-fine-tuning')\n",
    "# tabular_data_path = f\"{data_path}/tabular_data\"\n",
    "# text_data_path = f\"{data_path}/text_data\"\n",
    "# text_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPq5gXZvZ-5x"
   },
   "source": [
    "**Read Text Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e38k8TCHUkf6",
    "outputId": "38acf928-6ee3-465b-ff27-2d48fc413361",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# with open(f\"{text_data_path}/text_train_data.jsonl\", \"r\") as f:\n",
    "#   train_data = json.load(f)\n",
    "\n",
    "# with open(f\"{text_data_path}/text_val_data.jsonl\", \"r\") as f:\n",
    "#   val_data = json.load(f)\n",
    "\n",
    "# with open(f\"{text_data_path}/sample_50.jsonl\", \"r\") as f:\n",
    "#   sample_data = json.load(f)\n",
    "\n",
    "# print(\"Training data size = \", len(train_data))\n",
    "# print(\"Validation data size = \", len(val_data))\n",
    "# print(\"Sample data size = \", len(sample_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Dataset Sample from hugging Face Hub**\n",
    "\n",
    "A data sample that was created from structured real estate data and uploaded to Hugging Face in the first notebook. It is formatted for ion-based fine-tuning an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:00:51.051791Z",
     "iopub.status.busy": "2025-05-09T14:00:51.051397Z",
     "iopub.status.idle": "2025-05-09T14:00:55.950636Z",
     "shell.execute_reply": "2025-05-09T14:00:55.949764Z",
     "shell.execute_reply.started": "2025-05-09T14:00:51.051762Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d269fd21c87483cbb030c04e925d097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81891e740c944af497cf49e6b159ee9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_train_data.jsonl:   0%|          | 0.00/5.54M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e4dabb539a4424983f10e4a2973b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_val_data.jsonl:   0%|          | 0.00/222k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb3aff9db244940979973ff4c679295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670931b081454e57a6075d9fdbf77e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'instruction', 'input', 'output', 'history'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['system', 'instruction', 'input', 'output', 'history'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\n",
    "    path  ='heba1998/real-estate-data-sample-for-llm-fine-tuning'\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:12:47.182968Z",
     "iopub.status.busy": "2025-05-09T14:12:47.182008Z",
     "iopub.status.idle": "2025-05-09T14:12:47.213014Z",
     "shell.execute_reply": "2025-05-09T14:12:47.211853Z",
     "shell.execute_reply.started": "2025-05-09T14:12:47.182934Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert data to list of jsons or ``jsonl``\n",
    "\n",
    "val_data = [sample for sample in dataset['validation']]\n",
    "house_price = lambda sample : json_repair.loads(sample['output'])['estimated_house_price']\n",
    "true_labels = [ house_price(sample) for sample in dataset['validation']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XEQiv5qe6yp"
   },
   "source": [
    "---\n",
    "## Evaluate Responses from Base LM `Qwen3-0.6B`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Helper Function to get responses for base model**\n",
    "\n",
    "This function uses another function from the `fine_tuning_helpers.py` and `utils` utility scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:14:34.793346Z",
     "iopub.status.busy": "2025-05-09T14:14:34.792980Z",
     "iopub.status.idle": "2025-05-09T14:14:34.801718Z",
     "shell.execute_reply": "2025-05-09T14:14:34.800784Z",
     "shell.execute_reply.started": "2025-05-09T14:14:34.793318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@timeit\n",
    "def batch_generate(model, tokenizer, data, device):\n",
    "    predictions = []\n",
    "    tokens_history = []\n",
    "    bar_format = '{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'\n",
    "    \n",
    "    for idx, sample in enumerate(tqdm(data, total=len(data),\n",
    "                                 desc=\"Get response from pre-trained `Qwen3-0.6B` model\",\n",
    "                                 ncols=100, colour='green')):\n",
    "        # 1. PREPROCESSING: \n",
    "        # build the system and user prompt with the model chat template\n",
    "        prompt = apply_prompt_template(sample, output_str='ion')\n",
    "\n",
    "        # 2. TOKENIZATION: Tokenize the text prompt message\n",
    "        inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "        n_input_tokens = len(inputs.input_ids[0])\n",
    "        LOGGER.info(f\"\\t>> Tokenized to {n_input_tokens} tokens\")\n",
    "        \n",
    "        # 3. GENERATION: Generate response\n",
    "        response_tokens_ids = model.generate(\n",
    "            inputs=inputs.input_ids,\n",
    "            attention_mask=inputs.attention_mask,\n",
    "        )\n",
    "        n_output_tokens = len(response_tokens_ids[0])\n",
    "\n",
    "        # 4. POSTPROCESSING: Return only the output tokens and  exclude input ids and then clean response\n",
    "        response_text = decode_response(response_tokens_ids, inputs.input_ids, tokenizer)\n",
    "        response_dict = json_repair.loads(response_text)            \n",
    "        house_price = response_dict[\"estimated_house_price\"]\n",
    "        predictions.append(int(house_price))\n",
    "        \n",
    "        # Store BAse model metadata for cost calculation\n",
    "        tokens_history.append({\n",
    "                'id': idx,\n",
    "                'input_tokens': n_input_tokens, \n",
    "                'output_tokens': n_output_tokens,\n",
    "                'total_tokens': n_input_tokens + n_output_tokens\n",
    "            })\n",
    "            \n",
    "    return predictions, tokens_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load `Qwen3-0.6B` from Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T11:41:22.176780Z",
     "iopub.status.busy": "2025-05-09T11:41:22.176417Z",
     "iopub.status.idle": "2025-05-09T11:41:56.544316Z",
     "shell.execute_reply": "2025-05-09T11:41:56.542716Z",
     "shell.execute_reply.started": "2025-05-09T11:41:22.176752Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4205dd0a0e484381864816bafbf857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/9.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d729e8b8560b45788b6f89add15c7a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd01da4120ac4a4cb8e4a6ae202e8499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd47dd6d86d4f81a447b190ad72b9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea6da21fb7a48f5aeac19b8cc44e119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 11:41:33.445210: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746790893.732709      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746790893.808796      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0728ffd0da584087a848ddbe03bd425d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02aee0dab7a04d6db0ad3a206ddbf6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"Qwen/Qwen3-0.6B\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer_qwen = AutoTokenizer.from_pretrained(model_id)\n",
    "model_qwen = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=None).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Response using Pre-trained `Qwen3-0.6B`.**\n",
    "\n",
    "Generate responses from the base model `Qwen3-0.6B` in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T11:41:56.546687Z",
     "iopub.status.busy": "2025-05-09T11:41:56.545952Z",
     "iopub.status.idle": "2025-05-09T12:01:54.393988Z",
     "shell.execute_reply": "2025-05-09T12:01:54.392517Z",
     "shell.execute_reply.started": "2025-05-09T11:41:56.546655Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get response from pre-trained `Qwen3-0.6B` model: 100%|\u001b[32m███████████\u001b[0m| 200/200 [19:57<00:00,  5.99s/it]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data completed in 19.96 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Make batch prediction or text to number genration \n",
    "qwen_preds, qwen_tokens_history = batch_generate(model=model_qwen, \n",
    "                                                  tokenizer=tokenizer_qwen, \n",
    "                                                  data = val_data,\n",
    "                                                  device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Prediction for 200 sample takes 19.96 minutes using pretrained `Qwen3-0.6B`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3OCT8N8JWBX"
   },
   "source": [
    "### **Evaluation metrics**\n",
    "\n",
    "This function is implemented in the `utils.py` utility script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:40:19.129871Z",
     "iopub.status.busy": "2025-05-09T13:40:19.129366Z",
     "iopub.status.idle": "2025-05-09T13:40:19.154883Z",
     "shell.execute_reply": "2025-05-09T13:40:19.153690Z",
     "shell.execute_reply.started": "2025-05-09T13:40:19.129838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Price [2500000.0, 295000.0, 299900.0, 699000.0, 239000.0, 11000.0, 470000.0, 449000.0, 250000.0, 339000.0]\n",
      "Predicted Prices [55000, 128000, 85000, 85000, 85000, 85000, 85000, 85000, 85000, 85000]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Price\", true_labels[:10])\n",
    "print(\"Predicted Prices\", qwen_preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:50:38.872351Z",
     "iopub.status.busy": "2025-05-09T13:50:38.872037Z",
     "iopub.status.idle": "2025-05-09T13:50:38.879434Z",
     "shell.execute_reply": "2025-05-09T13:50:38.878626Z",
     "shell.execute_reply.started": "2025-05-09T13:50:38.872328Z"
    },
    "id": "v0DpDsevIw4p",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "MAE": 404009.03,
       "MSE": 428368963146.25,
       "R2": -0.5385257769487695,
       "RMSE": 654499.0169177109
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_qwen_metrics = evalute_model(true_labels, qwen_preds)\n",
    "JSON(pretrained_qwen_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKJ7qhbwir3n"
   },
   "source": [
    "> Model produce bad result and don't follow the output schema\n",
    "\n",
    "> Model predict the same value each time `85000` or `8500` because it is bais towards the example of the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:57:33.961209Z",
     "iopub.status.busy": "2025-05-09T13:57:33.960565Z",
     "iopub.status.idle": "2025-05-09T13:57:33.993443Z",
     "shell.execute_reply": "2025-05-09T13:57:33.992657Z",
     "shell.execute_reply.started": "2025-05-09T13:57:33.961180Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>y_actual</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>264</td>\n",
       "      <td>508</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>266</td>\n",
       "      <td>512</td>\n",
       "      <td>295000.0</td>\n",
       "      <td>128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>245</td>\n",
       "      <td>265</td>\n",
       "      <td>510</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>246</td>\n",
       "      <td>266</td>\n",
       "      <td>512</td>\n",
       "      <td>699000.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>265</td>\n",
       "      <td>510</td>\n",
       "      <td>239000.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>230</td>\n",
       "      <td>250</td>\n",
       "      <td>480</td>\n",
       "      <td>349000.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>241</td>\n",
       "      <td>261</td>\n",
       "      <td>502</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>244</td>\n",
       "      <td>264</td>\n",
       "      <td>508</td>\n",
       "      <td>389000.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "      <td>251</td>\n",
       "      <td>482</td>\n",
       "      <td>582990.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>229</td>\n",
       "      <td>249</td>\n",
       "      <td>478</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  input_tokens  output_tokens  total_tokens   y_actual  y_pred\n",
       "0      0           244            264           508  2500000.0   55000\n",
       "1      1           246            266           512   295000.0  128000\n",
       "2      2           245            265           510   299900.0   85000\n",
       "3      3           246            266           512   699000.0   85000\n",
       "4      4           245            265           510   239000.0   85000\n",
       "..   ...           ...            ...           ...        ...     ...\n",
       "195  195           230            250           480   349000.0   85000\n",
       "196  196           241            261           502   220000.0  210000\n",
       "197  197           244            264           508   389000.0   85000\n",
       "198  198           231            251           482   582990.0   85000\n",
       "199  199           229            249           478   220000.0   85000\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen_results = pd.DataFrame(qwen_tokens_history)\n",
    "qwen_results['y_actual'] = true_labels\n",
    "qwen_results['y_pred'] = qwen_preds\n",
    "\n",
    "qwen_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save Pre-trained`Qwen3-0.6B` Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:57:36.395729Z",
     "iopub.status.busy": "2025-05-09T13:57:36.395418Z",
     "iopub.status.idle": "2025-05-09T13:57:36.408689Z",
     "shell.execute_reply": "2025-05-09T13:57:36.407735Z",
     "shell.execute_reply.started": "2025-05-09T13:57:36.395684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(f\"{os.environ['RESULTS']}/pretrained_qwen_metrics.json\", 'w') as json_file:\n",
    "    json.dump(pretrained_qwen_metrics, json_file, indent=4)\n",
    "\n",
    "qwen_results.to_csv(f\"{os.environ['RESULTS']}/pretrained_qwen_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQQ4gDLjLJ8V"
   },
   "source": [
    "---\n",
    "## Evaluate Responses of Gemini Model\n",
    "---\n",
    "\n",
    "Evaluate the responses from Gemini API using regression metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Helper Function to get responses from `genai` SDK API**\n",
    "\n",
    "This function uses another function from the `fine_tuning_helpers.py` and `utils` utility scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:01:51.393745Z",
     "iopub.status.busy": "2025-05-09T14:01:51.393402Z",
     "iopub.status.idle": "2025-05-09T14:01:51.401369Z",
     "shell.execute_reply": "2025-05-09T14:01:51.400489Z",
     "shell.execute_reply.started": "2025-05-09T14:01:51.393698Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from fine_tuning_helpers import extract_house_price\n",
    "\n",
    "@timeit\n",
    "def batch_api_generate(model, data):\n",
    "    llm_predictions = []\n",
    "    tokens_history = []\n",
    "    bar_format = '{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'\n",
    "    \n",
    "    for idx, sample in enumerate(tqdm(data, total=len(data),\n",
    "                                 desc=\"Get response from pre-trained `Qwen3-0.6B` model\",\n",
    "                                 ncols=100, colour='green')):\n",
    "        LOGGER.info(\"-\"*50)\n",
    "        LOGGER.info(f\"Sample id {idx}\")\n",
    "        LOGGER.info(\"-\"*50)\n",
    "        # 1. PREPROCESSING: \n",
    "        # build the system and user prompt with the model chat template\n",
    "        prompt= apply_prompt_template(sample)\n",
    "\n",
    "        # 2. GENERATION: Generate response\n",
    "        response = model.generate_content(prompt)\n",
    "        text_response = response.candidates[0].content.parts[0].text\n",
    "\n",
    "        # 4. POSTPROCESSING:  return only the output tokens and  exclude input ids\n",
    "        LOGGER.info(f\"Response text for sample id={idx} \\n {text_response}\" )\n",
    "        \n",
    "        # Clean response\n",
    "        house_price = extract_house_price(text_response)\n",
    "        LOGGER.info(f\"\\t>> Predicted price: {house_price}\")\n",
    "        llm_predictions.append(int(house_price))\n",
    "        \n",
    "        # Store metadata for expenses calculation\n",
    "        tokens_history.append({\n",
    "                'id': idx,\n",
    "                'input_tokens': response.usage_metadata.prompt_token_count, \n",
    "                'output_tokens': response.usage_metadata.candidates_token_count,\n",
    "                'total_tokens': response.usage_metadata.total_token_count\n",
    "            })\n",
    "            \n",
    "        LOGGER.debug(f\"Updated tokens history for {idx}\")\n",
    "\n",
    "    return llm_predictions, tokens_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-09T12:23:06.908612Z",
     "iopub.status.busy": "2025-05-09T12:23:06.908242Z",
     "iopub.status.idle": "2025-05-09T12:23:07.186377Z",
     "shell.execute_reply": "2025-05-09T12:23:07.185489Z",
     "shell.execute_reply.started": "2025-05-09T12:23:06.908588Z"
    },
    "id": "iBkMuyuKB7Jg",
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/chat-bison-001',\n",
       " 'models/text-bison-001',\n",
       " 'models/embedding-gecko-001',\n",
       " 'models/gemini-1.0-pro-vision-latest',\n",
       " 'models/gemini-pro-vision',\n",
       " 'models/gemini-1.5-pro-latest',\n",
       " 'models/gemini-1.5-pro-001',\n",
       " 'models/gemini-1.5-pro-002',\n",
       " 'models/gemini-1.5-pro',\n",
       " 'models/gemini-1.5-flash-latest',\n",
       " 'models/gemini-1.5-flash-001',\n",
       " 'models/gemini-1.5-flash-001-tuning',\n",
       " 'models/gemini-1.5-flash',\n",
       " 'models/gemini-1.5-flash-002',\n",
       " 'models/gemini-1.5-flash-8b',\n",
       " 'models/gemini-1.5-flash-8b-001',\n",
       " 'models/gemini-1.5-flash-8b-latest',\n",
       " 'models/gemini-1.5-flash-8b-exp-0827',\n",
       " 'models/gemini-1.5-flash-8b-exp-0924',\n",
       " 'models/gemini-2.5-pro-exp-03-25',\n",
       " 'models/gemini-2.5-pro-preview-03-25',\n",
       " 'models/gemini-2.5-flash-preview-04-17',\n",
       " 'models/gemini-2.5-flash-preview-04-17-thinking',\n",
       " 'models/gemini-2.5-pro-preview-05-06',\n",
       " 'models/gemini-2.0-flash-exp',\n",
       " 'models/gemini-2.0-flash',\n",
       " 'models/gemini-2.0-flash-001',\n",
       " 'models/gemini-2.0-flash-lite-001',\n",
       " 'models/gemini-2.0-flash-lite',\n",
       " 'models/gemini-2.0-flash-lite-preview-02-05',\n",
       " 'models/gemini-2.0-flash-lite-preview',\n",
       " 'models/gemini-2.0-pro-exp',\n",
       " 'models/gemini-2.0-pro-exp-02-05',\n",
       " 'models/gemini-exp-1206',\n",
       " 'models/gemini-2.0-flash-thinking-exp-01-21',\n",
       " 'models/gemini-2.0-flash-thinking-exp',\n",
       " 'models/gemini-2.0-flash-thinking-exp-1219',\n",
       " 'models/learnlm-1.5-pro-experimental',\n",
       " 'models/learnlm-2.0-flash-experimental',\n",
       " 'models/gemma-3-1b-it',\n",
       " 'models/gemma-3-4b-it',\n",
       " 'models/gemma-3-12b-it',\n",
       " 'models/gemma-3-27b-it',\n",
       " 'models/embedding-001',\n",
       " 'models/text-embedding-004',\n",
       " 'models/gemini-embedding-exp-03-07',\n",
       " 'models/gemini-embedding-exp',\n",
       " 'models/aqa',\n",
       " 'models/imagen-3.0-generate-002',\n",
       " 'models/gemini-2.0-flash-live-001']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.name for model in genai.list_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Response using Gemini.**\n",
    "\n",
    "Generate responses from `gemini-2.0-flash-exp` in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:01:55.600585Z",
     "iopub.status.busy": "2025-05-09T14:01:55.600246Z",
     "iopub.status.idle": "2025-05-09T14:04:22.839202Z",
     "shell.execute_reply": "2025-05-09T14:04:22.838157Z",
     "shell.execute_reply.started": "2025-05-09T14:01:55.600511Z"
    },
    "id": "oyp-D90YCdIN",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get response from pre-trained `Qwen3-0.6B` model: 100%|\u001b[32m███████████\u001b[0m| 200/200 [02:27<00:00,  1.36it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data completed in 2.45 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "\n",
    "Configs = genai.GenerationConfig(max_output_tokens=200)\n",
    "\n",
    "model_id = \"models/gemini-2.0-flash-exp\"\n",
    "gemini = genai.GenerativeModel(model_name=model_id,\n",
    "                               generation_config=Configs)\n",
    "\n",
    "gemini_preds, gemini_tokens_history = batch_api_generate(gemini, data = val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3OCT8N8JWBX"
   },
   "source": [
    "### **Evaluation metrics**\n",
    "\n",
    "This function is implemented in the `utils.py` utility script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:04:22.841117Z",
     "iopub.status.busy": "2025-05-09T14:04:22.840787Z",
     "iopub.status.idle": "2025-05-09T14:04:22.846651Z",
     "shell.execute_reply": "2025-05-09T14:04:22.845687Z",
     "shell.execute_reply.started": "2025-05-09T14:04:22.841094Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Price [2500000.0, 295000.0, 299900.0, 699000.0, 239000.0, 11000.0, 470000.0, 449000.0, 250000.0, 339000.0]\n",
      "Predicted Prices [-1, -1, 345000, -1, -1, -1, -1, -1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Price\", true_labels[:10])\n",
    "print(\"Predicted Prices\", gemini_preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **`-1`** indecate to that gemini didn't produce the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:04:22.848139Z",
     "iopub.status.busy": "2025-05-09T14:04:22.847755Z",
     "iopub.status.idle": "2025-05-09T14:04:22.873172Z",
     "shell.execute_reply": "2025-05-09T14:04:22.872322Z",
     "shell.execute_reply.started": "2025-05-09T14:04:22.848118Z"
    },
    "id": "v0DpDsevIw4p",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "MAE": 390199.94,
       "MSE": 404732979411.82,
       "R2": -0.4536350090185375,
       "RMSE": 636186.2772897731
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_metrics = evalute_model(true_labels, gemini_preds)\n",
    "\n",
    "JSON(gemini_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:04:56.673411Z",
     "iopub.status.busy": "2025-05-09T14:04:56.673126Z",
     "iopub.status.idle": "2025-05-09T14:04:56.687456Z",
     "shell.execute_reply": "2025-05-09T14:04:56.686522Z",
     "shell.execute_reply.started": "2025-05-09T14:04:56.673392Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>> Gemini can't predict 72.0% from the given data <<<<<<\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>y_actual</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>78</td>\n",
       "      <td>335</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>77</td>\n",
       "      <td>335</td>\n",
       "      <td>295000.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>104</td>\n",
       "      <td>360</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>78</td>\n",
       "      <td>336</td>\n",
       "      <td>699000.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>78</td>\n",
       "      <td>336</td>\n",
       "      <td>239000.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  input_tokens  output_tokens  total_tokens   y_actual  y_pred\n",
       "0   0           257             78           335  2500000.0      -1\n",
       "1   1           258             77           335   295000.0      -1\n",
       "2   2           256            104           360   299900.0  345000\n",
       "3   3           258             78           336   699000.0      -1\n",
       "4   4           258             78           336   239000.0      -1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_results = pd.DataFrame(gemini_tokens_history)\n",
    "gemini_results['y_actual'] = true_labels\n",
    "gemini_results['y_pred'] = gemini_preds\n",
    "\n",
    "missed_prec = len(gemini_results[gemini_results['y_pred']==-1]) *100 /len(val_data)\n",
    "print(f\">>>>>> Gemini can't predict {missed_prec}% from the given data <<<<<<\")\n",
    "\n",
    "gemini_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save Gemini Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:22:42.608285Z",
     "iopub.status.busy": "2025-05-09T14:22:42.607877Z",
     "iopub.status.idle": "2025-05-09T14:22:42.616302Z",
     "shell.execute_reply": "2025-05-09T14:22:42.615312Z",
     "shell.execute_reply.started": "2025-05-09T14:22:42.608259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(f\"{os.environ['RESULTS']}/gemini_metrics.json\", 'w') as json_file:\n",
    "    json.dump(gemini_metrics, json_file, indent=4)\n",
    "\n",
    "qwen_results.to_csv(f\"{os.environ['RESULTS']}/gemini_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluate Responses from Fine-Tuned `Qwen3-0.6B`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Helper Function to get responses for base model**\n",
    "\n",
    "This function uses another function from the `fine_tuning_helpers.py` and `utils` utility scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load `Qwen3-0.6B` and the adaptor from Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen3-0.6B\"\n",
    "adaptor_id = \"heba1998/Qwen-LoRA-Estate\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer_qwen = AutoTokenizer.from_pretrained(model_id)\n",
    "base_qwen = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=None).to(device)\n",
    "\n",
    "# Load the LoRA adapter\n",
    "lora_adapter = LoraAdapter.from_pretrained(adaptor_id)\n",
    "\n",
    "# Attach the LoRA adapter to the model\n",
    "qwen_lora_estate = base_qwen.add_adapter(\"lora\", lora_adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Response using Pre-trained `Qwen3-0.6B`.**\n",
    "\n",
    "Generate responses from the base model `Qwen3-0.6B` in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get response from pre-trained `Qwen3-0.6B` model: 100%|\u001b[32m███████████\u001b[0m| 200/200 [19:57<00:00,  5.99s/it]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data completed in 19.96 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Make batch prediction or text to number genration\n",
    "qwen_lora_estate_preds, Qwen_lora_estate_tokens_history = batch_generate(model=qwen_lora_estate,\n",
    "                                                            tokenizer=tokenizer_qwen,\n",
    "                                                            data=val_data,\n",
    "                                                            device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Prediction for 200 sample takes 19.96 minutes using pretrained `Qwen3-0.6B`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation metrics**\n",
    "\n",
    "This function is implemented in the `utils.py` utility script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Price [2500000.0, 295000.0, 299900.0, 699000.0, 239000.0, 11000.0, 470000.0, 449000.0, 250000.0, 339000.0]\n",
      "Predicted Prices [55000, 128000, 85000, 85000, 85000, 85000, 85000, 85000, 85000, 85000]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Price\", true_labels[:10])\n",
    "print(\"Predicted Prices\", qwen_lora_estate_preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "MAE": 404009.03,
       "MSE": 428368963146.25,
       "R2": -0.5385257769487695,
       "RMSE": 654499.0169177109
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qwen_lora_estate_metrics = evaluate_model(true_labels, qwen_lora_estate_preds)\n",
    "JSON(qwen_lora_estate_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Model produce bad result and don't follow the output schema\n",
    "\n",
    "> Model predict the same value each time `85000` or `8500` because it is bais towards the example of the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>y_actual</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>264</td>\n",
       "      <td>508</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>266</td>\n",
       "      <td>512</td>\n",
       "      <td>295000.0</td>\n",
       "      <td>128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>245</td>\n",
       "      <td>265</td>\n",
       "      <td>510</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>246</td>\n",
       "      <td>266</td>\n",
       "      <td>512</td>\n",
       "      <td>699000.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>265</td>\n",
       "      <td>510</td>\n",
       "      <td>239000.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>230</td>\n",
       "      <td>250</td>\n",
       "      <td>480</td>\n",
       "      <td>349000.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>241</td>\n",
       "      <td>261</td>\n",
       "      <td>502</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>244</td>\n",
       "      <td>264</td>\n",
       "      <td>508</td>\n",
       "      <td>389000.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "      <td>251</td>\n",
       "      <td>482</td>\n",
       "      <td>582990.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>229</td>\n",
       "      <td>249</td>\n",
       "      <td>478</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  input_tokens  output_tokens  total_tokens   y_actual  y_pred\n",
       "0      0           244            264           508  2500000.0   55000\n",
       "1      1           246            266           512   295000.0  128000\n",
       "2      2           245            265           510   299900.0   85000\n",
       "3      3           246            266           512   699000.0   85000\n",
       "4      4           245            265           510   239000.0   85000\n",
       "..   ...           ...            ...           ...        ...     ...\n",
       "195  195           230            250           480   349000.0   85000\n",
       "196  196           241            261           502   220000.0  210000\n",
       "197  197           244            264           508   389000.0   85000\n",
       "198  198           231            251           482   582990.0   85000\n",
       "199  199           229            249           478   220000.0   85000\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qwen_results = pd.DataFrame(Qwen_lora_estate_tokens_history)\n",
    "qwen_results['y_actual'] = true_labels\n",
    "qwen_results['y_pred'] = qwen_preds\n",
    "\n",
    "qwen_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save Pre-trained`Qwen3-0.6B` Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.environ['RESULTS']}/qwen_lora_estate_metrics.json\", 'w') as json_file:\n",
    "    json.dump(qwen_lora_estate_metrics, json_file, indent=4)\n",
    "\n",
    "qwen_results.to_csv(f\"{os.environ['RESULTS']}/qwen_lora_estate_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:22:44.062274Z",
     "iopub.status.busy": "2025-05-09T14:22:44.061985Z",
     "iopub.status.idle": "2025-05-09T14:22:44.068154Z",
     "shell.execute_reply": "2025-05-09T14:22:44.066980Z",
     "shell.execute_reply.started": "2025-05-09T14:22:44.062255Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "results_metadata = {\n",
    "    \"Description\": \"Here is the time taken to predict 200 samples for the base models\",\n",
    "    \"Qwen Base (min)\": 2.45,\n",
    "    \"Gemini (min)\": 19.96,\n",
    "    \"Qwen LoRA Estate (min)\": None\n",
    "}\n",
    "\n",
    "with open(f\"{os.environ['RESULTS']}/results_metadata.json\", 'w') as json_file:\n",
    "    json.dump(results_metadata, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T14:22:46.914416Z",
     "iopub.status.busy": "2025-05-09T14:22:46.914104Z",
     "iopub.status.idle": "2025-05-09T14:22:47.061963Z",
     "shell.execute_reply": "2025-05-09T14:22:47.060791Z",
     "shell.execute_reply.started": "2025-05-09T14:22:46.914393Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: kaggle/working/results/ (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "# to be downolad for further comparasions\n",
    "!zip /kaggle/working/results_200.zip /kaggle/working/results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "x4v0D3WgVvB8",
    "_l-cfEqOVzuF",
    "zFlH_4lZ1i6j",
    "EHk9VZ_lEzNG"
   ],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3202774,
     "sourceId": 7981839,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7348439,
     "sourceId": 11718898,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 238628299,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 238764139,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b16163efaa3467aac8c6c3a381acc04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33466bd6149a4381b88c4fd4f96d441f",
      "placeholder": "​",
      "style": "IPY_MODEL_88bd985ff0b241d29edf9d93f83fb6ce",
      "value": "Kaggle credentials successfully validated."
     }
    },
    "0fc862d1f32d4222a9eab0d3d3363952": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c3f73d6e7d64e568520935df91bc862": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "290db3966a504b47bf6e23814a0b59c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33466bd6149a4381b88c4fd4f96d441f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f924d63bc0243798fcc0dcf91f640ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74c6f83c2e6f41c9aeb0ba8cfd0c1e3d",
      "placeholder": "​",
      "style": "IPY_MODEL_5ca49aef822a4aa8acd9a7d8efa73235",
      "value": "Connecting..."
     }
    },
    "504a7821b59d4524b299cd127e34865c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "535e2f372f74492dbdfccf95fa2ccc51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bca663d78c5b48c3a8a5cbab44403501",
      "placeholder": "​",
      "style": "IPY_MODEL_e56dc41c9e1a4922849bb6f3ac85385d",
      "value": "\n<b>Thank You</b></center>"
     }
    },
    "5ca49aef822a4aa8acd9a7d8efa73235": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6edbbdb4f52b4a4d84c5ae9c986ce926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Username:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_b198176b8666463bb22fc74613ca81c7",
      "placeholder": "​",
      "style": "IPY_MODEL_85a6a112fef043869b3f3f26a9afde08",
      "value": "hebamo7amed"
     }
    },
    "74c6f83c2e6f41c9aeb0ba8cfd0c1e3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bca60effe184c59a2f2f9722f402d49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85a6a112fef043869b3f3f26a9afde08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88bd985ff0b241d29edf9d93f83fb6ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "949aca8fdc584623b1e7d456d4f33bd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "9593f1f003a64cf9a96900362576b76a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "9ec64b1bfc0647bb96bf803c2068d7b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_0fc862d1f32d4222a9eab0d3d3363952",
      "style": "IPY_MODEL_9593f1f003a64cf9a96900362576b76a",
      "tooltip": ""
     }
    },
    "b198176b8666463bb22fc74613ca81c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bca663d78c5b48c3a8a5cbab44403501": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca360e1b101d4395af434fc52908477b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0b16163efaa3467aac8c6c3a381acc04"
      ],
      "layout": "IPY_MODEL_949aca8fdc584623b1e7d456d4f33bd9"
     }
    },
    "da45d9a4491f4bb49a94d3a6f390e904": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_504a7821b59d4524b299cd127e34865c",
      "placeholder": "​",
      "style": "IPY_MODEL_1c3f73d6e7d64e568520935df91bc862",
      "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
     }
    },
    "e56dc41c9e1a4922849bb6f3ac85385d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff752a123aec447cbc4ee24fd02fa347": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_290db3966a504b47bf6e23814a0b59c7",
      "placeholder": "​",
      "style": "IPY_MODEL_7bca60effe184c59a2f2f9722f402d49",
      "value": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
