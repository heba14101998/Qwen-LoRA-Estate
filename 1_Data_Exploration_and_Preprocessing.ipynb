{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration for Real Estate Price Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d8fe782c-b33f-48e7-ad6c-3a7cc2420b02",
    "_uuid": "cb00efe0-f1a8-439e-8228-3e26da3ba538",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "This notebook explores the USA Real Estate dataset, checks for inconsistencies, and outlines a plan to prepare it as natural language data for LLM fine-tuning.\n",
    "\n",
    "1. Takes raw USA real estate data (CSV format) as input\n",
    "2. Cleans and preprocesses the data (handling missing values, outliers, data types)\n",
    "3. Converts tabular data into natural language text format suitable for LLM fine-tuning\n",
    "4. Outputs structured JSON datasets (train/val splits) containing property descriptions and price information\n",
    "5. save text data to upload it into Kaggle and Hugginge Face for loading data again via colab and Kaggle.\n",
    "\n",
    "**Input raw data**\n",
    "- [Real Estate Tabular Data](https://www.kaggle.com/datasets/ahmedshahriarsakib/usa-real-estate-dataset)\n",
    "\n",
    "**Output text data**\n",
    "- [Kaggle Real Estate Text Data](https://www.kaggle.com/datasets/hebamo7amed/llm-real-estate-text-data/data)\n",
    "- [Hugging Face Real Estate Text Data](https://huggingface.co/datasets/heba1998/real-estate-data-for-llm-fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "297fa927-f897-41fa-b221-4246e4de44be",
    "_uuid": "add0f491-739a-42cb-aeab-fe764711c60c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "---\n",
    "## [0] Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda create -n llm_env python=3.12.9 -y\n",
    "# !conda activate llm_env\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kaggle \n",
    "\n",
    "from src.utils import check_missing, check_outliers_zscore, reduce_mem_usage, timeit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "seed = 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download raw dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist, downloading...\n",
      "Downloading usa-real-estate-dataset.zip to ./data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/38.2M [00:00<?, ?B/s]\n",
      "  3%|▎         | 1.00M/38.2M [00:00<00:25, 1.50MB/s]\n",
      "  5%|▌         | 2.00M/38.2M [00:00<00:16, 2.37MB/s]\n",
      "  8%|▊         | 3.00M/38.2M [00:01<00:12, 2.89MB/s]\n",
      " 10%|█         | 4.00M/38.2M [00:01<00:11, 3.24MB/s]\n",
      " 13%|█▎        | 5.00M/38.2M [00:01<00:10, 3.46MB/s]\n",
      " 16%|█▌        | 6.00M/38.2M [00:02<00:09, 3.62MB/s]\n",
      " 18%|█▊        | 7.00M/38.2M [00:02<00:08, 3.70MB/s]\n",
      " 21%|██        | 8.00M/38.2M [00:02<00:08, 3.71MB/s]\n",
      " 24%|██▎       | 9.00M/38.2M [00:02<00:08, 3.73MB/s]\n",
      " 26%|██▌       | 10.0M/38.2M [00:03<00:08, 3.69MB/s]\n",
      " 29%|██▉       | 11.0M/38.2M [00:03<00:07, 3.73MB/s]\n",
      " 31%|███▏      | 12.0M/38.2M [00:03<00:07, 3.72MB/s]\n",
      " 34%|███▍      | 13.0M/38.2M [00:03<00:07, 3.70MB/s]\n",
      " 37%|███▋      | 14.0M/38.2M [00:04<00:06, 3.69MB/s]\n",
      " 39%|███▉      | 15.0M/38.2M [00:04<00:06, 3.69MB/s]\n",
      " 42%|████▏     | 16.0M/38.2M [00:04<00:06, 3.69MB/s]\n",
      " 44%|████▍     | 17.0M/38.2M [00:05<00:06, 3.68MB/s]\n",
      " 47%|████▋     | 18.0M/38.2M [00:05<00:05, 3.65MB/s]\n",
      " 50%|████▉     | 19.0M/38.2M [00:05<00:06, 3.24MB/s]\n",
      " 52%|█████▏    | 20.0M/38.2M [00:06<00:05, 3.33MB/s]\n",
      " 55%|█████▍    | 21.0M/38.2M [00:06<00:05, 3.44MB/s]\n",
      " 58%|█████▊    | 22.0M/38.2M [00:06<00:04, 3.51MB/s]\n",
      " 60%|██████    | 23.0M/38.2M [00:06<00:04, 3.56MB/s]\n",
      " 63%|██████▎   | 24.0M/38.2M [00:07<00:04, 3.60MB/s]\n",
      " 65%|██████▌   | 25.0M/38.2M [00:07<00:03, 3.62MB/s]\n",
      " 68%|██████▊   | 26.0M/38.2M [00:07<00:03, 3.64MB/s]\n",
      " 71%|███████   | 27.0M/38.2M [00:08<00:03, 3.66MB/s]\n",
      " 73%|███████▎  | 28.0M/38.2M [00:08<00:02, 3.67MB/s]\n",
      " 76%|███████▌  | 29.0M/38.2M [00:08<00:02, 3.67MB/s]\n",
      " 78%|███████▊  | 30.0M/38.2M [00:08<00:02, 3.67MB/s]\n",
      " 81%|████████  | 31.0M/38.2M [00:09<00:02, 3.66MB/s]\n",
      " 84%|████████▎ | 32.0M/38.2M [00:09<00:01, 3.66MB/s]\n",
      " 86%|████████▋ | 33.0M/38.2M [00:09<00:01, 3.66MB/s]\n",
      " 89%|████████▉ | 34.0M/38.2M [00:10<00:01, 3.66MB/s]\n",
      " 92%|█████████▏| 35.0M/38.2M [00:10<00:00, 3.66MB/s]\n",
      " 94%|█████████▍| 36.0M/38.2M [00:10<00:00, 3.65MB/s]\n",
      " 97%|█████████▋| 37.0M/38.2M [00:11<00:00, 3.23MB/s]\n",
      " 99%|█████████▉| 38.0M/38.2M [00:11<00:00, 3.30MB/s]\n",
      "100%|██████████| 38.2M/38.2M [00:11<00:00, 3.50MB/s]\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./data/usa-real-estate-dataset.zip'):\n",
    "    print('File does not exist, downloading...')\n",
    "    !kaggle datasets download -d ahmedshahriarsakib/usa-real-estate-dataset -p ./data\n",
    "    !unzip -o ./data/usa-real-estate-dataset.zip -d ./data\n",
    "else:\n",
    "    print('File exists, skipping download...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tabular_data', 'text_data', 'usa-real-estate-dataset']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, listdir, filenames in os.walk('./data'):  \n",
    "    if listdir: print(listdir)\n",
    "    # for filename in filenames:  \n",
    "    #    print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "461236ec-e77e-4142-89c4-bfcc8452be03",
    "_uuid": "4c38b394-b3a6-4983-8d75-3882b67a74ef",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-05-06T10:56:29.034033Z",
     "iopub.status.busy": "2025-05-06T10:56:29.033720Z",
     "iopub.status.idle": "2025-05-06T10:56:29.038781Z",
     "shell.execute_reply": "2025-05-06T10:56:29.037926Z",
     "shell.execute_reply.started": "2025-05-06T10:56:29.034012Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tabular_data_dir = 'data/tabular_data'\n",
    "text_data_dir = 'data/text_data'\n",
    "raw_data_path = 'data/usa-real-estate-dataset/realtor-data.zip.csv'\n",
    "\n",
    "os.makedirs(tabular_data_dir, exist_ok=True)\n",
    "os.makedirs(text_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## [1] Load and Inspect the raw dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2226382, 12)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(raw_data_path, low_memory=False)\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brokered_by</th>\n",
       "      <th>status</th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>prev_sold_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103378.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1962661.0</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>601.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52707.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1902874.0</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>601.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103379.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1404990.0</td>\n",
       "      <td>Juana Diaz</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>795.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31239.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1947675.0</td>\n",
       "      <td>Ponce</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>731.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34632.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>331151.0</td>\n",
       "      <td>Mayaguez</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>680.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brokered_by    status     price  bed  bath  acre_lot     street  \\\n",
       "0     103378.0  for_sale  105000.0  3.0   2.0      0.12  1962661.0   \n",
       "1      52707.0  for_sale   80000.0  4.0   2.0      0.08  1902874.0   \n",
       "2     103379.0  for_sale   67000.0  2.0   1.0      0.15  1404990.0   \n",
       "3      31239.0  for_sale  145000.0  4.0   2.0      0.10  1947675.0   \n",
       "4      34632.0  for_sale   65000.0  6.0   2.0      0.05   331151.0   \n",
       "\n",
       "         city        state  zip_code  house_size prev_sold_date  \n",
       "0    Adjuntas  Puerto Rico     601.0       920.0            NaN  \n",
       "1    Adjuntas  Puerto Rico     601.0      1527.0            NaN  \n",
       "2  Juana Diaz  Puerto Rico     795.0       748.0            NaN  \n",
       "3       Ponce  Puerto Rico     731.0      1800.0            NaN  \n",
       "4    Mayaguez  Puerto Rico     680.0         NaN            NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2226382 entries, 0 to 2226381\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   brokered_by     float64\n",
      " 1   status          object \n",
      " 2   price           float64\n",
      " 3   bed             float64\n",
      " 4   bath            float64\n",
      " 5   acre_lot        float64\n",
      " 6   street          float64\n",
      " 7   city            object \n",
      " 8   state           object \n",
      " 9   zip_code        float64\n",
      " 10  house_size      float64\n",
      " 11  prev_sold_date  object \n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 203.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brokered_by</th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.221849e+06</td>\n",
       "      <td>2.224841e+06</td>\n",
       "      <td>1.745065e+06</td>\n",
       "      <td>1.714611e+06</td>\n",
       "      <td>1.900793e+06</td>\n",
       "      <td>2.215516e+06</td>\n",
       "      <td>2.226083e+06</td>\n",
       "      <td>1.657898e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.293989e+04</td>\n",
       "      <td>5.241955e+05</td>\n",
       "      <td>3.275841e+00</td>\n",
       "      <td>2.496440e+00</td>\n",
       "      <td>1.522303e+01</td>\n",
       "      <td>1.012325e+06</td>\n",
       "      <td>5.218668e+04</td>\n",
       "      <td>2.714471e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.064275e+04</td>\n",
       "      <td>2.138893e+06</td>\n",
       "      <td>1.567274e+00</td>\n",
       "      <td>1.652573e+00</td>\n",
       "      <td>7.628238e+02</td>\n",
       "      <td>5.837635e+05</td>\n",
       "      <td>2.895408e+04</td>\n",
       "      <td>8.081635e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.386100e+04</td>\n",
       "      <td>1.650000e+05</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.500000e-01</td>\n",
       "      <td>5.063128e+05</td>\n",
       "      <td>2.961700e+04</td>\n",
       "      <td>1.300000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.288400e+04</td>\n",
       "      <td>3.250000e+05</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.600000e-01</td>\n",
       "      <td>1.012766e+06</td>\n",
       "      <td>4.838200e+04</td>\n",
       "      <td>1.760000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.918300e+04</td>\n",
       "      <td>5.500000e+05</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>9.800000e-01</td>\n",
       "      <td>1.521173e+06</td>\n",
       "      <td>7.807000e+04</td>\n",
       "      <td>2.413000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.101420e+05</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>4.730000e+02</td>\n",
       "      <td>8.300000e+02</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>2.001357e+06</td>\n",
       "      <td>9.999900e+04</td>\n",
       "      <td>1.040400e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        brokered_by         price           bed          bath      acre_lot  \\\n",
       "count  2.221849e+06  2.224841e+06  1.745065e+06  1.714611e+06  1.900793e+06   \n",
       "mean   5.293989e+04  5.241955e+05  3.275841e+00  2.496440e+00  1.522303e+01   \n",
       "std    3.064275e+04  2.138893e+06  1.567274e+00  1.652573e+00  7.628238e+02   \n",
       "min    0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
       "25%    2.386100e+04  1.650000e+05  3.000000e+00  2.000000e+00  1.500000e-01   \n",
       "50%    5.288400e+04  3.250000e+05  3.000000e+00  2.000000e+00  2.600000e-01   \n",
       "75%    7.918300e+04  5.500000e+05  4.000000e+00  3.000000e+00  9.800000e-01   \n",
       "max    1.101420e+05  2.147484e+09  4.730000e+02  8.300000e+02  1.000000e+05   \n",
       "\n",
       "             street      zip_code    house_size  \n",
       "count  2.215516e+06  2.226083e+06  1.657898e+06  \n",
       "mean   1.012325e+06  5.218668e+04  2.714471e+03  \n",
       "std    5.837635e+05  2.895408e+04  8.081635e+05  \n",
       "min    0.000000e+00  0.000000e+00  4.000000e+00  \n",
       "25%    5.063128e+05  2.961700e+04  1.300000e+03  \n",
       "50%    1.012766e+06  4.838200e+04  1.760000e+03  \n",
       "75%    1.521173e+06  7.807000e+04  2.413000e+03  \n",
       "max    2.001357e+06  9.999900e+04  1.040400e+09  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>prev_sold_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2226382</td>\n",
       "      <td>2224975</td>\n",
       "      <td>2226374</td>\n",
       "      <td>1492085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>20098</td>\n",
       "      <td>55</td>\n",
       "      <td>14954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>for_sale</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2022-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1389306</td>\n",
       "      <td>23862</td>\n",
       "      <td>249432</td>\n",
       "      <td>17171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          status     city    state prev_sold_date\n",
       "count    2226382  2224975  2226374        1492085\n",
       "unique         3    20098       55          14954\n",
       "top     for_sale  Houston  Florida     2022-03-31\n",
       "freq     1389306    23862   249432          17171"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## [2] Clean and Prepare the dataset\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Check for any inconsistencies following these steps:\n",
    "\n",
    "1. Convert columns to correct data types that reduce the data size\n",
    "2. Check for duplicate records\n",
    "3. Check for outliers using utility function (using Z-score)\n",
    "4. Check negative values\n",
    "5. Handle missing values\n",
    "6. Use utility function to reduce the size.\n",
    "7. Seperate the data with unknown label in a sheet for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Handle features types\n",
    "\n",
    "Convert columns to correct data types that reduce the data size.\n",
    "- Some columns are floats but they should be strings (e.g. `brokered_by`, `street`, `zip_code`)\n",
    "- Some columns are strings but they should be datetime (e.g `prev_sold_date`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brokered_by'] = df['brokered_by'].astype('str').str.replace('.0','').replace('nan', np.NAN)\n",
    "df['zip_code'] = df['zip_code'].astype('str').str.replace('.0','').replace('nan', np.NAN)\n",
    "df['street'] = df['street'].astype('str').str.replace('.0','').replace('nan', np.NAN)\n",
    "\n",
    "df['prev_sold_date'] = pd.to_datetime(df['prev_sold_date'],format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1492083 entries, 0 to 1492082\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count    Dtype         \n",
      "---  ------          --------------    -----         \n",
      " 0   brokered_by     1488471 non-null  object        \n",
      " 1   status          1492083 non-null  object        \n",
      " 2   price           1491583 non-null  float64       \n",
      " 3   bed             1336443 non-null  float64       \n",
      " 4   bath            1329987 non-null  float64       \n",
      " 5   acre_lot        1297484 non-null  float64       \n",
      " 6   street          1486855 non-null  object        \n",
      " 7   city            1491745 non-null  object        \n",
      " 8   state           1492083 non-null  object        \n",
      " 9   zip_code        1492055 non-null  object        \n",
      " 10  house_size      1269124 non-null  float64       \n",
      " 11  prev_sold_date  1492083 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(5), object(6)\n",
      "memory usage: 136.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check Duplicate Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11811"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers_zscore(df, threshold=3):\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "    outliers = {}\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        z_scores = np.abs((df[col] - df[col].mean()) / df[col].std())\n",
    "        outliers[col] = len(z_scores[z_scores > threshold])\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'feature': outliers.keys(),\n",
    "        'num_outliers': outliers.values(),\n",
    "        'percent_outliers (%)': (np.array(list(outliers.values()))) / len(df) * 100\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>num_outliers</th>\n",
       "      <th>percent_outliers (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>price</td>\n",
       "      <td>10381</td>\n",
       "      <td>0.763114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bed</td>\n",
       "      <td>9783</td>\n",
       "      <td>0.719155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bath</td>\n",
       "      <td>13997</td>\n",
       "      <td>1.028929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acre_lot</td>\n",
       "      <td>629</td>\n",
       "      <td>0.046238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>house_size</td>\n",
       "      <td>1136</td>\n",
       "      <td>0.083508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  num_outliers  percent_outliers (%)\n",
       "0       price         10381              0.763114\n",
       "1         bed          9783              0.719155\n",
       "2        bath         13997              1.028929\n",
       "3    acre_lot           629              0.046238\n",
       "4  house_size          1136              0.083508"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_outliers_zscore(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Observations**\n",
    "\n",
    "- The feature  `price` has *8601* outliers, which is 0.58% of the total data.\n",
    "- The feature  `acre_lot` has 551 outliers, which is 0.04% of the total data.\n",
    "- The feature  `house_size` has 107 outliers, which is 0.01% of the total data.\n",
    "- The feature  `bed` and`bath` have no outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Check for Negative Values\n",
    "\n",
    "Some features, such as `price`, `bed`, `bath`, `acre_lot`, and `house_size`, are not supposed to have negative values. I will check for any negative values in these columns and handle them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'bed', 'bath', 'acre_lot', 'house_size'], dtype='object')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.select_dtypes(include='number').columns\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values found in column bed\n",
      "bed\n",
      "-68     0.4\n",
      "-66     0.2\n",
      "-44     0.2\n",
      "-108    0.2\n",
      "Name: proportion, dtype: float64\n",
      "Negative values found in column bath\n",
      "bath\n",
      "-34    0.333333\n",
      "-58    0.166667\n",
      "-93    0.166667\n",
      "-44    0.166667\n",
      "-81    0.166667\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for col in features:\n",
    "    if (df[col]<0).any():\n",
    "        print(f\"Negative values found in column {col}\")\n",
    "        print(df.loc[df[col]<0, col].value_counts(normalize=True).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NO negative values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>num_missing</th>\n",
       "      <th>percent_missing</th>\n",
       "      <th>num_unique</th>\n",
       "      <th>most_common</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prev_sold_date</td>\n",
       "      <td>734297</td>\n",
       "      <td>32.981627</td>\n",
       "      <td>14954</td>\n",
       "      <td>2022-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>house_size</td>\n",
       "      <td>568484</td>\n",
       "      <td>25.533983</td>\n",
       "      <td>12061</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bath</td>\n",
       "      <td>511771</td>\n",
       "      <td>22.986666</td>\n",
       "      <td>86</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bed</td>\n",
       "      <td>481317</td>\n",
       "      <td>21.618797</td>\n",
       "      <td>99</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acre_lot</td>\n",
       "      <td>325589</td>\n",
       "      <td>14.624130</td>\n",
       "      <td>16057</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>street</td>\n",
       "      <td>10866</td>\n",
       "      <td>0.488056</td>\n",
       "      <td>2001358</td>\n",
       "      <td>1916862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>brokered_by</td>\n",
       "      <td>4533</td>\n",
       "      <td>0.203604</td>\n",
       "      <td>110143</td>\n",
       "      <td>22611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>price</td>\n",
       "      <td>1541</td>\n",
       "      <td>0.069215</td>\n",
       "      <td>102137</td>\n",
       "      <td>350000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>city</td>\n",
       "      <td>1407</td>\n",
       "      <td>0.063197</td>\n",
       "      <td>20098</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zip_code</td>\n",
       "      <td>299</td>\n",
       "      <td>0.013430</td>\n",
       "      <td>30334</td>\n",
       "      <td>33993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>state</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>55</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  num_missing  percent_missing  num_unique most_common\n",
       "0   prev_sold_date       734297        32.981627       14954  2022-03-31\n",
       "1       house_size       568484        25.533983       12061      1200.0\n",
       "2             bath       511771        22.986666          86         2.0\n",
       "3              bed       481317        21.618797          99         3.0\n",
       "4         acre_lot       325589        14.624130       16057        0.17\n",
       "5           street        10866         0.488056     2001358   1916862.0\n",
       "6      brokered_by         4533         0.203604      110143     22611.0\n",
       "7            price         1541         0.069215      102137    350000.0\n",
       "8             city         1407         0.063197       20098     Houston\n",
       "9         zip_code          299         0.013430       30334     33993.0\n",
       "10           state            8         0.000359          55     Florida"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Some Columns**\n",
    "\n",
    "- `prev_sold_date`: Irrelavant column with 32% missing values\n",
    "- `street`: Encoded Categorical Column without benefits.\n",
    "- `brokered_by`: Encoded Categorical Column without benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['prev_sold_date', 'street', 'brokered_by'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop rows with `state`, `city`, or `street` missing**\n",
    "\n",
    "Tiny amount of missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values: 0.14%\n"
     ]
    }
   ],
   "source": [
    "null_condition = df[['state', 'city', 'price', 'zip_code']].isna().any(axis=1)\n",
    "\n",
    "missing_percentage = len(df[null_condition]) * 100 / len(df)\n",
    "print(f\"Percentage of missing values: {missing_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Drop 0.14% of the dataset, it is not a big deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape after removing nulls: (2223239, 9)\n"
     ]
    }
   ],
   "source": [
    "df = df[~null_condition]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f\"DataFrame shape after removing nulls: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill numerical features with `-1`**\n",
    "\n",
    "I will handle this in the process of converting to natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values: 38.81%\n"
     ]
    }
   ],
   "source": [
    "null_condition = df[['bath', 'bed', 'acre_lot', 'house_size']].isna().any(axis=1)\n",
    "\n",
    "missing_percentage = len(df[null_condition]) * 100 / len(df)\n",
    "print(f\"Percentage of missing values: {missing_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Cannot remove 38% of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bath'].fillna(-1, inplace=True)\n",
    "df['bed'].fillna(-1, inplace=True)\n",
    "df['acre_lot'].fillna(-1, inplace=True)\n",
    "df['house_size'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For Future Work, we can use iterative imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has no missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduce data size of `bath` and `bed`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found negative vlues in bath and acre_lot columns\n",
    "df['bath'] = df['bath'].astype('int8')\n",
    "df['bed'] = df['bed'].astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Memory size reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage reduced to 89.05 MB (27.6% reduction)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for_sale</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>601.0</td>\n",
       "      <td>920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for_sale</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.08</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>601.0</td>\n",
       "      <td>1527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for_sale</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>Juana Diaz</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>795.0</td>\n",
       "      <td>748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for_sale</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Ponce</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>731.0</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for_sale</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Mayaguez</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>680.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223234</th>\n",
       "      <td>sold</td>\n",
       "      <td>359900.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Richland</td>\n",
       "      <td>Washington</td>\n",
       "      <td>99354.0</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223235</th>\n",
       "      <td>sold</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Richland</td>\n",
       "      <td>Washington</td>\n",
       "      <td>99354.0</td>\n",
       "      <td>1616.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223236</th>\n",
       "      <td>sold</td>\n",
       "      <td>440000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Richland</td>\n",
       "      <td>Washington</td>\n",
       "      <td>99354.0</td>\n",
       "      <td>3200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223237</th>\n",
       "      <td>sold</td>\n",
       "      <td>179900.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09</td>\n",
       "      <td>Richland</td>\n",
       "      <td>Washington</td>\n",
       "      <td>99354.0</td>\n",
       "      <td>933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223238</th>\n",
       "      <td>sold</td>\n",
       "      <td>580000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Richland</td>\n",
       "      <td>Washington</td>\n",
       "      <td>99354.0</td>\n",
       "      <td>3615.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2223239 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           status     price  bed  bath  acre_lot        city        state  \\\n",
       "0        for_sale  105000.0    3     2      0.12    Adjuntas  Puerto Rico   \n",
       "1        for_sale   80000.0    4     2      0.08    Adjuntas  Puerto Rico   \n",
       "2        for_sale   67000.0    2     1      0.15  Juana Diaz  Puerto Rico   \n",
       "3        for_sale  145000.0    4     2      0.10       Ponce  Puerto Rico   \n",
       "4        for_sale   65000.0    6     2      0.05    Mayaguez  Puerto Rico   \n",
       "...           ...       ...  ...   ...       ...         ...          ...   \n",
       "2223234      sold  359900.0    4     2      0.33    Richland   Washington   \n",
       "2223235      sold  350000.0    3     2      0.10    Richland   Washington   \n",
       "2223236      sold  440000.0    6     3      0.50    Richland   Washington   \n",
       "2223237      sold  179900.0    2     1      0.09    Richland   Washington   \n",
       "2223238      sold  580000.0    5     3      0.31    Richland   Washington   \n",
       "\n",
       "         zip_code  house_size  \n",
       "0           601.0       920.0  \n",
       "1           601.0      1527.0  \n",
       "2           795.0       748.0  \n",
       "3           731.0      1800.0  \n",
       "4           680.0        -1.0  \n",
       "...           ...         ...  \n",
       "2223234   99354.0      3600.0  \n",
       "2223235   99354.0      1616.0  \n",
       "2223236   99354.0      3200.0  \n",
       "2223237   99354.0       933.0  \n",
       "2223238   99354.0      3615.0  \n",
       "\n",
       "[2223239 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Memory usage reduced from 203.8 MB to 113.95 MB (44% reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save sheets for train/val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "df_shuffled = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "split_index = int(0.99 * len(df_shuffled)) # Define split size\n",
    "\n",
    "# Split train data to train and validation with 99/1 ratio\n",
    "train_data = df_shuffled[:split_index]\n",
    "val_data = df_shuffled[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (2201006, 9), Val data shape: (22233, 9)\n"
     ]
    }
   ],
   "source": [
    "train_data.reset_index(drop=True, inplace=True)\n",
    "val_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Train data shape: {train_data.shape}, Val data shape: {val_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# release memory  \n",
    "del df_shuffled, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train, validation, and test data\n",
    "train_data.to_csv(f'{tabular_data_dir}/train_data.csv', index=False)\n",
    "val_data.to_csv(f'{tabular_data_dir}/val_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## [3] Prepare Data for LLM Fine-Tuning\n",
    "---\n",
    "1. Convert the tabular data to natural language datasets in josnl (json list) format.\n",
    "2. Save the text data for fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data for LLM fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "properties": {
        "estimated_house_price": {
         "description": "Numerical value that expresses the estimated house price",
         "example": 85000,
         "title": "Estimated House Price",
         "type": "number"
        }
       },
       "required": [
        "estimated_house_price"
       ],
       "title": "ResponseSchema",
       "type": "object"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import JSON, Markdown\n",
    "\n",
    "class ResponseSchema(BaseModel):\n",
    "    estimated_house_price: float = Field(...,\n",
    "                                description=\"Numerical value that expresses the estimated house price\",\n",
    "                                example=85000.0)\n",
    "\n",
    "JSON(ResponseSchema.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"estimated_house_price\":2510010.0}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResponseSchema(estimated_house_price=2510010.0).model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_val(raw, col):\n",
    "    val = raw[col]\n",
    "    if val  == -1:\n",
    "        return 'missing info'\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_data(row, idx):\n",
    "\n",
    "    description = \"\\n\".join([   \n",
    "        \"A house listing in the USA with the following details:\\n\" ,\n",
    "        f\"- Status: {row['status']}\\n\",\n",
    "        f\"- Number of bedrooms: {row['bed']}\\n\",\n",
    "        f\"- Number of bathrooms: {row['bath']}\\n\",\n",
    "        f\"- Land size: {row['acre_lot']} acres\\n\",\n",
    "        f\"- Address (city, state, zip): {row['city']}, {row['state']}, {row['zip_code']}\\n\"\n",
    "        f\"- House size: {row['house_size']} sqft\\n\",\n",
    "        \"Your task is to predict the final sale price in $?\",\n",
    "        \"### Output schema:\",\n",
    "        f\"{ResponseSchema.model_json_schema()}\",\n",
    "        \"### Response: \\n ```json\"\n",
    "    ])\n",
    "        \n",
    "    return {\n",
    "        \"id\": idx,\n",
    "        \"query\": description,\n",
    "        \"response\": ResponseSchema(estimated_house_price=row['price']).model_dump_json()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.utils import timeit\n",
    "\n",
    "@timeit\n",
    "def translate_all_rows(df):\n",
    "    text_data = []\n",
    "    bar_format = '{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'\n",
    "    for idx, row in tqdm(df.iterrows(),\n",
    "                         total=len(df), unit=\"sample\",\n",
    "                         ncols=100, colour='green',\n",
    "                         desc=\"Translating tabular data to text\",\n",
    "                         bar_format=bar_format):\n",
    "        \n",
    "        translated_text = translate_data(row, idx)\n",
    "        text_data.append(translated_text)\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate train dataset to natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating tabular data to text:   0%|\u001b[32m                                        \u001b[0m| 0/2201006 [00:00<?]\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating tabular data to text: 100%|\u001b[32m██████████████████████████████\u001b[0m| 2201006/2201006 [23:11<00:00]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data completed in 23.21 minutes.\n"
     ]
    }
   ],
   "source": [
    "text_train_data = translate_all_rows(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Data Length:  2201006\n",
      "Sample:  \n",
      " {'id': 0, 'query': \"A house listing in the USA with the following details:\\n\\n- Status: for_sale\\n\\n- Number of bedrooms: -1\\n\\n- Number of bathrooms: -1\\n\\n- Land size: 0.7300000190734863 acres\\n\\n- Address (city, state, zip): Port Aransas, Texas, 78373.0\\n- House size: -1.0 sqft\\n\\nYour task is to predict the final sale price in $?\\n### Output schema:\\n{'properties': {'estimated_house_price': {'description': 'Numerical value that expresses the estimated house price', 'example': 85000.0, 'title': 'Estimated House Price', 'type': 'number'}}, 'required': ['estimated_house_price'], 'title': 'ResponseSchema', 'type': 'object'}\\n### Response: \\n ```json\", 'response': '{\"estimated_house_price\":295000.0}'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Tabular Data Length\", train_data.shape)\n",
    "print(\"Text Data Length: \", len(text_train_data))\n",
    "print(\"Sample:  \\n\", text_train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate Validation dataset to natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating tabular data to text: 100%|\u001b[32m██████████████████████████████████\u001b[0m| 22233/22233 [00:11<00:00]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data completed in 0.18 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_val_data = translate_all_rows(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular Data Length (22233, 9)\n",
      "Text Data Length:  22233\n",
      "Sample:  \n",
      " {'id': 0, 'query': \"A house listing in the USA with the following details:\\n\\n- Status: for_sale\\n\\n- Number of bedrooms: -1\\n\\n- Number of bathrooms: -1\\n\\n- Land size: 0.07000000029802322 acres\\n\\n- Address (city, state, zip): Washington, District of Columbia, 20002.0\\n- House size: -1.0 sqft\\n\\nYour task is to predict the final sale price in $?\\n### Output schema:\\n{'properties': {'estimated_house_price': {'description': 'Numerical value that expresses the estimated house price', 'example': 85000.0, 'title': 'Estimated House Price', 'type': 'number'}}, 'required': ['estimated_house_price'], 'title': 'ResponseSchema', 'type': 'object'}\\n### Response: \\n ```json\", 'response': '{\"estimated_house_price\":2500000.0}'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Tabular Data Length\", val_data.shape)\n",
    "print(\"Text Data Length: \", len(text_val_data))\n",
    "print(\"Sample:  \\n\", text_val_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4419"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Release un-needed variables from memory\n",
    "del train_data, val_data \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## [4] Upload data to Huggingface Hub\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "username = \"heba1998\"\n",
    "data_title = \"Real Estate Data For LLM Fine-Tuning\"\n",
    "repo_name = data_title.replace(\" \", \"-\").lower()\n",
    "date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "metadata = {\n",
    "    \"title\": data_title,\n",
    "    \"id\": f\"{username}/{repo_name}\",\n",
    "    \"licenses\": [{\"name\": \"CC0-1.0\"}],\n",
    "    \"description\": \"Translated Text data generated from tabular US real estate data for LLM fine-tuning\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"created_at\": date,\n",
    "    \"tags\": [\n",
    "        \"LLM\",\n",
    "        \"Text Data\",\n",
    "        \"Real Estate\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f'{text_data_dir}/text_train_data.jsonl', 'w') as json_file:\n",
    "    json.dump(text_train_data, json_file, indent=4)\n",
    "\n",
    "with open(f'{text_data_dir}/text_val_data.jsonl', 'w') as json_file:\n",
    "    json.dump(text_val_data, json_file, indent=4)\n",
    "    \n",
    "with open(f'{text_data_dir}/dataset-metadata.json', 'w') as json_file:\n",
    "    json.dump(metadata, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data will upload to Huggingface Hub in order to be used with the tiny LLM model via colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Log in to Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "huggingface_hub.login(os.getenv(\"HF_TOKEN\"))\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define repository details**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "text_data_dir = \"data/text_data\"\n",
    "with open(f'{text_data_dir}/text_val_data.jsonl', 'r') as json_file:\n",
    "    text_val_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_50 = text_val_data[:50]\n",
    "with open(f'{text_data_dir}/sample_50.jsonl', 'w') as json_file:\n",
    "    json.dump(sample_50, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/heba1998/real-estate-data-for-llm-fine-tuning/commit/f5b76d66c88709faf45be0e43ba27808a0f8c03a', commit_message='Add sample_50.jsonl file', commit_description='', oid='f5b76d66c88709faf45be0e43ba27808a0f8c03a', pr_url='https://huggingface.co/datasets/heba1998/real-estate-data-for-llm-fine-tuning/discussions/2', repo_url=RepoUrl('https://huggingface.co/datasets/heba1998/real-estate-data-for-llm-fine-tuning', endpoint='https://huggingface.co', repo_type='dataset', repo_id='heba1998/real-estate-data-for-llm-fine-tuning'), pr_revision='refs/pr/2', pr_num=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = \"heba1998\"\n",
    "data_title = \"Real Estate Data For LLM Fine-Tuning\"\n",
    "repo_name = data_title.replace(\" \", \"-\").lower()\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=f\"{text_data_dir}/sample_50.jsonl\",\n",
    "    repo_id=f\"{username}/{repo_name}\",\n",
    "    repo_type=\"dataset\",\n",
    "    create_pr=True,\n",
    "    path_in_repo=\"sample_50.jsonl\",\n",
    "    commit_message=\"Add sample_50.jsonl file\",\n",
    "    revision=\"main\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "text_train_data.jsonl:   0%|          | 0.00/1.66G [00:00<?, ?B/s]'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/bf/77/bf775231d95a7a83e0137e6940f880f969999cde9bab280e791fc89b1370e3b9/e748311cae4b68cf9b8bd9813f2e2e1fb97d15ad89d31d273fa17e56e884d72b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250507%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250507T040539Z&X-Amz-Expires=86400&X-Amz-Signature=98d2829d4c24c6255e44adc0e4cdebe7ac182d3455e47544253b00a358f655e0&X-Amz-SignedHeaders=host&partNumber=1&uploadId=KjrS5ZZXOoDP7C24n9KG_EAbneCKmhxD9kHgrvav3RE35EAAofe6QUTkiEP_QwOXu6GZSCVU2V99RSuyI9b6rJagdTeTTw172mO09MLsmYEs16ooLU2gQOo7kvCsQtPW&x-id=UploadPart (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1010)')))\"), '(Request ID: 47135c61-3fd1-4c27-af2d-c3f6f004755c)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/bf/77/bf775231d95a7a83e0137e6940f880f969999cde9bab280e791fc89b1370e3b9/e748311cae4b68cf9b8bd9813f2e2e1fb97d15ad89d31d273fa17e56e884d72b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250507%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250507T040539Z&X-Amz-Expires=86400&X-Amz-Signature=98d2829d4c24c6255e44adc0e4cdebe7ac182d3455e47544253b00a358f655e0&X-Amz-SignedHeaders=host&partNumber=1&uploadId=KjrS5ZZXOoDP7C24n9KG_EAbneCKmhxD9kHgrvav3RE35EAAofe6QUTkiEP_QwOXu6GZSCVU2V99RSuyI9b6rJagdTeTTw172mO09MLsmYEs16ooLU2gQOo7kvCsQtPW&x-id=UploadPart\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/bf/77/bf775231d95a7a83e0137e6940f880f969999cde9bab280e791fc89b1370e3b9/7852a95b95de74ea8674691044021fe66b62eddb5da00e402da5f7b8ce44ebda?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250507%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250507T040539Z&X-Amz-Expires=86400&X-Amz-Signature=ba174724901ff474bb40f96a7dc605ca15819c628d55c13038ac58b5218b4160&X-Amz-SignedHeaders=host&partNumber=1&uploadId=KASJ6ruqvbdrHEn2ZXjuJoVr9dr4BT5.pvhnvArZmAjyc5EMPwU6q0PoJ7C.lEm5nLOMYFOHR7wVPwnasEBrLNRwt0N0aBaKYdlK5hGIRQI50Oatz3SfXvSs352Z3MQQ&x-id=UploadPart (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1010)')))\"), '(Request ID: 8e21b12f-81fa-4871-ba00-5ca951d71278)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/bf/77/bf775231d95a7a83e0137e6940f880f969999cde9bab280e791fc89b1370e3b9/7852a95b95de74ea8674691044021fe66b62eddb5da00e402da5f7b8ce44ebda?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250507%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250507T040539Z&X-Amz-Expires=86400&X-Amz-Signature=ba174724901ff474bb40f96a7dc605ca15819c628d55c13038ac58b5218b4160&X-Amz-SignedHeaders=host&partNumber=1&uploadId=KASJ6ruqvbdrHEn2ZXjuJoVr9dr4BT5.pvhnvArZmAjyc5EMPwU6q0PoJ7C.lEm5nLOMYFOHR7wVPwnasEBrLNRwt0N0aBaKYdlK5hGIRQI50Oatz3SfXvSs352Z3MQQ&x-id=UploadPart\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Retrying in 1s [Retry 1/5].\n",
      "text_val_data.jsonl: 100%|██████████| 16.7M/16.7M [01:50<00:00, 151kB/s]B/s]  \n",
      "text_train_data.jsonl:  30%|███       | 503M/1.66G [25:06<53:20, 361kB/s]   "
     ]
    }
   ],
   "source": [
    "# Upload dir\n",
    "username = \"heba1998\"\n",
    "api.upload_folder(\n",
    "    folder_path=text_data_dir,\n",
    "    repo_id=f\"{username}/{repo_name}\",\n",
    "    repo_type=\"dataset\",\n",
    "    create_pr=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3202774,
     "sourceId": 7981839,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 238138033,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
