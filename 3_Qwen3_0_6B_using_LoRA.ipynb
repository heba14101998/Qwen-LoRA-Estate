{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZU5_1OLopMUy"
   },
   "source": [
    "---\n",
    "## Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4v0D3WgVvB8"
   },
   "source": [
    "### **Install Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yj6qTXvPpwyk",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -qU transformers==4.48.3 datasets==3.2.0 optimum==1.24.0 \n",
    "!pip install wandb huggingface_hub[hf_xet]\n",
    "!pip install -qU json-repair==0.29.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hi0hW8Tbi5H"
   },
   "source": [
    "### **Install LLaMA-Factory**\n",
    "\n",
    "To **install the current project (like LLaMA-Factory)** in **development mode** with **extra features** (like GPU support and 8-bit training), so we can:\n",
    "* Edit the code locally and use it without reinstalling.\n",
    "* Start fine-tuning immediately\n",
    "* Customize the training pipeline\n",
    "> I followed the [installation documentation](https://llamafactory.readthedocs.io/en/latest/getting_started/installation.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-08T22:37:33.932474Z",
     "iopub.status.busy": "2025-05-08T22:37:33.932199Z",
     "iopub.status.idle": "2025-05-08T22:37:35.665269Z",
     "shell.execute_reply": "2025-05-08T22:37:35.664573Z",
     "shell.execute_reply.started": "2025-05-08T22:37:33.932451Z"
    },
    "id": "ywDTvfx_ZHpc",
    "outputId": "0f071963-827f-4414-840d-b888602a8bf7",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "Cloning into 'LLaMA-Factory'...\n",
      "remote: Enumerating objects: 357, done.\u001b[K\n",
      "remote: Counting objects: 100% (357/357), done.\u001b[K\n",
      "remote: Compressing objects: 100% (276/276), done.\u001b[K\n",
      "remote: Total 357 (delta 76), reused 304 (delta 66), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (357/357), 9.64 MiB | 31.06 MiB/s, done.\n",
      "Resolving deltas: 100% (76/76), done.\n",
      "/kaggle/working/LLaMA-Factory\n",
      "\u001b[0m\u001b[01;34massets\u001b[0m/       \u001b[01;34mevaluation\u001b[0m/  MANIFEST.in     requirements.txt  \u001b[01;34mtests\u001b[0m/\n",
      "CITATION.cff  \u001b[01;34mexamples\u001b[0m/    pyproject.toml  \u001b[01;34mscripts\u001b[0m/\n",
      "\u001b[01;34mdata\u001b[0m/         LICENSE      README.md       setup.py\n",
      "\u001b[01;34mdocker\u001b[0m/       Makefile     README_zh.md    \u001b[01;34msrc\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/\n",
    "!rm -rf LLaMA-Factory\n",
    "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
    "%cd LLaMA-Factory\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-09T01:50:52.010605Z",
     "iopub.status.busy": "2025-05-09T01:50:52.010343Z",
     "iopub.status.idle": "2025-05-09T01:51:02.355598Z",
     "shell.execute_reply": "2025-05-09T01:51:02.354670Z",
     "shell.execute_reply.started": "2025-05-09T01:50:52.010588Z"
    },
    "id": "ZxkjVnu8bi5H",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "acb07cdc-b6a9-4ba4-db05-6d455dfd9746",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/LLaMA-Factory\n",
      "Obtaining file:///kaggle/working/LLaMA-Factory\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (4.51.3)\n",
      "Requirement already satisfied: datasets<=3.5.0,>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (3.5.0)\n",
      "Requirement already satisfied: accelerate<=1.6.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (1.3.0)\n",
      "Requirement already satisfied: peft<=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.14.0)\n",
      "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.9.6)\n",
      "Requirement already satisfied: tokenizers<=0.21.1,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.21.0)\n",
      "Requirement already satisfied: gradio<=5.25.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (5.25.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (1.15.2)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.8.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.2.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.9.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (3.20.3)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.34.2)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.115.12)\n",
      "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (2.3.4)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (3.7.5)\n",
      "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.7.0)\n",
      "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (2.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (6.0.2)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (1.26.4)\n",
      "Requirement already satisfied: pydantic<=2.10.6 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (2.10.6)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (2.2.3)\n",
      "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (14.3.0)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.10.2.post1)\n",
      "Requirement already satisfied: tyro<0.9.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.8.14)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (2.5.1+cu124)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (0.5.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.11.16)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (4.9.0)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.8.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.10.15)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (11.1.0)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.11.8)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (4.13.1)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (14.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0->llamafactory==0.9.3.dev0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0->llamafactory==0.9.3.dev0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0->llamafactory==0.9.3.dev0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0->llamafactory==0.9.3.dev0) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0->llamafactory==0.9.3.dev0) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0->llamafactory==0.9.3.dev0) (2.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.3.dev0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.3.dev0) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->llamafactory==0.9.3.dev0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->llamafactory==0.9.3.dev0) (2.27.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0->llamafactory==0.9.3.dev0) (2024.11.6)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory==0.9.3.dev0) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory==0.9.3.dev0) (14.0.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory==0.9.3.dev0) (1.7.2)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llamafactory==0.9.3.dev0) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llamafactory==0.9.3.dev0) (0.14.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->llamafactory==0.9.3.dev0) (2.5.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (1.1.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->llamafactory==0.9.3.dev0) (4.9.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (1.19.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.0.7)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->llamafactory==0.9.3.dev0) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->llamafactory==0.9.3.dev0) (4.3.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (2.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.3.dev0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.3.dev0) (2.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa->llamafactory==0.9.3.dev0) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.3.dev0) (1.17.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.5.4)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0->llamafactory==0.9.3.dev0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0->llamafactory==0.9.3.dev0) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0->llamafactory==0.9.3.dev0) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0.0->llamafactory==0.9.3.dev0) (2024.2.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.3.dev0) (2.22)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0.0->llamafactory==0.9.3.dev0) (2024.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.3.dev0) (0.1.2)\n",
      "Building wheels for collected packages: llamafactory\n",
      "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for llamafactory: filename=llamafactory-0.9.3.dev0-0.editable-py3-none-any.whl size=26940 sha256=fa9134c33b7ed01efc7f993da3b01ed82cdbcb27ae5ac32445023cd99e62813b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-aq46ugn9/wheels/96/d8/b2/8fc665ed70525080a50f3ff8538833c6f74cd48eb82195d0f8\n",
      "Successfully built llamafactory\n",
      "Installing collected packages: llamafactory\n",
      "  Attempting uninstall: llamafactory\n",
      "    Found existing installation: llamafactory 0.9.3.dev0\n",
      "    Uninstalling llamafactory-0.9.3.dev0:\n",
      "      Successfully uninstalled llamafactory-0.9.3.dev0\n",
      "Successfully installed llamafactory-0.9.3.dev0\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/LLaMA-Factory/\n",
    "!pip install -e . # Install LlaMaFactory in order to use LLaMA-Factory CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OY8EWXIBajYB",
    "outputId": "85eadde8-6ecc-42dd-de3b-65d56ede5f6c",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 13:38:16.502271: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746711496.720150   39276 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746711496.780438   39276 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-08 13:38:17.240307: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "----------------------------------------------------------\n",
      "| Welcome to LLaMA Factory, version 0.9.3.dev0           |\n",
      "|                                                        |\n",
      "| Project page: https://github.com/hiyouga/LLaMA-Factory |\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!GRADIO_SHARE=1\n",
    "!llamafactory-cli version # webui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T01:39:58.383338Z",
     "iopub.status.busy": "2025-05-09T01:39:58.383025Z",
     "iopub.status.idle": "2025-05-09T01:39:58.387067Z",
     "shell.execute_reply": "2025-05-09T01:39:58.386405Z",
     "shell.execute_reply.started": "2025-05-09T01:39:58.383310Z"
    },
    "id": "LUJjNWf-yYiT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import llamafactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_l-cfEqOVzuF"
   },
   "source": [
    "### **Import Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T01:40:12.761031Z",
     "iopub.status.busy": "2025-05-09T01:40:12.760765Z",
     "iopub.status.idle": "2025-05-09T01:40:12.766120Z",
     "shell.execute_reply": "2025-05-09T01:40:12.765356Z",
     "shell.execute_reply.started": "2025-05-09T01:40:12.761011Z"
    },
    "id": "mAre3Yb9TEj9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import json_repair\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUyiLlkSVfnP"
   },
   "source": [
    "### **Logins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T01:40:15.005495Z",
     "iopub.status.busy": "2025-05-09T01:40:15.005262Z",
     "iopub.status.idle": "2025-05-09T01:40:15.218589Z",
     "shell.execute_reply": "2025-05-09T01:40:15.218032Z",
     "shell.execute_reply.started": "2025-05-09T01:40:15.005479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# if using kaggle \n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "hf_token = user_secrets.get_secret(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "wandb_token = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "\n",
    "\n",
    "# uncomment if using colab\n",
    "# from google.colab import userdata\n",
    "# hf_token = userdata.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "# import kagglehub\n",
    "# from kagglehub import auth, login\n",
    "# kagglehub.login(validate_credentials=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T01:40:17.096751Z",
     "iopub.status.busy": "2025-05-09T01:40:17.096080Z",
     "iopub.status.idle": "2025-05-09T01:40:17.318589Z",
     "shell.execute_reply": "2025-05-09T01:40:17.317978Z",
     "shell.execute_reply.started": "2025-05-09T01:40:17.096726Z"
    },
    "id": "emek94Zsa9tz",
    "outputId": "b0f8b58a-ace7-409f-b2a8-46703a13afae",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "auth": {
        "accessToken": {
         "createdAt": "2025-05-06T20:44:04.749Z",
         "displayName": "fine-tune",
         "fineGrained": {
          "canReadGatedRepos": true,
          "global": [
           "discussion.write",
           "post.write"
          ],
          "scoped": [
           {
            "entity": {
             "_id": "681ada3852431b1769c74a39",
             "name": "heba1998/real-estate-data-for-llm-fine-tuning",
             "type": "dataset"
            },
            "permissions": [
             "repo.content.read",
             "discussion.write",
             "repo.write"
            ]
           },
           {
            "entity": {
             "_id": "64ce9cd07c24890fb4a7417d",
             "name": "heba1998",
             "type": "user"
            },
            "permissions": [
             "user.webhooks.read",
             "repo.content.read",
             "repo.write",
             "inference.serverless.write",
             "inference.endpoints.infer.write",
             "inference.endpoints.write",
             "user.webhooks.write",
             "collection.read",
             "collection.write",
             "discussion.write",
             "user.billing.read"
            ]
           }
          ]
         },
         "role": "fineGrained"
        },
        "type": "access_token"
       },
       "avatarUrl": "/avatars/8145446f31c46dc9df026753db8f5d9c.svg",
       "canPay": false,
       "fullname": "Heba ",
       "id": "64ce9cd07c24890fb4a7417d",
       "isPro": false,
       "name": "heba1998",
       "orgs": [],
       "periodEnd": null,
       "type": "user"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from huggingface_hub import whoami, login\n",
    "\n",
    "# or use ---> !huggingface-cli login --token {mytoken} # another method\n",
    "login(token = hf_token)\n",
    "wandb.login(key=wandb_token)\n",
    "# !chmod 600 ~/.netrc\n",
    "# !cat ~/.netrc\n",
    "\n",
    "JSON(whoami())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mount Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-08T22:52:55.462092Z",
     "iopub.status.idle": "2025-05-08T22:52:55.462382Z",
     "shell.execute_reply": "2025-05-08T22:52:55.462223Z",
     "shell.execute_reply.started": "2025-05-08T22:52:55.462212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Uncomment if you need to mount drive in kaggle\n",
    "\n",
    "# !apt-get install -y -qq software-properties-common\n",
    "# !add-apt-repository -y ppa:alessandro-strada/ppa\n",
    "# !apt-get update -qq\n",
    "# !apt-get install -y -qq google-drive-ocamlfuse\n",
    "# !pip install pydrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T22:54:39.001679Z",
     "iopub.status.busy": "2025-05-08T22:54:39.001399Z",
     "iopub.status.idle": "2025-05-08T22:54:39.037147Z",
     "shell.execute_reply": "2025-05-08T22:54:39.036598Z",
     "shell.execute_reply.started": "2025-05-08T22:54:39.001661Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Uncomment if you need to mount drive in kaggle\n",
    "\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)\n",
    "# your_client_secret='4/0AUJR-x5xn-4uLV-EY18thcr0VacO5dCgomO124Fki0c66vPG8zx_JE3bOXxmiXFFl9xhWw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13KHoOjC-PVh"
   },
   "source": [
    "### **Caching Directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T01:40:21.147677Z",
     "iopub.status.busy": "2025-05-09T01:40:21.146950Z",
     "iopub.status.idle": "2025-05-09T01:40:21.152088Z",
     "shell.execute_reply": "2025-05-09T01:40:21.151494Z",
     "shell.execute_reply.started": "2025-05-09T01:40:21.147650Z"
    },
    "id": "apFwZvBpi1wK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ['HF_HOME'] = '/kaggle/working/drive/MyDrive/llm-finetuning/hf_home'\n",
    "# FULL DATA HERE ==> /kaggle/working/drive/MyDrive/llm-finetuning/datasets_cache\n",
    "os.environ['DATASETS'] = '/kaggle/working/drive/MyDrive/llm-finetuning/datasets_samples'\n",
    "os.environ['LLAMAFACTORY_OUTPUT']= '/kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output'\n",
    "\n",
    "os.makedirs(os.environ['HF_HOME'], exist_ok=True)\n",
    "os.makedirs(os.environ['DATASETS'], exist_ok=True)\n",
    "os.makedirs(os.environ['LLAMAFACTORY_OUTPUT'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T01:40:21.614976Z",
     "iopub.status.busy": "2025-05-09T01:40:21.614725Z",
     "iopub.status.idle": "2025-05-09T01:40:21.619605Z",
     "shell.execute_reply": "2025-05-09T01:40:21.618798Z",
     "shell.execute_reply.started": "2025-05-09T01:40:21.614958Z"
    },
    "id": "D-rdnCaNlrUN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_force_compilation_parallelism=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-B1psKPpKQ9"
   },
   "source": [
    "---\n",
    "## Load Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7GkWQCm44Ne"
   },
   "source": [
    "### **Load Data From Kaggle**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ix7pknmVppL"
   },
   "source": [
    "**Download the dataset from Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "execution": {
     "iopub.execute_input": "2025-05-08T22:55:21.449333Z",
     "iopub.status.busy": "2025-05-08T22:55:21.448586Z",
     "iopub.status.idle": "2025-05-08T22:55:21.452581Z",
     "shell.execute_reply": "2025-05-08T22:55:21.451847Z",
     "shell.execute_reply.started": "2025-05-08T22:55:21.449297Z"
    },
    "id": "0L9nwgUziDkG",
    "outputId": "bbd36f67-b96e-4c3f-b009-b66a09bacbef",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Uucomment if using Colab\n",
    "\n",
    "# data_path = kagglehub.dataset_download('hebamo7amed/real-estate-data-for-llm-fine-tuning')\n",
    "# tabular_data_path = f\"{data_path}/tabular_data\"\n",
    "# text_data_path = f\"{data_path}/text_data\"\n",
    "# text_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPq5gXZvZ-5x"
   },
   "source": [
    "**Read Datasets From Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-08T00:34:06.520226Z",
     "iopub.status.busy": "2025-05-08T00:34:06.519745Z",
     "iopub.status.idle": "2025-05-08T00:34:14.176937Z",
     "shell.execute_reply": "2025-05-08T00:34:14.175779Z",
     "shell.execute_reply.started": "2025-05-08T00:34:06.520202Z"
    },
    "id": "e38k8TCHUkf6",
    "outputId": "8898662e-d654-4c3f-bfce-02c489d7bb5a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size =  2201006\n",
      "Validation data size =  22233\n",
      "Sample data size =  50\n"
     ]
    }
   ],
   "source": [
    "# with open(f\"{text_data_path}/text_train_data.jsonl\", \"r\") as f:\n",
    "#    train_data = json.load(f)\n",
    "\n",
    "# with open(f\"{text_data_path}/text_val_data.jsonl\", \"r\") as f:\n",
    "#   val_data = json.load(f)\n",
    "\n",
    "# with open(f\"{text_data_path}/sample_50.jsonl\", \"r\") as f:\n",
    "#   sample_data = json.load(f)\n",
    "\n",
    "# print(\"Training data size = \", len(train_data))\n",
    "# print(\"Validation data size = \", len(val_data))\n",
    "# print(\"Sample data size = \", len(sample_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTAas15G8piS"
   },
   "source": [
    "### **Load Full Dataset from HuggingFace Hub**\n",
    "\n",
    "\n",
    "This dataset was created from structured real estate data and uploaded to Hugging Face in the first notebook. It is formatted for instruction-based fine-tuning an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362,
     "referenced_widgets": [
      "feed144772414889b09faed42497067c",
      "4c7bf3cf0ff54ef887514f359e461966",
      "ebb0423da11d4097bd0d08f195d7d008",
      "787e5615593140b6a2b241d3b8304934",
      "9edb9852718e4b079828cae843ff23ea",
      "e14a698850b84346a6cbb8de30ef212b",
      "d166cd8b8a6246f59905520c495f2464",
      "ef9a9f38d0ef4e89aa1be0f1d5c2e553",
      "5a35c333e6d24f4783ecbc7e33fa96a5",
      "91fa5d7b2be543668aa18ac211b50886",
      "098840716b3041cfb04bf817b22bf2e6",
      "676879a090174233b4c4f00a83222159",
      "b26f563360dc460c8e1ff8f9f0778069",
      "39d267ea88d342b18131c6fee44b94a3",
      "e86db4ccf47e4af09db5a13c945d98f9",
      "8124b64e84d84127b441f399eff526d6",
      "775974e59f9c4f5cb650bed70c44f8f8",
      "ff22dc9ccc0a403599a55c456013c3cb",
      "5a8b4c0ea74c4e838300bdeca96c987e",
      "c682ff05651045138f79176ff037b8f2",
      "632f91249df74f80b53f86aec3f46d69",
      "d952bd3306d34e4dbcff925ca819c0f4",
      "7ebeca0960c14b52b2b9a0e0aaab1928",
      "04967a17f83b48bba671009974b3f3fa",
      "c1728c9511af4afdbec6f101a7b6fc27",
      "d88c2859fc6e455886ee5761c7a52894",
      "6db89663543942009233df993e0ab4a7",
      "3d0d3a6006c54b398672ec051e1b1192",
      "e3c650cfad064124bfce73af34dfa287",
      "ba654c4509674c4795bac2502012f205",
      "a5cba89fc6cb45c1ba53b1d3d568b940",
      "ccd024d40290428383f95dc94592782b",
      "a490e95392394ae2a8d9e6318317dd84",
      "6ca9284ca9414faeb4fcb45e50ed44f5",
      "9511d32d63ab407ca4c35b8ff0f6bee5",
      "b6e14f1678974665a2b2d21760467b80",
      "df857533519542a9ad46fd8da47f523f",
      "57c036f53bd943fb850c7f0d7cc3992b",
      "afe9fb7456c54d63927839f30a82caa8",
      "e252bd65e8694bba8670401cf84a3136",
      "7d9ee638f0da47368576d9484613d04a",
      "dcce7f4bd6a244e0abdfbb69baa319a5",
      "b547fd3848474319a288dd917a47aa3d",
      "c822a0a968b04614bf180f6955841907",
      "41f4aa4a5a87409bbae5f9ccb563df37",
      "3c4fb661a8584eeebbabc0f5553b7259",
      "450a0ee993b045fcaa4f1d835c99a01a",
      "18627bf677d74c66809645161dd508c9",
      "981c384646ee409db52bbccbff56f23b",
      "edeb5fd8f29a4420a2459b5266708331",
      "69688de478a94a7386f46cf346857004",
      "9cb3c815686f40c680d88aa1a8282fcd",
      "6d701af891854fd6b4f05bd1593e0df0",
      "23fe842d1a434777809cc312a270f9e1",
      "b8f9278c94364df3bc733bcbcd401914"
     ]
    },
    "execution": {
     "iopub.status.busy": "2025-05-08T00:34:14.177574Z",
     "iopub.status.idle": "2025-05-08T00:34:14.177794Z",
     "shell.execute_reply": "2025-05-08T00:34:14.177701Z",
     "shell.execute_reply.started": "2025-05-08T00:34:14.177691Z"
    },
    "id": "iiUmTwb58oar",
    "outputId": "7ca938e7-933d-4124-80ed-423ab59e88e3",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feed144772414889b09faed42497067c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/31.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676879a090174233b4c4f00a83222159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_train_data.jsonl:   0%|          | 0.00/1.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebeca0960c14b52b2b9a0e0aaab1928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_val_data.jsonl:   0%|          | 0.00/16.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca9284ca9414faeb4fcb45e50ed44f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f4aa4a5a87409bbae5f9ccb563df37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'query', 'response'],\n",
       "        num_rows: 2201006\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'query', 'response'],\n",
       "        num_rows: 22233\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id = \"heba1998/real-estate-data-for-llm-fine-tuning\"\n",
    "\n",
    "dataset = load_dataset(repo_id,\n",
    "    data_files={\n",
    "    \"train\": \"text_train_data.jsonl\",\n",
    "    \"validation\": \"text_val_data.jsonl\"\n",
    "    },\n",
    "    # cache_dir = os.environ['DATASETS_CACHE'],\n",
    "    trust_remote_code = True\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twVWatF6iFXS"
   },
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "val_data = dataset['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ajBE9n010kM"
   },
   "source": [
    "### **Load Dataset Sample from hugging Face Hub**\n",
    "\n",
    "A data sample that was created from structured real estate data and uploaded to Hugging Face in the first notebook. It is formatted for instruction-based fine-tuning an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266,
     "referenced_widgets": [
      "5bb78e48096441e1bba9c1db08556a18",
      "d4bb354a080c4abaa40089a0c964a198",
      "3d699244258a48079f8195a893d6be6b",
      "a65d72b3455c4d318b16418311234e16",
      "b82d86dd23284f7bb3a8472b5492b3de",
      "6786fc60749b44d1b2e8fd26667f001a",
      "8e885a061f5f469d8a8b2ef490e33fb6",
      "55aba028f2e24dcb8b4e5dc5115d69f9",
      "0343daed947f4752b166f1a6ac6b3068",
      "04ae22956f4b4ea980bc8cfa35247597",
      "d5a7b32aa85f454f8748dfe200ae61aa",
      "6132ba7a78ad434f98a79aa496d56ff7",
      "25763e3764344d4ebe8575b7a67da9f9",
      "2797905ed9b746ae8327a59802043da2",
      "9ade7d1143ea40c69e4e82e3900ab12e",
      "40a912e08c1841af9b56f36cbad0b881",
      "6225dac29a5544cd8bbb26539b51c2c0",
      "46ac53497f044a6e83dbc2923ed8e7f3",
      "a544e7a9981d47d5838915637dcb58c4",
      "f9da6489ad384c32b33410058cd9b69e",
      "ae6901b08a6748b1a2d3db21a5246c71",
      "511c3e8e5d7b46b8a37759b634cfeed9"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T01:40:42.239868Z",
     "iopub.status.busy": "2025-05-09T01:40:42.239308Z",
     "iopub.status.idle": "2025-05-09T01:40:43.599498Z",
     "shell.execute_reply": "2025-05-09T01:40:43.598891Z",
     "shell.execute_reply.started": "2025-05-09T01:40:42.239844Z"
    },
    "id": "4CdqwJVM1zuc",
    "outputId": "deb8eb53-f421-415c-a4a9-b56fed3f1a02",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d29ef73480f4a2ba8eb6a3b218578a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d83bd94b7446a1a2d8861349c16495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da6e20cb5374646b1116460ffe45e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'instruction', 'input', 'output', 'history'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['system', 'instruction', 'input', 'output', 'history'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\n",
    "    path  ='heba1998/real-estate-data-sample-for-llm-fine-tuning' # data sample\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save to Working directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T23:07:51.779194Z",
     "iopub.status.busy": "2025-05-08T23:07:51.778527Z",
     "iopub.status.idle": "2025-05-08T23:07:52.148003Z",
     "shell.execute_reply": "2025-05-08T23:07:52.147470Z",
     "shell.execute_reply.started": "2025-05-08T23:07:51.779171Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# Assuming your DatasetDict is named `dataset_dict`\n",
    "splits = [\"train\", \"validation\"]\n",
    "names = [\"llm_train_data\", \"llm_val_data\"]\n",
    "\n",
    "for split, name in zip(splits, names):\n",
    "    output_path = f\"{os.environ['DATASETS']}/{name}.jsonl\"\n",
    "    \n",
    "    # Open file and write each example as a JSON line\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for example in dataset[split]:\n",
    "            json.dump(example, f, ensure_ascii=False)  # Write as JSON\n",
    "            f.write(\"\\n\")  # Newline for next example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T01:41:00.552185Z",
     "iopub.status.busy": "2025-05-09T01:41:00.551695Z",
     "iopub.status.idle": "2025-05-09T01:41:00.707707Z",
     "shell.execute_reply": "2025-05-09T01:41:00.706989Z",
     "shell.execute_reply.started": "2025-05-09T01:41:00.552163Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_train_data.jsonl  llm_val_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls {os.environ['DATASETS']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Q--kqVkczCv"
   },
   "source": [
    "---\n",
    "## Format Dataset for LlaMa-Factory\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T01:42:23.669481Z",
     "iopub.status.busy": "2025-05-09T01:42:23.668918Z",
     "iopub.status.idle": "2025-05-09T01:42:23.674969Z",
     "shell.execute_reply": "2025-05-09T01:42:23.674032Z",
     "shell.execute_reply.started": "2025-05-09T01:42:23.669457Z"
    },
    "id": "iEe8YWqxeGpr",
    "outputId": "294ae136-3e2f-4bc0-cfff-f36f9b820042",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "description": "Define the response schema.",
       "properties": {
        "estimated_house_price": {
         "description": "Numerical value that expresses the estimated house price",
         "example": 85000,
         "title": "Estimated House Price",
         "type": "number"
        }
       },
       "required": [
        "estimated_house_price"
       ],
       "title": "ResponseSchema",
       "type": "object"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fine_tuning_helpers import ResponseSchema, SYSTEM_MESSAGE \n",
    "\n",
    "JSON(ResponseSchema.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T01:42:34.579695Z",
     "iopub.status.busy": "2025-05-09T01:42:34.579203Z",
     "iopub.status.idle": "2025-05-09T01:42:34.583442Z",
     "shell.execute_reply": "2025-05-09T01:42:34.582716Z",
     "shell.execute_reply.started": "2025-05-09T01:42:34.579675Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in real estate price estimation with experience in the housing market.\n",
      "Given the following house features, predict the final sale price.\n",
      "#### Critical notes:\n",
      "- Some feature values are missing.\n",
      "- Broker ID and street are encoded for privacy.\n",
      "- Do not include any introduction or conclusion.\n"
     ]
    }
   ],
   "source": [
    "print(SYSTEM_MESSAGE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXSejH0ubi5Q"
   },
   "source": [
    "### **Refactoring Datasets for LLaMA-Factory**\n",
    "\n",
    "Transform training and validation sets into a specific dictionary format that LLaMA-Factory expects for instruction tuning following the [documentation](https://llamafactory.readthedocs.io/en/latest/getting_started/data_preparation.html).\n",
    "\n",
    "##### **Current Format Example**\n",
    "```json\n",
    "{\n",
    "  \"id\": 0,\n",
    "  \"query\": \"A house listing in the USA with the following details: - Status: for_sale - Number of bedrooms: -1 - Number of bathrooms: -1 - Land size: 0.07000000029802322 acres - Address (city, state, zip): Washington, District of Columbia, 20002.0 - House size: -1.0 sqft Your task is to predict the final sale price in $? ### Output schema: {'properties': {'estimated_house_price': {'description': 'Numerical value that expresses the estimated house price', 'example': 85000.0, 'title': 'Estimated House Price', 'type': 'number'}}, 'required': ['estimated_house_price'], 'title': 'ResponseSchema', 'type': 'object'} ### Response: ```json\",\n",
    "  \"response\": \"{'estimated_house_price':2500000.0}\"\n",
    "}\n",
    "```\n",
    "##### **Needed Templete:**\n",
    "```json\n",
    "{\n",
    "  \"system\": \"You are a helpful assistant that predicts house prices based on listing data.\",\n",
    "  \"instruction\": \"A house listing in the USA with the following details: - Status: for_sale - Number of bedrooms: -1 - Number of bathrooms: -1 - Land size: 0.07000000029802322 acres - Address (city, state, zip): Washington, District of Columbia, 20002.0 - House size: -1.0 sqft Your task is to predict the final sale price in $? ### Output schema: {'properties': {'estimated_house_price': {'description': 'Numerical value that expresses the estimated house price', 'example': 85000.0, 'title': 'Estimated House Price', 'type': 'number'}}, 'required': ['estimated_house_price'], 'title': 'ResponseSchema', 'type': 'object'} ### Response: ```json\",\n",
    "  \"input\": \"\",\n",
    "  \"output\": \"{'estimated_house_price':2500000.0}\",\n",
    "  \"history\": []\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "L5UVkGAKc6Zr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def refactor_data(df, color=\"green\"):\n",
    "\n",
    "  llamafactory_data = []\n",
    "  bar_format = '{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}{postfix}]'\n",
    "\n",
    "  for row in tqdm(df,\n",
    "                  total=len(df), unit=\"sample\",\n",
    "                  ncols=100, colour= color,\n",
    "                  desc=\"Format Data for LlaMa Factory\",\n",
    "                  bar_format=bar_format):\n",
    "\n",
    "      llamafactory_data.append({\n",
    "          \"system\": system_message,\n",
    "          \"instruction\": row['query'],\n",
    "          \"input\": \"\",\n",
    "          \"output\": row['response'],\n",
    "          \"history\": []\n",
    "      })\n",
    "  return llamafactory_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "IIA-xMbtAmof"
   },
   "outputs": [],
   "source": [
    "# release to optimize memory usage\n",
    "del llm_train_data, llm_val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5vZoio8tWyl"
   },
   "source": [
    "### **Push the data after refactoring to Hugging Face (Optional)**\n",
    "\n",
    "Optionaly push the new datasets (`llm_train_data.jsonl` and `llm_val_data.jsonl`) to hugging face after refactor it to suit the LlaMa-Factory template.\n",
    "\n",
    "> By applying this step you can call it directly in `LLaMA-Factory/data/dataset_info.json` from hugging face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Y7erp_q1tfnp"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "username = \"heba1998\"\n",
    "data_title = \"Real Estate Data Sample For LLM Fine-Tuning\"\n",
    "repo_name = data_title.replace(\" \", \"-\").lower()\n",
    "date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "metadata = {\n",
    "    \"title\": data_title,\n",
    "    \"id\": f\"{username}/{repo_name}\",\n",
    "    \"licenses\": [{\"name\": \"CC0-1.0\"}],\n",
    "    \"description\": \"Translated Text data generated from tabular US real estate data for LLM fine-tuning\",\n",
    "    \"version\": \"2.0\",\n",
    "    \"create_at\": date,\n",
    "    \"author\": username,\n",
    "    \"tags\": [\n",
    "        \"LLM\",\n",
    "        \"Text Data\",\n",
    "        \"Real Estate\",\n",
    "        \"LlaMa-Factory\"\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "d6jXe-Iwtx8p",
    "outputId": "73485426-619f-4ac4-fbdf-2a9225e3ac18"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/heba1998/real-estate-data-sample-for-llm-fine-tuning/commit/47e26f86ae6d7162b014adc1b8a79204cd0eb546', commit_message='Add 200 sample llm_train_data.jsonl file after refactoring for llamafactory', commit_description='', oid='47e26f86ae6d7162b014adc1b8a79204cd0eb546', pr_url='https://huggingface.co/datasets/heba1998/real-estate-data-sample-for-llm-fine-tuning/discussions/4', repo_url=RepoUrl('https://huggingface.co/datasets/heba1998/real-estate-data-sample-for-llm-fine-tuning', endpoint='https://huggingface.co', repo_type='dataset', repo_id='heba1998/real-estate-data-sample-for-llm-fine-tuning'), pr_revision='refs/pr/4', pr_num=4)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "\n",
    "# Uncomment if first time upload\n",
    "# api.create_repo(repo_id=f\"{username}/{repo_name}\",\n",
    "#                 repo_type=\"dataset\",\n",
    "#                 private=True)\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=f\"{os.environ['DATASETS']}/llm_train_data.jsonl\",\n",
    "    repo_id=f\"{username}/{repo_name}\",\n",
    "    repo_type=\"dataset\",\n",
    "    create_pr=True,\n",
    "    path_in_repo=\"llm_train_data.jsonl\",\n",
    "    commit_message=\"Add 5000 sample of llm_train_data.jsonl after refactoring for llamafactory\",\n",
    "    revision=\"main\",\n",
    "    )\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=f\"{os.environ['DATASETS']}/llm_val_data.jsonl\",\n",
    "    repo_id=f\"{username}/{repo_name}\",\n",
    "    repo_type=\"dataset\",\n",
    "    create_pr=True,\n",
    "    path_in_repo=\"llm_val_data.jsonl\",\n",
    "    commit_message=\"Add 200 sample llm_train_data.jsonl file after refactoring for llamafactory\",\n",
    "    revision=\"main\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYJdgJvAU_C4"
   },
   "source": [
    "---\n",
    "## Fine-tune Using LoRA\n",
    "---\n",
    "\n",
    "Fine-tune the **`Qwen3-0.6B-Instruct`** model on a real estate dataset using LoRA (Low-Rank Adaptation) with the **LLaMA-Factory** training framework. Here is my steps:\n",
    "\n",
    "1. **Load pretrained Model:** Load the pretrained `Qwen3-0.6B-Instruct` model from Hugging Face.\n",
    "2. **Fine-Tune:** apply LoRA fine-tuning on *all* target layers with rank **64**.\n",
    "3. **Monitor Training** using W\\&B (`wandb`) with metrics and loss plots.\n",
    "4. **Model Checkpoints:** save the fine-tuned model to Google drive.\n",
    "5. **Push the resulting fine-tuned model to Hugging Face Hub**, privately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OV9YUO0Mbi5h"
   },
   "source": [
    "### **Register the Custom Real Estate Dataset**\n",
    "Registering two custom datasets (`real_estate_finetune_train` and `real_estate_finetune_val`) into the LLaMA-Factorys dataset metadata file `dataset_info.json` following these steps:\n",
    "\n",
    "1. **Loading** the existing dataset configuration file (`dataset_info.json`).\n",
    "2. **Adding metadata** for your training and validation datasets:\n",
    "   * Where the data files are stored (paths to `.jsonl` files in the Kaggle cache).\n",
    "   * Which **columns in your dataset** should be mapped to expected fields:\n",
    "\n",
    "| Target Field | Source Column in my JSONL |\n",
    "| ------------ | --------------------------- |\n",
    "| `prompt`     | `instruction`               |\n",
    "| `query`      | `input`                     |\n",
    "| `response`   | `output`                    |\n",
    "| `system`     | `system`                    |\n",
    "| `history`    | `history`                   |\n",
    "\n",
    "3. **Saving** the updated [LLaMA-Factory/data/dataset_info.json](https://https://github.com/hiyouga/LLaMA-Factory/blob/main/data/dataset_info.json/) file, so the training system can use these datasets with the correct structure during fine-tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iojzX7EQyZra"
   },
   "source": [
    "#### **Call Datasets Locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T01:42:59.503513Z",
     "iopub.status.busy": "2025-05-09T01:42:59.503176Z",
     "iopub.status.idle": "2025-05-09T01:42:59.662218Z",
     "shell.execute_reply": "2025-05-09T01:42:59.661418Z",
     "shell.execute_reply.started": "2025-05-09T01:42:59.503492Z"
    },
    "id": "3_wqaddZy0b7",
    "outputId": "9f28d552-63b4-4a39-c229-37a4359cdd60",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpaca_en_demo.json  glaive_toolcall_en_demo.json  mllm_demo.json\n",
      "alpaca_zh_demo.json  glaive_toolcall_zh_demo.json  mllm_video_audio_demo.json\n",
      "belle_multiturn      hh_rlhf_en\t\t\t   mllm_video_demo.json\n",
      "c4_demo.jsonl\t     identity.json\t\t   README.md\n",
      "dataset_info.json    kto_en_demo.json\t\t   README_zh.md\n",
      "dpo_en_demo.json     mllm_audio_demo.json\t   ultra_chat\n",
      "dpo_zh_demo.json     mllm_demo_data\t\t   wiki_demo.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/LLaMA-Factory/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T01:43:03.337499Z",
     "iopub.status.busy": "2025-05-09T01:43:03.336778Z",
     "iopub.status.idle": "2025-05-09T01:43:03.345957Z",
     "shell.execute_reply": "2025-05-09T01:43:03.345440Z",
     "shell.execute_reply.started": "2025-05-09T01:43:03.337470Z"
    },
    "id": "GDfIXkxVskeI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/working/LLaMA-Factory/data/dataset_info.json\"\n",
    "\n",
    "# Load existing JSON\n",
    "with open(file_path, \"r\") as f:\n",
    "    dataset_info = json.load(f)\n",
    "\n",
    "# Append new entries\n",
    "dataset_info[\"real_estate_finetune_train\"] = {\n",
    "    \"file_name\": f'{os.environ[\"DATASETS\"]}/llm_train_data.jsonl',\n",
    "    \"columns\": {\n",
    "        \"prompt\": \"instruction\",\n",
    "        \"query\": \"input\",\n",
    "        \"response\": \"output\",\n",
    "        \"system\": \"system\",\n",
    "        \"history\": \"history\"\n",
    "    }\n",
    "}\n",
    "\n",
    "dataset_info[\"real_estate_finetune_val\"] = {\n",
    "    \"file_name\":f'{os.environ[\"DATASETS\"]}/llm_val_data.jsonl',\n",
    "    \"columns\": {\n",
    "        \"prompt\": \"instruction\",\n",
    "        \"query\": \"input\",\n",
    "        \"response\": \"output\",\n",
    "        \"system\": \"system\",\n",
    "        \"history\": \"history\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write back the updated JSON\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(dataset_info, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxF2MT_Xbi5j"
   },
   "source": [
    "> LLaMA-Factory will now **recognize** the real estate fine-tuning datasets (`real_estate_finetune_train`, `real_estate_finetune_val`) and understand how to **parse each field** correctly for training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MM3Hu0klykbg"
   },
   "source": [
    "#### **Call Datasets from Hugging Face Repo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "K0lvX_b7yov1"
   },
   "outputs": [],
   "source": [
    "# file_path = \"/kaggle/working/LLaMA-Factory/data/dataset_info.json\"\n",
    "\n",
    "# # Load existing JSON\n",
    "# with open(file_path, \"r\") as f:\n",
    "#     dataset_info = json.load(f)\n",
    "\n",
    "\n",
    "# # Append new entries\n",
    "# dataset_info[\"real_estate_hf_train\"] ={\n",
    "#     \"hf_repo\": f\"{username}/{repo_name}\",                    # repo id\n",
    "#     \"hf_file\": \"llm_train_data.jsonl\",                       # HF train file name\n",
    "#     \"file_name\": f'{os.environ[\"DATASETS\"]}/llm_train_data.jsonl', # Local train file name\n",
    "#     \"columns\": {\n",
    "#       \"prompt\": \"instruction\",\n",
    "#       \"query\": \"input\",\n",
    "#       \"response\": \"output\",\n",
    "#       \"system\": \"system\",\n",
    "#       \"history\": \"history\"\n",
    "#     }\n",
    "#   }\n",
    "\n",
    "# dataset_info[\"real_estate_hf_val\"]= {\n",
    "#     \"hf_repo\": f\"{username}/{repo_name}\",                    # repo id\n",
    "#     \"hf_file\": \"llm_val_data.jsonl\",                         # HF validation file name\n",
    "#     \"file_name\": f'{os.environ[\"DATASETS\"]}/llm_val_data.jsonl', # Local validation file name\n",
    "#     \"columns\": {\n",
    "#       \"prompt\": \"instruction\",\n",
    "#       \"query\": \"input\",\n",
    "#       \"response\": \"output\",\n",
    "#       \"system\": \"system\",\n",
    "#       \"history\": \"history\"\n",
    "#     },\n",
    "#   }\n",
    "\n",
    "# # Write back the updated JSON\n",
    "# with open(file_path, \"w\") as f:\n",
    "#     json.dump(dataset_info, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48y8JK0ibi5j"
   },
   "source": [
    "### **Fine-Tune YAML Configuration File**\n",
    "Fine-tune a lightweight, instruction-tuned LLM (`Qwen3-0.6B-Instruct`) on a real estate-specific dataset, optimizing it to perform better on tasks related to real estate queries or text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T01:43:09.102658Z",
     "iopub.status.busy": "2025-05-09T01:43:09.102070Z",
     "iopub.status.idle": "2025-05-09T01:43:09.257843Z",
     "shell.execute_reply": "2025-05-09T01:43:09.256904Z",
     "shell.execute_reply.started": "2025-05-09T01:43:09.102634Z"
    },
    "id": "R3m61j_FqsZq",
    "outputId": "0c9e2ea4-5f6e-4d08-c2aa-41354047495b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3_lora_dpo.yaml\t   llama3_lora_sft.sh\n",
      "llama3_lora_eval.yaml\t   llama3_lora_sft.yaml\n",
      "llama3_lora_kto.yaml\t   llama3_preprocess.yaml\n",
      "llama3_lora_ppo.yaml\t   llama4_lora_sft_ds3.yaml\n",
      "llama3_lora_pretrain.yaml  qwen2_5vl_lora_dpo.yaml\n",
      "llama3_lora_reward.yaml    qwen2_5vl_lora_sft.yaml\n",
      "llama3_lora_sft_ds3.yaml   real_estate_qwen3_lora.yaml\n",
      "llama3_lora_sft_ray.yaml\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/LLaMA-Factory/examples/train_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T23:08:55.984700Z",
     "iopub.status.busy": "2025-05-08T23:08:55.984129Z",
     "iopub.status.idle": "2025-05-08T23:08:55.988546Z",
     "shell.execute_reply": "2025-05-08T23:08:55.987919Z",
     "shell.execute_reply.started": "2025-05-08T23:08:55.984671Z"
    },
    "id": "1EgzQcyxtLfR",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !cat /kaggle/working/LLaMA-Factory/examples/train_lora/qwen2_5vl_lora_sft.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-08T23:16:01.126869Z",
     "iopub.status.busy": "2025-05-08T23:16:01.126258Z",
     "iopub.status.idle": "2025-05-08T23:16:01.132538Z",
     "shell.execute_reply": "2025-05-08T23:16:01.131855Z",
     "shell.execute_reply.started": "2025-05-08T23:16:01.126844Z"
    },
    "id": "f-JILP3Dz6Ij",
    "outputId": "5d9259f0-c240-472e-f66c-245ff33cb2f8",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/LLaMA-Factory/examples/train_lora/real_estate_qwen3_lora.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/LLaMA-Factory/examples/train_lora/real_estate_qwen3_lora.yaml\n",
    "\n",
    "### model metadata (config)\n",
    "model_name_or_path: Qwen/Qwen3-0.6B\n",
    "trust_remote_code: true\n",
    "\n",
    "### method\n",
    "stage: sft\n",
    "do_train: true\n",
    "finetuning_type: lora\n",
    "lora_rank: 64\n",
    "lora_target: all\n",
    "\n",
    "# Defines the dataset for training and evaluation\n",
    "dataset: real_estate_finetune_train # real_estate_sample_data\n",
    "eval_dataset: real_estate_finetune_val\n",
    "template: qwen3\n",
    "cutoff_len: 3500\n",
    "overwrite_cache: true\n",
    "preprocessing_num_workers: 16\n",
    "\n",
    "### Output Directory and Logging Configuration\n",
    "output_dir: /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output\n",
    "logging_steps: 50\n",
    "save_steps: 200\n",
    "plot_loss: true\n",
    "overwrite_output_dir: true\n",
    "save_only_model: false\n",
    "save_safetensors: true\n",
    "\n",
    "### train\n",
    "per_device_train_batch_size: 1\n",
    "gradient_accumulation_steps: 8\n",
    "learning_rate: 1.0e-4\n",
    "num_train_epochs: 3.0\n",
    "lr_scheduler_type: cosine\n",
    "warmup_ratio: 0.1\n",
    "bf16: true\n",
    "ddp_timeout: 180000000\n",
    "\n",
    "### eval\n",
    "per_device_eval_batch_size: 1\n",
    "eval_strategy: steps\n",
    "eval_steps: 100\n",
    "load_best_model_at_end: true\n",
    "metric_for_best_model: eval_loss\n",
    "greater_is_better: false\n",
    "\n",
    "### logging\n",
    "report_to: wandb\n",
    "run_name: real-estate-finetune-qwen0.6B\n",
    "\n",
    "### Additional Model Saving and Hub Configuration\n",
    "push_to_hub: true\n",
    "export_hub_model_id: \"heba1998/Qwen3-0.6B-real-estate-adaptor\"\n",
    "hub_private_repo: true\n",
    "# hub_strategy: checkpoint\n",
    "hub_token: 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\n",
    "\n",
    "### Additional settings\n",
    "save_strategy: steps\n",
    "save_total_limit: 2\n",
    "export_device: auto\n",
    "adapter_folder: /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/adapters\n",
    "export_dir: /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/exported_models\n",
    "use_cache: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUJ2LNtZbi5k"
   },
   "source": [
    "### **Start Fine-Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T01:43:20.621431Z",
     "iopub.status.busy": "2025-05-09T01:43:20.620736Z",
     "iopub.status.idle": "2025-05-09T01:43:20.626579Z",
     "shell.execute_reply": "2025-05-09T01:43:20.625646Z",
     "shell.execute_reply.started": "2025-05-09T01:43:20.621400Z"
    },
    "id": "megiKo5aB1yn",
    "outputId": "4cd3ffd0-08d1-4a0f-8a32-e3f5c34d0f56",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-08T23:16:06.738882Z",
     "iopub.status.busy": "2025-05-08T23:16:06.738585Z",
     "iopub.status.idle": "2025-05-09T01:25:34.377428Z",
     "shell.execute_reply": "2025-05-09T01:25:34.369736Z",
     "shell.execute_reply.started": "2025-05-08T23:16:06.738864Z"
    },
    "id": "LSRxV_NsAI5d",
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746746172.253936    2161 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746746172.260589    2161 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "[INFO|2025-05-08 23:16:19] llamafactory.cli:143 >> Initializing 2 distributed tasks at: 127.0.0.1:38619\n",
      "W0508 23:16:21.495000 2181 torch/distributed/run.py:793] \n",
      "W0508 23:16:21.495000 2181 torch/distributed/run.py:793] *****************************************\n",
      "W0508 23:16:21.495000 2181 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0508 23:16:21.495000 2181 torch/distributed/run.py:793] *****************************************\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746746187.068435    2183 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746746187.068445    2184 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746746187.075031    2184 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "E0000 00:00:1746746187.075047    2183 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "[W508 23:16:32.501817184 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W508 23:16:33.543598181 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[INFO|2025-05-08 23:16:33] llamafactory.hparams.parser:143 >> Set `ddp_find_unused_parameters` to False in DDP training since LoRA is enabled.\n",
      "[INFO|2025-05-08 23:16:33] llamafactory.hparams.parser:401 >> Process rank: 0, world size: 2, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16\n",
      "[INFO|2025-05-08 23:16:33] llamafactory.hparams.parser:401 >> Process rank: 1, world size: 2, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16\n",
      "tokenizer_config.json: 100%|| 9.68k/9.68k [00:00<00:00, 16.5MB/s]\n",
      "vocab.json: 100%|| 2.78M/2.78M [00:00<00:00, 25.5MB/s]\n",
      "merges.txt: 100%|| 1.67M/1.67M [00:00<00:00, 89.8MB/s]\n",
      "tokenizer.json: 100%|| 11.4M/11.4M [00:00<00:00, 28.3MB/s]\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:34,322 >> loading file vocab.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/vocab.json\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:34,322 >> loading file merges.txt from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/merges.txt\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:34,322 >> loading file tokenizer.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:34,322 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:34,322 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:34,322 >> loading file tokenizer_config.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:34,322 >> loading file chat_template.jinja from cache at None\n",
      "[INFO|tokenization_utils_base.py:2323] 2025-05-08 23:16:34,871 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "config.json: 100%|| 726/726 [00:00<00:00, 5.00MB/s]\n",
      "[INFO|configuration_utils.py:693] 2025-05-08 23:16:35,417 >> loading configuration file config.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
      "[INFO|configuration_utils.py:765] 2025-05-08 23:16:35,418 >> Model config Qwen3Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:35,458 >> loading file vocab.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/vocab.json\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:35,458 >> loading file merges.txt from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/merges.txt\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:35,459 >> loading file tokenizer.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:35,459 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:35,459 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:35,459 >> loading file tokenizer_config.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2060] 2025-05-08 23:16:35,459 >> loading file chat_template.jinja from cache at None\n",
      "[rank1]:[W508 23:16:35.151229867 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[INFO|tokenization_utils_base.py:2323] 2025-05-08 23:16:35,960 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|2025-05-08 23:16:36] llamafactory.data.loader:143 >> Loading dataset /kaggle/working/drive/MyDrive/llm-finetuning/datasets_samples/llm_train_data.jsonl...\n",
      "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
      "Generating train split: 5000 examples [00:00, 126990.06 examples/s]\n",
      "Converting format of dataset (num_proc=16): 100%|| 5000/5000 [00:00<00:00, 7990\n",
      "[INFO|2025-05-08 23:16:37] llamafactory.data.loader:143 >> Loading dataset /kaggle/working/drive/MyDrive/llm-finetuning/datasets_samples/llm_val_data.jsonl...\n",
      "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
      "Generating train split: 200 examples [00:00, 65270.84 examples/s]\n",
      "Converting format of dataset (num_proc=16): 100%|| 200/200 [00:00<00:00, 593.10\n",
      "[rank0]:[W508 23:16:38.593596335 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "Running tokenizer on dataset (num_proc=16): 100%|| 5000/5000 [00:09<00:00, 529.\n",
      "training example:\n",
      "input_ids:\n",
      "[151644, 8948, 198, 2610, 525, 458, 6203, 304, 1931, 12394, 3349, 41204, 448, 3139, 304, 279, 11721, 3081, 624, 22043, 279, 2701, 3753, 4419, 11, 7023, 279, 1590, 6278, 3349, 624, 820, 34661, 8388, 510, 12, 4329, 4565, 2750, 525, 7402, 624, 12, 52701, 3034, 323, 8592, 525, 20498, 369, 12345, 624, 12, 3155, 537, 2924, 894, 16800, 476, 16688, 13, 151645, 198, 151644, 872, 198, 32, 3753, 14838, 304, 279, 7279, 448, 279, 2701, 3565, 1447, 12, 8104, 25, 369, 47114, 271, 12, 5624, 315, 27589, 25, 481, 16, 271, 12, 5624, 315, 39883, 25, 481, 16, 271, 12, 11426, 1379, 25, 220, 15, 13, 22, 18, 15, 15, 15, 15, 15, 16, 24, 15, 22, 18, 19, 23, 21, 18, 26367, 271, 12, 9177, 320, 8926, 11, 1584, 11, 10308, 1648, 5776, 1644, 13805, 11, 8257, 11, 220, 22, 23, 18, 22, 18, 13, 15, 198, 12, 4678, 1379, 25, 481, 16, 13, 15, 18031, 723, 271, 7771, 3383, 374, 311, 7023, 279, 1590, 6278, 3349, 304, 400, 5267, 14374, 9258, 10802, 510, 13608, 13193, 1210, 5360, 44229, 64270, 9040, 1210, 5360, 4684, 1210, 364, 67737, 938, 897, 429, 60020, 279, 12943, 3753, 3349, 516, 364, 8687, 1210, 220, 23, 20, 15, 15, 15, 13, 15, 11, 364, 2102, 1210, 364, 72565, 4678, 8483, 516, 364, 1313, 1210, 364, 4082, 8275, 2137, 364, 6279, 1210, 2509, 44229, 64270, 9040, 4089, 364, 2102, 1210, 364, 2582, 8632, 516, 364, 1313, 1210, 364, 1700, 16418, 14374, 5949, 25, 715, 54275, 2236, 151645, 198, 151644, 77091, 198, 151667, 271, 151668, 271, 4913, 44229, 64270, 9040, 788, 17, 24, 20, 15, 15, 15, 13, 15, 92, 151645, 198]\n",
      "inputs:\n",
      "<|im_start|>system\n",
      "You are an expert in real estate price estimation with experience in the housing market.\n",
      "Given the following house features, predict the final sale price.\n",
      "#### Critical notes:\n",
      "- Some feature values are missing.\n",
      "- Broker ID and street are encoded for privacy.\n",
      "- Do not include any introduction or conclusion.<|im_end|>\n",
      "<|im_start|>user\n",
      "A house listing in the USA with the following details:\n",
      "\n",
      "- Status: for_sale\n",
      "\n",
      "- Number of bedrooms: -1\n",
      "\n",
      "- Number of bathrooms: -1\n",
      "\n",
      "- Land size: 0.7300000190734863 acres\n",
      "\n",
      "- Address (city, state, zip): Port Aransas, Texas, 78373.0\n",
      "- House size: -1.0 sqft\n",
      "\n",
      "Your task is to predict the final sale price in $?\n",
      "### Output schema:\n",
      "{'properties': {'estimated_house_price': {'description': 'Numerical value that expresses the estimated house price', 'example': 85000.0, 'title': 'Estimated House Price', 'type': 'number'}}, 'required': ['estimated_house_price'], 'title': 'ResponseSchema', 'type': 'object'}\n",
      "### Response: \n",
      " ```json<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "{\"estimated_house_price\":295000.0}<|im_end|>\n",
      "\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4913, 44229, 64270, 9040, 788, 17, 24, 20, 15, 15, 15, 13, 15, 92, 151645, 198]\n",
      "labels:\n",
      "{\"estimated_house_price\":295000.0}<|im_end|>\n",
      "\n",
      "Running tokenizer on dataset (num_proc=16): 100%|| 200/200 [00:06<00:00, 31.69 \n",
      "eval example:\n",
      "input_ids:\n",
      "[151644, 8948, 198, 2610, 525, 458, 6203, 304, 1931, 12394, 3349, 41204, 448, 3139, 304, 279, 11721, 3081, 624, 22043, 279, 2701, 3753, 4419, 11, 7023, 279, 1590, 6278, 3349, 624, 820, 34661, 8388, 510, 12, 4329, 4565, 2750, 525, 7402, 624, 12, 52701, 3034, 323, 8592, 525, 20498, 369, 12345, 624, 12, 3155, 537, 2924, 894, 16800, 476, 16688, 13, 151645, 198, 151644, 872, 198, 32, 3753, 14838, 304, 279, 7279, 448, 279, 2701, 3565, 1447, 12, 8104, 25, 369, 47114, 271, 12, 5624, 315, 27589, 25, 481, 16, 271, 12, 5624, 315, 39883, 25, 481, 16, 271, 12, 11426, 1379, 25, 220, 15, 13, 15, 22, 15, 15, 15, 15, 15, 15, 15, 17, 24, 23, 15, 17, 18, 17, 17, 26367, 271, 12, 9177, 320, 8926, 11, 1584, 11, 10308, 1648, 6515, 11, 10942, 315, 18796, 11, 220, 17, 15, 15, 15, 17, 13, 15, 198, 12, 4678, 1379, 25, 481, 16, 13, 15, 18031, 723, 271, 7771, 3383, 374, 311, 7023, 279, 1590, 6278, 3349, 304, 400, 5267, 14374, 9258, 10802, 510, 13608, 13193, 1210, 5360, 44229, 64270, 9040, 1210, 5360, 4684, 1210, 364, 67737, 938, 897, 429, 60020, 279, 12943, 3753, 3349, 516, 364, 8687, 1210, 220, 23, 20, 15, 15, 15, 13, 15, 11, 364, 2102, 1210, 364, 72565, 4678, 8483, 516, 364, 1313, 1210, 364, 4082, 8275, 2137, 364, 6279, 1210, 2509, 44229, 64270, 9040, 4089, 364, 2102, 1210, 364, 2582, 8632, 516, 364, 1313, 1210, 364, 1700, 16418, 14374, 5949, 25, 715, 54275, 2236, 151645, 198, 151644, 77091, 198, 151667, 271, 151668, 271, 4913, 44229, 64270, 9040, 788, 17, 20, 15, 15, 15, 15, 15, 13, 15, 92, 151645, 198]\n",
      "inputs:\n",
      "<|im_start|>system\n",
      "You are an expert in real estate price estimation with experience in the housing market.\n",
      "Given the following house features, predict the final sale price.\n",
      "#### Critical notes:\n",
      "- Some feature values are missing.\n",
      "- Broker ID and street are encoded for privacy.\n",
      "- Do not include any introduction or conclusion.<|im_end|>\n",
      "<|im_start|>user\n",
      "A house listing in the USA with the following details:\n",
      "\n",
      "- Status: for_sale\n",
      "\n",
      "- Number of bedrooms: -1\n",
      "\n",
      "- Number of bathrooms: -1\n",
      "\n",
      "- Land size: 0.07000000029802322 acres\n",
      "\n",
      "- Address (city, state, zip): Washington, District of Columbia, 20002.0\n",
      "- House size: -1.0 sqft\n",
      "\n",
      "Your task is to predict the final sale price in $?\n",
      "### Output schema:\n",
      "{'properties': {'estimated_house_price': {'description': 'Numerical value that expresses the estimated house price', 'example': 85000.0, 'title': 'Estimated House Price', 'type': 'number'}}, 'required': ['estimated_house_price'], 'title': 'ResponseSchema', 'type': 'object'}\n",
      "### Response: \n",
      " ```json<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "{\"estimated_house_price\":2500000.0}<|im_end|>\n",
      "\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4913, 44229, 64270, 9040, 788, 17, 20, 15, 15, 15, 15, 15, 13, 15, 92, 151645, 198]\n",
      "labels:\n",
      "{\"estimated_house_price\":2500000.0}<|im_end|>\n",
      "\n",
      "[INFO|configuration_utils.py:693] 2025-05-08 23:16:56,536 >> loading configuration file config.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
      "[INFO|configuration_utils.py:765] 2025-05-08 23:16:56,538 >> Model config Qwen3Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|2025-05-08 23:16:56] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.\n",
      "model.safetensors: 100%|| 1.50G/1.50G [00:09<00:00, 167MB/s]\n",
      "[INFO|modeling_utils.py:1124] 2025-05-08 23:17:05,798 >> loading weights file model.safetensors from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/model.safetensors\n",
      "[INFO|modeling_utils.py:2167] 2025-05-08 23:17:05,800 >> Instantiating Qwen3ForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1142] 2025-05-08 23:17:05,802 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:4930] 2025-05-08 23:17:07,351 >> All model checkpoint weights were used when initializing Qwen3ForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4938] 2025-05-08 23:17:07,351 >> All the weights of Qwen3ForCausalLM were initialized from the model checkpoint at Qwen/Qwen3-0.6B.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen3ForCausalLM for predictions without further training.\n",
      "generation_config.json: 100%|| 239/239 [00:00<00:00, 1.60MB/s]\n",
      "[INFO|configuration_utils.py:1097] 2025-05-08 23:17:07,399 >> loading configuration file generation_config.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/generation_config.json\n",
      "[INFO|configuration_utils.py:1142] 2025-05-08 23:17:07,399 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.95\n",
      "}\n",
      "\n",
      "[INFO|2025-05-08 23:17:07] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.\n",
      "[INFO|2025-05-08 23:17:07] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
      "[INFO|2025-05-08 23:17:07] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.\n",
      "[INFO|2025-05-08 23:17:07] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA\n",
      "[INFO|2025-05-08 23:17:07] llamafactory.model.model_utils.misc:143 >> Found linear modules: v_proj,gate_proj,up_proj,o_proj,down_proj,k_proj,q_proj\n",
      "[INFO|2025-05-08 23:17:08] llamafactory.model.loader:143 >> trainable params: 40,370,176 || all params: 636,420,096 || trainable%: 6.3433\n",
      "[INFO|trainer.py:748] 2025-05-08 23:17:08,298 >> Using auto half precision backend\n",
      "[INFO|trainer.py:2414] 2025-05-08 23:17:09,042 >> ***** Running training *****\n",
      "[INFO|trainer.py:2415] 2025-05-08 23:17:09,042 >>   Num examples = 5,000\n",
      "[INFO|trainer.py:2416] 2025-05-08 23:17:09,042 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:2417] 2025-05-08 23:17:09,042 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:2420] 2025-05-08 23:17:09,043 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:2421] 2025-05-08 23:17:09,043 >>   Gradient Accumulation steps = 8\n",
      "[INFO|trainer.py:2422] 2025-05-08 23:17:09,043 >>   Total optimization steps = 936\n",
      "[INFO|trainer.py:2423] 2025-05-08 23:17:09,047 >>   Number of trainable parameters = 40,370,176\n",
      "[INFO|integration_utils.py:831] 2025-05-08 23:17:09,093 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LLaMA-Factory/wandb/run-20250508_231709-vbdtlxqp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mreal-estate-finetune-qwen0.6B\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/debi2023-group-3/llamafactory\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/debi2023-group-3/llamafactory/runs/vbdtlxqp\u001b[0m\n",
      "{'loss': 0.8141, 'grad_norm': 1.5399190187454224, 'learning_rate': 5.212765957446809e-05, 'epoch': 0.16}\n",
      "{'loss': 0.4846, 'grad_norm': 0.9170283675193787, 'learning_rate': 9.999129952458628e-05, 'epoch': 0.32}\n",
      " 11%|                                  | 100/936 [09:13<1:17:13,  5.54s/it][INFO|trainer.py:4307] 2025-05-08 23:26:23,985 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-05-08 23:26:23,985 >>   Num examples = 200\n",
      "[INFO|trainer.py:4312] 2025-05-08 23:26:23,985 >>   Batch size = 1\n",
      "\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|                                          | 2/100 [00:00<00:10,  9.00it/s]\u001b[A\n",
      "  3%|                                         | 3/100 [00:00<00:15,  6.22it/s]\u001b[A\n",
      "  4%|                                         | 4/100 [00:00<00:17,  5.37it/s]\u001b[A\n",
      "  5%|                                        | 5/100 [00:00<00:19,  4.97it/s]\u001b[A\n",
      "  6%|                                        | 6/100 [00:01<00:19,  4.71it/s]\u001b[A\n",
      "  7%|                                        | 7/100 [00:01<00:20,  4.59it/s]\u001b[A\n",
      "  8%|                                       | 8/100 [00:01<00:20,  4.54it/s]\u001b[A\n",
      "  9%|                                       | 9/100 [00:01<00:20,  4.50it/s]\u001b[A\n",
      " 10%|                                     | 10/100 [00:02<00:20,  4.44it/s]\u001b[A\n",
      " 11%|                                     | 11/100 [00:02<00:20,  4.40it/s]\u001b[A\n",
      " 12%|                                     | 12/100 [00:02<00:20,  4.38it/s]\u001b[A\n",
      " 13%|                                    | 13/100 [00:02<00:19,  4.38it/s]\u001b[A\n",
      " 14%|                                    | 14/100 [00:02<00:19,  4.37it/s]\u001b[A\n",
      " 15%|                                   | 15/100 [00:03<00:19,  4.36it/s]\u001b[A\n",
      " 16%|                                   | 16/100 [00:03<00:19,  4.35it/s]\u001b[A\n",
      " 17%|                                  | 17/100 [00:03<00:19,  4.35it/s]\u001b[A\n",
      " 18%|                                  | 18/100 [00:03<00:18,  4.35it/s]\u001b[A\n",
      " 19%|                                  | 19/100 [00:04<00:18,  4.34it/s]\u001b[A\n",
      " 20%|                                 | 20/100 [00:04<00:18,  4.35it/s]\u001b[A\n",
      " 21%|                                 | 21/100 [00:04<00:18,  4.37it/s]\u001b[A\n",
      " 22%|                                | 22/100 [00:04<00:17,  4.36it/s]\u001b[A\n",
      " 23%|                                | 23/100 [00:05<00:17,  4.33it/s]\u001b[A\n",
      " 24%|                                | 24/100 [00:05<00:17,  4.33it/s]\u001b[A\n",
      " 25%|                               | 25/100 [00:05<00:17,  4.33it/s]\u001b[A\n",
      " 26%|                               | 26/100 [00:05<00:17,  4.35it/s]\u001b[A\n",
      " 27%|                              | 27/100 [00:05<00:16,  4.35it/s]\u001b[A\n",
      " 28%|                              | 28/100 [00:06<00:16,  4.35it/s]\u001b[A\n",
      " 29%|                             | 29/100 [00:06<00:16,  4.36it/s]\u001b[A\n",
      " 30%|                             | 30/100 [00:06<00:16,  4.37it/s]\u001b[A\n",
      " 31%|                             | 31/100 [00:06<00:15,  4.37it/s]\u001b[A\n",
      " 32%|                            | 32/100 [00:07<00:15,  4.36it/s]\u001b[A\n",
      " 33%|                            | 33/100 [00:07<00:15,  4.35it/s]\u001b[A\n",
      " 34%|                           | 34/100 [00:07<00:15,  4.35it/s]\u001b[A\n",
      " 35%|                           | 35/100 [00:07<00:14,  4.35it/s]\u001b[A\n",
      " 36%|                           | 36/100 [00:08<00:14,  4.37it/s]\u001b[A\n",
      " 37%|                          | 37/100 [00:08<00:14,  4.36it/s]\u001b[A\n",
      " 38%|                          | 38/100 [00:08<00:14,  4.34it/s]\u001b[A\n",
      " 39%|                         | 39/100 [00:08<00:14,  4.35it/s]\u001b[A\n",
      " 40%|                         | 40/100 [00:08<00:13,  4.32it/s]\u001b[A\n",
      " 41%|                        | 41/100 [00:09<00:13,  4.33it/s]\u001b[A\n",
      " 42%|                        | 42/100 [00:09<00:13,  4.34it/s]\u001b[A\n",
      " 43%|                        | 43/100 [00:09<00:13,  4.34it/s]\u001b[A\n",
      " 44%|                       | 44/100 [00:09<00:12,  4.36it/s]\u001b[A\n",
      " 45%|                       | 45/100 [00:10<00:12,  4.35it/s]\u001b[A\n",
      " 46%|                      | 46/100 [00:10<00:12,  4.35it/s]\u001b[A\n",
      " 47%|                      | 47/100 [00:10<00:12,  4.38it/s]\u001b[A\n",
      " 48%|                     | 48/100 [00:10<00:11,  4.37it/s]\u001b[A\n",
      " 49%|                     | 49/100 [00:11<00:11,  4.35it/s]\u001b[A\n",
      " 50%|                     | 50/100 [00:11<00:11,  4.37it/s]\u001b[A\n",
      " 51%|                    | 51/100 [00:11<00:11,  4.35it/s]\u001b[A\n",
      " 52%|                    | 52/100 [00:11<00:11,  4.34it/s]\u001b[A\n",
      " 53%|                   | 53/100 [00:11<00:10,  4.35it/s]\u001b[A\n",
      " 54%|                   | 54/100 [00:12<00:10,  4.34it/s]\u001b[A\n",
      " 55%|                   | 55/100 [00:12<00:10,  4.36it/s]\u001b[A\n",
      " 56%|                  | 56/100 [00:12<00:10,  4.36it/s]\u001b[A\n",
      " 57%|                  | 57/100 [00:12<00:09,  4.38it/s]\u001b[A\n",
      " 58%|                 | 58/100 [00:13<00:09,  4.38it/s]\u001b[A\n",
      " 59%|                 | 59/100 [00:13<00:09,  4.39it/s]\u001b[A\n",
      " 60%|                | 60/100 [00:13<00:09,  4.39it/s]\u001b[A\n",
      " 61%|                | 61/100 [00:13<00:08,  4.40it/s]\u001b[A\n",
      " 62%|                | 62/100 [00:14<00:08,  4.38it/s]\u001b[A\n",
      " 63%|               | 63/100 [00:14<00:08,  4.36it/s]\u001b[A\n",
      " 64%|               | 64/100 [00:14<00:08,  4.34it/s]\u001b[A\n",
      " 65%|              | 65/100 [00:14<00:08,  4.34it/s]\u001b[A\n",
      " 66%|              | 66/100 [00:14<00:07,  4.33it/s]\u001b[A\n",
      " 67%|             | 67/100 [00:15<00:07,  4.35it/s]\u001b[A\n",
      " 68%|             | 68/100 [00:15<00:07,  4.36it/s]\u001b[A\n",
      " 69%|             | 69/100 [00:15<00:07,  4.35it/s]\u001b[A\n",
      " 70%|            | 70/100 [00:15<00:06,  4.37it/s]\u001b[A\n",
      " 71%|            | 71/100 [00:16<00:06,  4.36it/s]\u001b[A\n",
      " 72%|           | 72/100 [00:16<00:06,  4.34it/s]\u001b[A\n",
      " 73%|           | 73/100 [00:16<00:06,  4.35it/s]\u001b[A\n",
      " 74%|           | 74/100 [00:16<00:05,  4.35it/s]\u001b[A\n",
      " 75%|          | 75/100 [00:16<00:05,  4.36it/s]\u001b[A\n",
      " 76%|          | 76/100 [00:17<00:05,  4.37it/s]\u001b[A\n",
      " 77%|         | 77/100 [00:17<00:05,  4.37it/s]\u001b[A\n",
      " 78%|         | 78/100 [00:17<00:05,  4.36it/s]\u001b[A\n",
      " 79%|        | 79/100 [00:17<00:04,  4.35it/s]\u001b[A\n",
      " 80%|        | 80/100 [00:18<00:04,  4.35it/s]\u001b[A\n",
      " 81%|        | 81/100 [00:18<00:04,  4.37it/s]\u001b[A\n",
      " 82%|       | 82/100 [00:18<00:04,  4.37it/s]\u001b[A\n",
      " 83%|       | 83/100 [00:18<00:03,  4.37it/s]\u001b[A\n",
      " 84%|      | 84/100 [00:19<00:03,  4.37it/s]\u001b[A\n",
      " 85%|      | 85/100 [00:19<00:03,  4.38it/s]\u001b[A\n",
      " 86%|      | 86/100 [00:19<00:03,  4.38it/s]\u001b[A\n",
      " 87%|     | 87/100 [00:19<00:02,  4.38it/s]\u001b[A\n",
      " 88%|     | 88/100 [00:19<00:02,  4.38it/s]\u001b[A\n",
      " 89%|    | 89/100 [00:20<00:02,  4.39it/s]\u001b[A\n",
      " 90%|    | 90/100 [00:20<00:02,  4.38it/s]\u001b[A\n",
      " 91%|   | 91/100 [00:20<00:02,  4.37it/s]\u001b[A\n",
      " 92%|   | 92/100 [00:20<00:01,  4.36it/s]\u001b[A\n",
      " 93%|   | 93/100 [00:21<00:01,  4.37it/s]\u001b[A\n",
      " 94%|  | 94/100 [00:21<00:01,  4.35it/s]\u001b[A\n",
      " 95%|  | 95/100 [00:21<00:01,  4.35it/s]\u001b[A\n",
      " 96%| | 96/100 [00:21<00:00,  4.33it/s]\u001b[A\n",
      " 97%| | 97/100 [00:22<00:00,  4.35it/s]\u001b[A\n",
      " 98%|| 98/100 [00:22<00:00,  4.36it/s]\u001b[A\n",
      " 99%|| 99/100 [00:22<00:00,  4.35it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.47288909554481506, 'eval_runtime': 22.9473, 'eval_samples_per_second': 8.716, 'eval_steps_per_second': 4.358, 'epoch': 0.32}\n",
      " 11%|                                  | 100/936 [09:36<1:17:13,  5.54s/it]\n",
      "100%|| 100/100 [00:22<00:00,  4.39it/s]\u001b[A\n",
      "{'loss': 0.483, 'grad_norm': 0.5103364586830139, 'learning_rate': 9.895090130200888e-05, 'epoch': 0.48}\n",
      "{'loss': 0.4623, 'grad_norm': 0.6712064146995544, 'learning_rate': 9.621180444051205e-05, 'epoch': 0.64}\n",
      " 21%|                              | 200/936 [18:52<1:08:20,  5.57s/it][INFO|trainer.py:4307] 2025-05-08 23:36:03,176 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-05-08 23:36:03,176 >>   Num examples = 200\n",
      "[INFO|trainer.py:4312] 2025-05-08 23:36:03,176 >>   Batch size = 1\n",
      "\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|                                          | 2/100 [00:00<00:11,  8.64it/s]\u001b[A\n",
      "  3%|                                         | 3/100 [00:00<00:15,  6.17it/s]\u001b[A\n",
      "  4%|                                         | 4/100 [00:00<00:18,  5.32it/s]\u001b[A\n",
      "  5%|                                        | 5/100 [00:00<00:19,  4.92it/s]\u001b[A\n",
      "  6%|                                        | 6/100 [00:01<00:19,  4.70it/s]\u001b[A\n",
      "  7%|                                        | 7/100 [00:01<00:20,  4.58it/s]\u001b[A\n",
      "  8%|                                       | 8/100 [00:01<00:20,  4.51it/s]\u001b[A\n",
      "  9%|                                       | 9/100 [00:01<00:20,  4.45it/s]\u001b[A\n",
      " 10%|                                     | 10/100 [00:02<00:20,  4.42it/s]\u001b[A\n",
      " 11%|                                     | 11/100 [00:02<00:20,  4.40it/s]\u001b[A\n",
      " 12%|                                     | 12/100 [00:02<00:20,  4.38it/s]\u001b[A\n",
      " 13%|                                    | 13/100 [00:02<00:19,  4.39it/s]\u001b[A\n",
      " 14%|                                    | 14/100 [00:02<00:19,  4.36it/s]\u001b[A\n",
      " 15%|                                   | 15/100 [00:03<00:19,  4.35it/s]\u001b[A\n",
      " 16%|                                   | 16/100 [00:03<00:19,  4.34it/s]\u001b[A\n",
      " 17%|                                  | 17/100 [00:03<00:19,  4.34it/s]\u001b[A\n",
      " 18%|                                  | 18/100 [00:03<00:18,  4.33it/s]\u001b[A\n",
      " 19%|                                  | 19/100 [00:04<00:18,  4.32it/s]\u001b[A\n",
      " 20%|                                 | 20/100 [00:04<00:18,  4.32it/s]\u001b[A\n",
      " 21%|                                 | 21/100 [00:04<00:18,  4.34it/s]\u001b[A\n",
      " 22%|                                | 22/100 [00:04<00:18,  4.33it/s]\u001b[A\n",
      " 23%|                                | 23/100 [00:05<00:17,  4.33it/s]\u001b[A\n",
      " 24%|                                | 24/100 [00:05<00:17,  4.34it/s]\u001b[A\n",
      " 25%|                               | 25/100 [00:05<00:17,  4.34it/s]\u001b[A\n",
      " 26%|                               | 26/100 [00:05<00:17,  4.34it/s]\u001b[A\n",
      " 27%|                              | 27/100 [00:05<00:16,  4.35it/s]\u001b[A\n",
      " 28%|                              | 28/100 [00:06<00:16,  4.34it/s]\u001b[A\n",
      " 29%|                             | 29/100 [00:06<00:16,  4.34it/s]\u001b[A\n",
      " 30%|                             | 30/100 [00:06<00:16,  4.35it/s]\u001b[A\n",
      " 31%|                             | 31/100 [00:06<00:15,  4.36it/s]\u001b[A\n",
      " 32%|                            | 32/100 [00:07<00:15,  4.36it/s]\u001b[A\n",
      " 33%|                            | 33/100 [00:07<00:15,  4.37it/s]\u001b[A\n",
      " 34%|                           | 34/100 [00:07<00:15,  4.35it/s]\u001b[A\n",
      " 35%|                           | 35/100 [00:07<00:14,  4.35it/s]\u001b[A\n",
      " 36%|                           | 36/100 [00:08<00:14,  4.33it/s]\u001b[A\n",
      " 37%|                          | 37/100 [00:08<00:14,  4.34it/s]\u001b[A\n",
      " 38%|                          | 38/100 [00:08<00:14,  4.35it/s]\u001b[A\n",
      " 39%|                         | 39/100 [00:08<00:14,  4.34it/s]\u001b[A\n",
      " 40%|                         | 40/100 [00:08<00:13,  4.32it/s]\u001b[A\n",
      " 41%|                        | 41/100 [00:09<00:13,  4.33it/s]\u001b[A\n",
      " 42%|                        | 42/100 [00:09<00:13,  4.33it/s]\u001b[A\n",
      " 43%|                        | 43/100 [00:09<00:13,  4.33it/s]\u001b[A\n",
      " 44%|                       | 44/100 [00:09<00:12,  4.33it/s]\u001b[A\n",
      " 45%|                       | 45/100 [00:10<00:12,  4.34it/s]\u001b[A\n",
      " 46%|                      | 46/100 [00:10<00:12,  4.35it/s]\u001b[A\n",
      " 47%|                      | 47/100 [00:10<00:12,  4.37it/s]\u001b[A\n",
      " 48%|                     | 48/100 [00:10<00:11,  4.38it/s]\u001b[A\n",
      " 49%|                     | 49/100 [00:11<00:11,  4.36it/s]\u001b[A\n",
      " 50%|                     | 50/100 [00:11<00:11,  4.38it/s]\u001b[A\n",
      " 51%|                    | 51/100 [00:11<00:11,  4.38it/s]\u001b[A\n",
      " 52%|                    | 52/100 [00:11<00:11,  4.36it/s]\u001b[A\n",
      " 53%|                   | 53/100 [00:11<00:10,  4.37it/s]\u001b[A\n",
      " 54%|                   | 54/100 [00:12<00:10,  4.38it/s]\u001b[A\n",
      " 55%|                   | 55/100 [00:12<00:10,  4.35it/s]\u001b[A\n",
      " 56%|                  | 56/100 [00:12<00:10,  4.35it/s]\u001b[A\n",
      " 57%|                  | 57/100 [00:12<00:09,  4.35it/s]\u001b[A\n",
      " 58%|                 | 58/100 [00:13<00:09,  4.37it/s]\u001b[A\n",
      " 59%|                 | 59/100 [00:13<00:09,  4.36it/s]\u001b[A\n",
      " 60%|                | 60/100 [00:13<00:09,  4.36it/s]\u001b[A\n",
      " 61%|                | 61/100 [00:13<00:08,  4.36it/s]\u001b[A\n",
      " 62%|                | 62/100 [00:14<00:08,  4.37it/s]\u001b[A\n",
      " 63%|               | 63/100 [00:14<00:08,  4.35it/s]\u001b[A\n",
      " 64%|               | 64/100 [00:14<00:08,  4.35it/s]\u001b[A\n",
      " 65%|              | 65/100 [00:14<00:08,  4.37it/s]\u001b[A\n",
      " 66%|              | 66/100 [00:14<00:07,  4.36it/s]\u001b[A\n",
      " 67%|             | 67/100 [00:15<00:07,  4.35it/s]\u001b[A\n",
      " 68%|             | 68/100 [00:15<00:07,  4.36it/s]\u001b[A\n",
      " 69%|             | 69/100 [00:15<00:07,  4.35it/s]\u001b[A\n",
      " 70%|            | 70/100 [00:15<00:06,  4.37it/s]\u001b[A\n",
      " 71%|            | 71/100 [00:16<00:06,  4.36it/s]\u001b[A\n",
      " 72%|           | 72/100 [00:16<00:06,  4.35it/s]\u001b[A\n",
      " 73%|           | 73/100 [00:16<00:06,  4.35it/s]\u001b[A\n",
      " 74%|           | 74/100 [00:16<00:05,  4.37it/s]\u001b[A\n",
      " 75%|          | 75/100 [00:17<00:05,  4.36it/s]\u001b[A\n",
      " 76%|          | 76/100 [00:17<00:05,  4.38it/s]\u001b[A\n",
      " 77%|         | 77/100 [00:17<00:05,  4.39it/s]\u001b[A\n",
      " 78%|         | 78/100 [00:17<00:05,  4.38it/s]\u001b[A\n",
      " 79%|        | 79/100 [00:17<00:04,  4.36it/s]\u001b[A\n",
      " 80%|        | 80/100 [00:18<00:04,  4.35it/s]\u001b[A\n",
      " 81%|        | 81/100 [00:18<00:04,  4.36it/s]\u001b[A\n",
      " 82%|       | 82/100 [00:18<00:04,  4.36it/s]\u001b[A\n",
      " 83%|       | 83/100 [00:18<00:03,  4.35it/s]\u001b[A\n",
      " 84%|      | 84/100 [00:19<00:03,  4.35it/s]\u001b[A\n",
      " 85%|      | 85/100 [00:19<00:03,  4.35it/s]\u001b[A\n",
      " 86%|      | 86/100 [00:19<00:03,  4.34it/s]\u001b[A\n",
      " 87%|     | 87/100 [00:19<00:03,  4.33it/s]\u001b[A\n",
      " 88%|     | 88/100 [00:20<00:02,  4.33it/s]\u001b[A\n",
      " 89%|    | 89/100 [00:20<00:02,  4.35it/s]\u001b[A\n",
      " 90%|    | 90/100 [00:20<00:02,  4.37it/s]\u001b[A\n",
      " 91%|   | 91/100 [00:20<00:02,  4.36it/s]\u001b[A\n",
      " 92%|   | 92/100 [00:20<00:01,  4.35it/s]\u001b[A\n",
      " 93%|   | 93/100 [00:21<00:01,  4.36it/s]\u001b[A\n",
      " 94%|  | 94/100 [00:21<00:01,  4.37it/s]\u001b[A\n",
      " 95%|  | 95/100 [00:21<00:01,  4.36it/s]\u001b[A\n",
      " 96%| | 96/100 [00:21<00:00,  4.34it/s]\u001b[A\n",
      " 97%| | 97/100 [00:22<00:00,  4.33it/s]\u001b[A\n",
      " 98%|| 98/100 [00:22<00:00,  4.36it/s]\u001b[A\n",
      " 99%|| 99/100 [00:22<00:00,  4.35it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.4403047263622284, 'eval_runtime': 22.9792, 'eval_samples_per_second': 8.704, 'eval_steps_per_second': 4.352, 'epoch': 0.64}\n",
      " 21%|                              | 200/936 [19:15<1:08:20,  5.57s/it]\n",
      "100%|| 100/100 [00:22<00:00,  4.37it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3984] 2025-05-08 23:36:26,161 >> Saving model checkpoint to /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-200\n",
      "[INFO|configuration_utils.py:693] 2025-05-08 23:36:26,326 >> loading configuration file config.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
      "[INFO|configuration_utils.py:765] 2025-05-08 23:36:26,327 >> Model config Qwen3Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-05-08 23:36:26,704 >> tokenizer config file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-05-08 23:36:26,705 >> Special tokens file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-200/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-05-08 23:36:27,526 >> tokenizer config file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-05-08 23:36:27,527 >> Special tokens file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/special_tokens_map.json\n",
      "{'loss': 0.4508, 'grad_norm': 0.4003492593765259, 'learning_rate': 9.186906132905563e-05, 'epoch': 0.8}\n",
      "{'loss': 0.4483, 'grad_norm': 0.5363093018531799, 'learning_rate': 8.607337423493995e-05, 'epoch': 0.96}\n",
      " 32%|                           | 300/936 [28:33<59:02,  5.57s/it][INFO|trainer.py:4307] 2025-05-08 23:45:44,097 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-05-08 23:45:44,097 >>   Num examples = 200\n",
      "[INFO|trainer.py:4312] 2025-05-08 23:45:44,098 >>   Batch size = 1\n",
      "\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|                                          | 2/100 [00:00<00:11,  8.83it/s]\u001b[A\n",
      "  3%|                                         | 3/100 [00:00<00:15,  6.18it/s]\u001b[A\n",
      "  4%|                                         | 4/100 [00:00<00:17,  5.36it/s]\u001b[A\n",
      "  5%|                                        | 5/100 [00:00<00:19,  4.98it/s]\u001b[A\n",
      "  6%|                                        | 6/100 [00:01<00:19,  4.75it/s]\u001b[A\n",
      "  7%|                                        | 7/100 [00:01<00:20,  4.63it/s]\u001b[A\n",
      "  8%|                                       | 8/100 [00:01<00:20,  4.55it/s]\u001b[A\n",
      "  9%|                                       | 9/100 [00:01<00:20,  4.49it/s]\u001b[A\n",
      " 10%|                                     | 10/100 [00:02<00:20,  4.44it/s]\u001b[A\n",
      " 11%|                                     | 11/100 [00:02<00:20,  4.43it/s]\u001b[A\n",
      " 12%|                                     | 12/100 [00:02<00:20,  4.39it/s]\u001b[A\n",
      " 13%|                                    | 13/100 [00:02<00:19,  4.39it/s]\u001b[A\n",
      " 14%|                                    | 14/100 [00:02<00:19,  4.37it/s]\u001b[A\n",
      " 15%|                                   | 15/100 [00:03<00:19,  4.37it/s]\u001b[A\n",
      " 16%|                                   | 16/100 [00:03<00:19,  4.36it/s]\u001b[A\n",
      " 17%|                                  | 17/100 [00:03<00:19,  4.36it/s]\u001b[A\n",
      " 18%|                                  | 18/100 [00:03<00:18,  4.35it/s]\u001b[A\n",
      " 19%|                                  | 19/100 [00:04<00:18,  4.36it/s]\u001b[A\n",
      " 20%|                                 | 20/100 [00:04<00:18,  4.34it/s]\u001b[A\n",
      " 21%|                                 | 21/100 [00:04<00:18,  4.36it/s]\u001b[A\n",
      " 22%|                                | 22/100 [00:04<00:17,  4.37it/s]\u001b[A\n",
      " 23%|                                | 23/100 [00:05<00:17,  4.36it/s]\u001b[A\n",
      " 24%|                                | 24/100 [00:05<00:17,  4.36it/s]\u001b[A\n",
      " 25%|                               | 25/100 [00:05<00:17,  4.35it/s]\u001b[A\n",
      " 26%|                               | 26/100 [00:05<00:16,  4.36it/s]\u001b[A\n",
      " 27%|                              | 27/100 [00:05<00:16,  4.36it/s]\u001b[A\n",
      " 28%|                              | 28/100 [00:06<00:16,  4.34it/s]\u001b[A\n",
      " 29%|                             | 29/100 [00:06<00:16,  4.35it/s]\u001b[A\n",
      " 30%|                             | 30/100 [00:06<00:16,  4.35it/s]\u001b[A\n",
      " 31%|                             | 31/100 [00:06<00:15,  4.35it/s]\u001b[A\n",
      " 32%|                            | 32/100 [00:07<00:15,  4.36it/s]\u001b[A\n",
      " 33%|                            | 33/100 [00:07<00:15,  4.35it/s]\u001b[A\n",
      " 34%|                           | 34/100 [00:07<00:15,  4.35it/s]\u001b[A\n",
      " 35%|                           | 35/100 [00:07<00:14,  4.34it/s]\u001b[A\n",
      " 36%|                           | 36/100 [00:08<00:14,  4.34it/s]\u001b[A\n",
      " 37%|                          | 37/100 [00:08<00:14,  4.35it/s]\u001b[A\n",
      " 38%|                          | 38/100 [00:08<00:14,  4.36it/s]\u001b[A\n",
      " 39%|                         | 39/100 [00:08<00:14,  4.35it/s]\u001b[A\n",
      " 40%|                         | 40/100 [00:08<00:13,  4.33it/s]\u001b[A\n",
      " 41%|                        | 41/100 [00:09<00:13,  4.34it/s]\u001b[A\n",
      " 42%|                        | 42/100 [00:09<00:13,  4.34it/s]\u001b[A\n",
      " 43%|                        | 43/100 [00:09<00:13,  4.34it/s]\u001b[A\n",
      " 44%|                       | 44/100 [00:09<00:12,  4.37it/s]\u001b[A\n",
      " 45%|                       | 45/100 [00:10<00:12,  4.35it/s]\u001b[A\n",
      " 46%|                      | 46/100 [00:10<00:12,  4.33it/s]\u001b[A\n",
      " 47%|                      | 47/100 [00:10<00:12,  4.36it/s]\u001b[A\n",
      " 48%|                     | 48/100 [00:10<00:11,  4.36it/s]\u001b[A\n",
      " 49%|                     | 49/100 [00:11<00:11,  4.36it/s]\u001b[A\n",
      " 50%|                     | 50/100 [00:11<00:11,  4.37it/s]\u001b[A\n",
      " 51%|                    | 51/100 [00:11<00:11,  4.37it/s]\u001b[A\n",
      " 52%|                    | 52/100 [00:11<00:10,  4.37it/s]\u001b[A\n",
      " 53%|                   | 53/100 [00:11<00:10,  4.37it/s]\u001b[A\n",
      " 54%|                   | 54/100 [00:12<00:10,  4.37it/s]\u001b[A\n",
      " 55%|                   | 55/100 [00:12<00:10,  4.37it/s]\u001b[A\n",
      " 56%|                  | 56/100 [00:12<00:10,  4.37it/s]\u001b[A\n",
      " 57%|                  | 57/100 [00:12<00:09,  4.37it/s]\u001b[A\n",
      " 58%|                 | 58/100 [00:13<00:09,  4.39it/s]\u001b[A\n",
      " 59%|                 | 59/100 [00:13<00:09,  4.37it/s]\u001b[A\n",
      " 60%|                | 60/100 [00:13<00:09,  4.37it/s]\u001b[A\n",
      " 61%|                | 61/100 [00:13<00:08,  4.38it/s]\u001b[A\n",
      " 62%|                | 62/100 [00:13<00:08,  4.37it/s]\u001b[A\n",
      " 63%|               | 63/100 [00:14<00:08,  4.35it/s]\u001b[A\n",
      " 64%|               | 64/100 [00:14<00:08,  4.35it/s]\u001b[A\n",
      " 65%|              | 65/100 [00:14<00:08,  4.35it/s]\u001b[A\n",
      " 66%|              | 66/100 [00:14<00:07,  4.35it/s]\u001b[A\n",
      " 67%|             | 67/100 [00:15<00:07,  4.35it/s]\u001b[A\n",
      " 68%|             | 68/100 [00:15<00:07,  4.35it/s]\u001b[A\n",
      " 69%|             | 69/100 [00:15<00:07,  4.34it/s]\u001b[A\n",
      " 70%|            | 70/100 [00:15<00:06,  4.36it/s]\u001b[A\n",
      " 71%|            | 71/100 [00:16<00:06,  4.35it/s]\u001b[A\n",
      " 72%|           | 72/100 [00:16<00:06,  4.36it/s]\u001b[A\n",
      " 73%|           | 73/100 [00:16<00:06,  4.37it/s]\u001b[A\n",
      " 74%|           | 74/100 [00:16<00:05,  4.39it/s]\u001b[A\n",
      " 75%|          | 75/100 [00:16<00:05,  4.38it/s]\u001b[A\n",
      " 76%|          | 76/100 [00:17<00:05,  4.38it/s]\u001b[A\n",
      " 77%|         | 77/100 [00:17<00:05,  4.37it/s]\u001b[A\n",
      " 78%|         | 78/100 [00:17<00:05,  4.37it/s]\u001b[A\n",
      " 79%|        | 79/100 [00:17<00:04,  4.36it/s]\u001b[A\n",
      " 80%|        | 80/100 [00:18<00:04,  4.34it/s]\u001b[A\n",
      " 81%|        | 81/100 [00:18<00:04,  4.34it/s]\u001b[A\n",
      " 82%|       | 82/100 [00:18<00:04,  4.35it/s]\u001b[A\n",
      " 83%|       | 83/100 [00:18<00:03,  4.35it/s]\u001b[A\n",
      " 84%|      | 84/100 [00:19<00:03,  4.37it/s]\u001b[A\n",
      " 85%|      | 85/100 [00:19<00:03,  4.38it/s]\u001b[A\n",
      " 86%|      | 86/100 [00:19<00:03,  4.39it/s]\u001b[A\n",
      " 87%|     | 87/100 [00:19<00:02,  4.39it/s]\u001b[A\n",
      " 88%|     | 88/100 [00:19<00:02,  4.38it/s]\u001b[A\n",
      " 89%|    | 89/100 [00:20<00:02,  4.37it/s]\u001b[A\n",
      " 90%|    | 90/100 [00:20<00:02,  4.37it/s]\u001b[A\n",
      " 91%|   | 91/100 [00:20<00:02,  4.36it/s]\u001b[A\n",
      " 92%|   | 92/100 [00:20<00:01,  4.37it/s]\u001b[A\n",
      " 93%|   | 93/100 [00:21<00:01,  4.38it/s]\u001b[A\n",
      " 94%|  | 94/100 [00:21<00:01,  4.35it/s]\u001b[A\n",
      " 95%|  | 95/100 [00:21<00:01,  4.35it/s]\u001b[A\n",
      " 96%| | 96/100 [00:21<00:00,  4.35it/s]\u001b[A\n",
      " 97%| | 97/100 [00:22<00:00,  4.34it/s]\u001b[A\n",
      " 98%|| 98/100 [00:22<00:00,  4.35it/s]\u001b[A\n",
      " 99%|| 99/100 [00:22<00:00,  4.36it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.4345220923423767, 'eval_runtime': 22.9255, 'eval_samples_per_second': 8.724, 'eval_steps_per_second': 4.362, 'epoch': 0.96}\n",
      " 32%|                           | 300/936 [28:56<59:02,  5.57s/it]\n",
      "100%|| 100/100 [00:22<00:00,  4.38it/s]\u001b[A\n",
      "{'loss': 0.4484, 'grad_norm': 0.3328734338283539, 'learning_rate': 7.902586561998929e-05, 'epoch': 1.12}\n",
      "{'loss': 0.4403, 'grad_norm': 0.3535067141056061, 'learning_rate': 7.097109877054907e-05, 'epoch': 1.28}\n",
      " 43%|                       | 400/936 [38:18<50:36,  5.67s/it][INFO|trainer.py:4307] 2025-05-08 23:55:28,420 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-05-08 23:55:28,420 >>   Num examples = 200\n",
      "[INFO|trainer.py:4312] 2025-05-08 23:55:28,421 >>   Batch size = 1\n",
      "\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|                                          | 2/100 [00:00<00:11,  8.45it/s]\u001b[A\n",
      "  3%|                                         | 3/100 [00:00<00:16,  5.95it/s]\u001b[A\n",
      "  4%|                                         | 4/100 [00:00<00:18,  5.19it/s]\u001b[A\n",
      "  5%|                                        | 5/100 [00:00<00:19,  4.83it/s]\u001b[A\n",
      "  6%|                                        | 6/100 [00:01<00:20,  4.62it/s]\u001b[A\n",
      "  7%|                                        | 7/100 [00:01<00:20,  4.48it/s]\u001b[A\n",
      "  8%|                                       | 8/100 [00:01<00:20,  4.40it/s]\u001b[A\n",
      "  9%|                                       | 9/100 [00:01<00:20,  4.35it/s]\u001b[A\n",
      " 10%|                                     | 10/100 [00:02<00:20,  4.31it/s]\u001b[A\n",
      " 11%|                                     | 11/100 [00:02<00:20,  4.30it/s]\u001b[A\n",
      " 12%|                                     | 12/100 [00:02<00:20,  4.29it/s]\u001b[A\n",
      " 13%|                                    | 13/100 [00:02<00:20,  4.26it/s]\u001b[A\n",
      " 14%|                                    | 14/100 [00:03<00:20,  4.27it/s]\u001b[A\n",
      " 15%|                                   | 15/100 [00:03<00:19,  4.26it/s]\u001b[A\n",
      " 16%|                                   | 16/100 [00:03<00:19,  4.27it/s]\u001b[A\n",
      " 17%|                                  | 17/100 [00:03<00:19,  4.28it/s]\u001b[A\n",
      " 18%|                                  | 18/100 [00:04<00:19,  4.27it/s]\u001b[A\n",
      " 19%|                                  | 19/100 [00:04<00:18,  4.28it/s]\u001b[A\n",
      " 20%|                                 | 20/100 [00:04<00:18,  4.27it/s]\u001b[A\n",
      " 21%|                                 | 21/100 [00:04<00:18,  4.25it/s]\u001b[A\n",
      " 22%|                                | 22/100 [00:04<00:18,  4.25it/s]\u001b[A\n",
      " 23%|                                | 23/100 [00:05<00:18,  4.27it/s]\u001b[A\n",
      " 24%|                                | 24/100 [00:05<00:17,  4.27it/s]\u001b[A\n",
      " 25%|                               | 25/100 [00:05<00:17,  4.25it/s]\u001b[A\n",
      " 26%|                               | 26/100 [00:05<00:17,  4.27it/s]\u001b[A\n",
      " 27%|                              | 27/100 [00:06<00:17,  4.28it/s]\u001b[A\n",
      " 28%|                              | 28/100 [00:06<00:16,  4.29it/s]\u001b[A\n",
      " 29%|                             | 29/100 [00:06<00:16,  4.28it/s]\u001b[A\n",
      " 30%|                             | 30/100 [00:06<00:16,  4.27it/s]\u001b[A\n",
      " 31%|                             | 31/100 [00:07<00:16,  4.26it/s]\u001b[A\n",
      " 32%|                            | 32/100 [00:07<00:16,  4.24it/s]\u001b[A\n",
      " 33%|                            | 33/100 [00:07<00:15,  4.24it/s]\u001b[A\n",
      " 34%|                           | 34/100 [00:07<00:15,  4.24it/s]\u001b[A\n",
      " 35%|                           | 35/100 [00:07<00:15,  4.26it/s]\u001b[A\n",
      " 36%|                           | 36/100 [00:08<00:14,  4.27it/s]\u001b[A\n",
      " 37%|                          | 37/100 [00:08<00:14,  4.24it/s]\u001b[A\n",
      " 38%|                          | 38/100 [00:08<00:14,  4.27it/s]\u001b[A\n",
      " 39%|                         | 39/100 [00:08<00:14,  4.27it/s]\u001b[A\n",
      " 40%|                         | 40/100 [00:09<00:14,  4.25it/s]\u001b[A\n",
      " 41%|                        | 41/100 [00:09<00:13,  4.26it/s]\u001b[A\n",
      " 42%|                        | 42/100 [00:09<00:13,  4.27it/s]\u001b[A\n",
      " 43%|                        | 43/100 [00:09<00:13,  4.26it/s]\u001b[A\n",
      " 44%|                       | 44/100 [00:10<00:13,  4.25it/s]\u001b[A\n",
      " 45%|                       | 45/100 [00:10<00:12,  4.23it/s]\u001b[A\n",
      " 46%|                      | 46/100 [00:10<00:12,  4.27it/s]\u001b[A\n",
      " 47%|                      | 47/100 [00:10<00:12,  4.27it/s]\u001b[A\n",
      " 48%|                     | 48/100 [00:11<00:12,  4.26it/s]\u001b[A\n",
      " 49%|                     | 49/100 [00:11<00:11,  4.26it/s]\u001b[A\n",
      " 50%|                     | 50/100 [00:11<00:11,  4.24it/s]\u001b[A\n",
      " 51%|                    | 51/100 [00:11<00:11,  4.24it/s]\u001b[A\n",
      " 52%|                    | 52/100 [00:11<00:11,  4.27it/s]\u001b[A\n",
      " 53%|                   | 53/100 [00:12<00:11,  4.26it/s]\u001b[A\n",
      " 54%|                   | 54/100 [00:12<00:10,  4.27it/s]\u001b[A\n",
      " 55%|                   | 55/100 [00:12<00:10,  4.27it/s]\u001b[A\n",
      " 56%|                  | 56/100 [00:12<00:10,  4.30it/s]\u001b[A\n",
      " 57%|                  | 57/100 [00:13<00:10,  4.30it/s]\u001b[A\n",
      " 58%|                 | 58/100 [00:13<00:09,  4.31it/s]\u001b[A\n",
      " 59%|                 | 59/100 [00:13<00:09,  4.28it/s]\u001b[A\n",
      " 60%|                | 60/100 [00:13<00:09,  4.30it/s]\u001b[A\n",
      " 61%|                | 61/100 [00:14<00:09,  4.30it/s]\u001b[A\n",
      " 62%|                | 62/100 [00:14<00:08,  4.30it/s]\u001b[A\n",
      " 63%|               | 63/100 [00:14<00:08,  4.29it/s]\u001b[A\n",
      " 64%|               | 64/100 [00:14<00:08,  4.27it/s]\u001b[A\n",
      " 65%|              | 65/100 [00:15<00:08,  4.28it/s]\u001b[A\n",
      " 66%|              | 66/100 [00:15<00:07,  4.27it/s]\u001b[A\n",
      " 67%|             | 67/100 [00:15<00:07,  4.27it/s]\u001b[A\n",
      " 68%|             | 68/100 [00:15<00:07,  4.28it/s]\u001b[A\n",
      " 69%|             | 69/100 [00:15<00:07,  4.29it/s]\u001b[A\n",
      " 70%|            | 70/100 [00:16<00:07,  4.26it/s]\u001b[A\n",
      " 71%|            | 71/100 [00:16<00:06,  4.27it/s]\u001b[A\n",
      " 72%|           | 72/100 [00:16<00:06,  4.28it/s]\u001b[A\n",
      " 73%|           | 73/100 [00:16<00:06,  4.31it/s]\u001b[A\n",
      " 74%|           | 74/100 [00:17<00:06,  4.31it/s]\u001b[A\n",
      " 75%|          | 75/100 [00:17<00:05,  4.30it/s]\u001b[A\n",
      " 76%|          | 76/100 [00:17<00:05,  4.29it/s]\u001b[A\n",
      " 77%|         | 77/100 [00:17<00:05,  4.30it/s]\u001b[A\n",
      " 78%|         | 78/100 [00:18<00:05,  4.30it/s]\u001b[A\n",
      " 79%|        | 79/100 [00:18<00:04,  4.29it/s]\u001b[A\n",
      " 80%|        | 80/100 [00:18<00:04,  4.28it/s]\u001b[A\n",
      " 81%|        | 81/100 [00:18<00:04,  4.29it/s]\u001b[A\n",
      " 82%|       | 82/100 [00:18<00:04,  4.28it/s]\u001b[A\n",
      " 83%|       | 83/100 [00:19<00:03,  4.29it/s]\u001b[A\n",
      " 84%|      | 84/100 [00:19<00:03,  4.26it/s]\u001b[A\n",
      " 85%|      | 85/100 [00:19<00:03,  4.26it/s]\u001b[A\n",
      " 86%|      | 86/100 [00:19<00:03,  4.27it/s]\u001b[A\n",
      " 87%|     | 87/100 [00:20<00:03,  4.26it/s]\u001b[A\n",
      " 88%|     | 88/100 [00:20<00:02,  4.26it/s]\u001b[A\n",
      " 89%|    | 89/100 [00:20<00:02,  4.25it/s]\u001b[A\n",
      " 90%|    | 90/100 [00:20<00:02,  4.25it/s]\u001b[A\n",
      " 91%|   | 91/100 [00:21<00:02,  4.26it/s]\u001b[A\n",
      " 92%|   | 92/100 [00:21<00:01,  4.25it/s]\u001b[A\n",
      " 93%|   | 93/100 [00:21<00:01,  4.26it/s]\u001b[A\n",
      " 94%|  | 94/100 [00:21<00:01,  4.26it/s]\u001b[A\n",
      " 95%|  | 95/100 [00:22<00:01,  4.25it/s]\u001b[A\n",
      " 96%| | 96/100 [00:22<00:00,  4.26it/s]\u001b[A\n",
      " 97%| | 97/100 [00:22<00:00,  4.25it/s]\u001b[A\n",
      " 98%|| 98/100 [00:22<00:00,  4.26it/s]\u001b[A\n",
      " 99%|| 99/100 [00:22<00:00,  4.25it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.42671313881874084, 'eval_runtime': 23.4315, 'eval_samples_per_second': 8.536, 'eval_steps_per_second': 4.268, 'epoch': 1.28}\n",
      " 43%|                       | 400/936 [38:41<50:36,  5.67s/it]\n",
      "100%|| 100/100 [00:23<00:00,  4.27it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3984] 2025-05-08 23:55:51,858 >> Saving model checkpoint to /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-400\n",
      "[INFO|configuration_utils.py:693] 2025-05-08 23:55:52,050 >> loading configuration file config.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
      "[INFO|configuration_utils.py:765] 2025-05-08 23:55:52,052 >> Model config Qwen3Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-05-08 23:55:52,521 >> tokenizer config file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-05-08 23:55:52,522 >> Special tokens file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-400/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-05-08 23:55:53,733 >> tokenizer config file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-05-08 23:55:53,734 >> Special tokens file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/special_tokens_map.json\n",
      "{'loss': 0.4396, 'grad_norm': 0.4065883159637451, 'learning_rate': 6.218859094003082e-05, 'epoch': 1.44}\n",
      "{'loss': 0.4414, 'grad_norm': 0.5127588510513306, 'learning_rate': 5.298311351570604e-05, 'epoch': 1.6}\n",
      " 53%|                   | 500/936 [48:08<40:48,  5.61s/it][INFO|trainer.py:4307] 2025-05-09 00:05:19,134 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-05-09 00:05:19,134 >>   Num examples = 200\n",
      "[INFO|trainer.py:4312] 2025-05-09 00:05:19,135 >>   Batch size = 1\n",
      "\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|                                          | 2/100 [00:00<00:11,  8.70it/s]\u001b[A\n",
      "  3%|                                         | 3/100 [00:00<00:15,  6.11it/s]\u001b[A\n",
      "  4%|                                         | 4/100 [00:00<00:18,  5.30it/s]\u001b[A\n",
      "  5%|                                        | 5/100 [00:00<00:19,  4.90it/s]\u001b[A\n",
      "  6%|                                        | 6/100 [00:01<00:20,  4.70it/s]\u001b[A\n",
      "  7%|                                        | 7/100 [00:01<00:20,  4.57it/s]\u001b[A\n",
      "  8%|                                       | 8/100 [00:01<00:20,  4.49it/s]\u001b[A\n",
      "  9%|                                       | 9/100 [00:01<00:20,  4.43it/s]\u001b[A\n",
      " 10%|                                     | 10/100 [00:02<00:20,  4.38it/s]\u001b[A\n",
      " 11%|                                     | 11/100 [00:02<00:20,  4.35it/s]\u001b[A\n",
      " 12%|                                     | 12/100 [00:02<00:20,  4.34it/s]\u001b[A\n",
      " 13%|                                    | 13/100 [00:02<00:20,  4.33it/s]\u001b[A\n",
      " 14%|                                    | 14/100 [00:03<00:19,  4.32it/s]\u001b[A\n",
      " 15%|                                   | 15/100 [00:03<00:19,  4.31it/s]\u001b[A\n",
      " 16%|                                   | 16/100 [00:03<00:19,  4.30it/s]\u001b[A\n",
      " 17%|                                  | 17/100 [00:03<00:19,  4.32it/s]\u001b[A\n",
      " 18%|                                  | 18/100 [00:03<00:19,  4.30it/s]\u001b[A\n",
      " 19%|                                  | 19/100 [00:04<00:18,  4.32it/s]\u001b[A\n",
      " 20%|                                 | 20/100 [00:04<00:18,  4.31it/s]\u001b[A\n",
      " 21%|                                 | 21/100 [00:04<00:18,  4.30it/s]\u001b[A\n",
      " 22%|                                | 22/100 [00:04<00:18,  4.30it/s]\u001b[A\n",
      " 23%|                                | 23/100 [00:05<00:17,  4.31it/s]\u001b[A\n",
      " 24%|                                | 24/100 [00:05<00:17,  4.32it/s]\u001b[A\n",
      " 25%|                               | 25/100 [00:05<00:17,  4.33it/s]\u001b[A\n",
      " 26%|                               | 26/100 [00:05<00:17,  4.33it/s]\u001b[A\n",
      " 27%|                              | 27/100 [00:06<00:16,  4.31it/s]\u001b[A\n",
      " 28%|                              | 28/100 [00:06<00:16,  4.33it/s]\u001b[A\n",
      " 29%|                             | 29/100 [00:06<00:16,  4.32it/s]\u001b[A\n",
      " 30%|                             | 30/100 [00:06<00:16,  4.31it/s]\u001b[A\n",
      " 31%|                             | 31/100 [00:06<00:15,  4.33it/s]\u001b[A\n",
      " 32%|                            | 32/100 [00:07<00:15,  4.33it/s]\u001b[A\n",
      " 33%|                            | 33/100 [00:07<00:15,  4.35it/s]\u001b[A\n",
      " 34%|                           | 34/100 [00:07<00:15,  4.32it/s]\u001b[A\n",
      " 35%|                           | 35/100 [00:07<00:15,  4.32it/s]\u001b[A\n",
      " 36%|                           | 36/100 [00:08<00:14,  4.35it/s]\u001b[A\n",
      " 37%|                          | 37/100 [00:08<00:14,  4.34it/s]\u001b[A\n",
      " 38%|                          | 38/100 [00:08<00:14,  4.36it/s]\u001b[A\n",
      " 39%|                         | 39/100 [00:08<00:14,  4.33it/s]\u001b[A\n",
      " 40%|                         | 40/100 [00:09<00:13,  4.33it/s]\u001b[A\n",
      " 41%|                        | 41/100 [00:09<00:13,  4.34it/s]\u001b[A\n",
      " 42%|                        | 42/100 [00:09<00:13,  4.35it/s]\u001b[A\n",
      " 43%|                        | 43/100 [00:09<00:13,  4.35it/s]\u001b[A\n",
      " 44%|                       | 44/100 [00:09<00:12,  4.32it/s]\u001b[A\n",
      " 45%|                       | 45/100 [00:10<00:12,  4.32it/s]\u001b[A\n",
      " 46%|                      | 46/100 [00:10<00:12,  4.33it/s]\u001b[A\n",
      " 47%|                      | 47/100 [00:10<00:12,  4.33it/s]\u001b[A\n",
      " 48%|                     | 48/100 [00:10<00:12,  4.30it/s]\u001b[A\n",
      " 49%|                     | 49/100 [00:11<00:11,  4.31it/s]\u001b[A\n",
      " 50%|                     | 50/100 [00:11<00:11,  4.30it/s]\u001b[A\n",
      " 51%|                    | 51/100 [00:11<00:11,  4.32it/s]\u001b[A\n",
      " 52%|                    | 52/100 [00:11<00:11,  4.32it/s]\u001b[A\n",
      " 53%|                   | 53/100 [00:12<00:10,  4.31it/s]\u001b[A\n",
      " 54%|                   | 54/100 [00:12<00:10,  4.30it/s]\u001b[A\n",
      " 55%|                   | 55/100 [00:12<00:10,  4.30it/s]\u001b[A\n",
      " 56%|                  | 56/100 [00:12<00:10,  4.32it/s]\u001b[A\n",
      " 57%|                  | 57/100 [00:12<00:09,  4.33it/s]\u001b[A\n",
      " 58%|                 | 58/100 [00:13<00:09,  4.34it/s]\u001b[A\n",
      " 59%|                 | 59/100 [00:13<00:09,  4.34it/s]\u001b[A\n",
      " 60%|                | 60/100 [00:13<00:09,  4.36it/s]\u001b[A\n",
      " 61%|                | 61/100 [00:13<00:08,  4.35it/s]\u001b[A\n",
      " 62%|                | 62/100 [00:14<00:08,  4.34it/s]\u001b[A\n",
      " 63%|               | 63/100 [00:14<00:08,  4.31it/s]\u001b[A\n",
      " 64%|               | 64/100 [00:14<00:08,  4.33it/s]\u001b[A\n",
      " 65%|              | 65/100 [00:14<00:08,  4.32it/s]\u001b[A\n",
      " 66%|              | 66/100 [00:15<00:07,  4.31it/s]\u001b[A\n",
      " 67%|             | 67/100 [00:15<00:07,  4.31it/s]\u001b[A\n",
      " 68%|             | 68/100 [00:15<00:07,  4.33it/s]\u001b[A\n",
      " 69%|             | 69/100 [00:15<00:07,  4.35it/s]\u001b[A\n",
      " 70%|            | 70/100 [00:15<00:06,  4.36it/s]\u001b[A\n",
      " 71%|            | 71/100 [00:16<00:06,  4.34it/s]\u001b[A\n",
      " 72%|           | 72/100 [00:16<00:06,  4.35it/s]\u001b[A\n",
      " 73%|           | 73/100 [00:16<00:06,  4.36it/s]\u001b[A\n",
      " 74%|           | 74/100 [00:16<00:05,  4.36it/s]\u001b[A\n",
      " 75%|          | 75/100 [00:17<00:05,  4.35it/s]\u001b[A\n",
      " 76%|          | 76/100 [00:17<00:05,  4.36it/s]\u001b[A\n",
      " 77%|         | 77/100 [00:17<00:05,  4.36it/s]\u001b[A\n",
      " 78%|         | 78/100 [00:17<00:05,  4.36it/s]\u001b[A\n",
      " 79%|        | 79/100 [00:18<00:04,  4.35it/s]\u001b[A\n",
      " 80%|        | 80/100 [00:18<00:04,  4.35it/s]\u001b[A\n",
      " 81%|        | 81/100 [00:18<00:04,  4.32it/s]\u001b[A\n",
      " 82%|       | 82/100 [00:18<00:04,  4.33it/s]\u001b[A\n",
      " 83%|       | 83/100 [00:18<00:03,  4.33it/s]\u001b[A\n",
      " 84%|      | 84/100 [00:19<00:03,  4.34it/s]\u001b[A\n",
      " 85%|      | 85/100 [00:19<00:03,  4.35it/s]\u001b[A\n",
      " 86%|      | 86/100 [00:19<00:03,  4.33it/s]\u001b[A\n",
      " 87%|     | 87/100 [00:19<00:03,  4.33it/s]\u001b[A\n",
      " 88%|     | 88/100 [00:20<00:02,  4.34it/s]\u001b[A\n",
      " 89%|    | 89/100 [00:20<00:02,  4.34it/s]\u001b[A\n",
      " 90%|    | 90/100 [00:20<00:02,  4.31it/s]\u001b[A\n",
      " 91%|   | 91/100 [00:20<00:02,  4.31it/s]\u001b[A\n",
      " 92%|   | 92/100 [00:21<00:01,  4.31it/s]\u001b[A\n",
      " 93%|   | 93/100 [00:21<00:01,  4.31it/s]\u001b[A\n",
      " 94%|  | 94/100 [00:21<00:01,  4.33it/s]\u001b[A\n",
      " 95%|  | 95/100 [00:21<00:01,  4.32it/s]\u001b[A\n",
      " 96%| | 96/100 [00:21<00:00,  4.30it/s]\u001b[A\n",
      " 97%| | 97/100 [00:22<00:00,  4.34it/s]\u001b[A\n",
      " 98%|| 98/100 [00:22<00:00,  4.33it/s]\u001b[A\n",
      " 99%|| 99/100 [00:22<00:00,  4.35it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.42922675609588623, 'eval_runtime': 23.0934, 'eval_samples_per_second': 8.66, 'eval_steps_per_second': 4.33, 'epoch': 1.6}\n",
      " 53%|                   | 500/936 [48:31<40:48,  5.61s/it]\n",
      "100%|| 100/100 [00:22<00:00,  4.39it/s]\u001b[A\n",
      "{'loss': 0.4347, 'grad_norm': 0.3257627785205841, 'learning_rate': 4.367411581424459e-05, 'epoch': 1.76}\n",
      "{'loss': 0.4368, 'grad_norm': 0.5264989137649536, 'learning_rate': 3.4584639522409665e-05, 'epoch': 1.92}\n",
      " 64%|              | 600/936 [57:48<31:06,  5.55s/it][INFO|trainer.py:4307] 2025-05-09 00:14:58,788 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-05-09 00:14:58,789 >>   Num examples = 200\n",
      "[INFO|trainer.py:4312] 2025-05-09 00:14:58,789 >>   Batch size = 1\n",
      "\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|                                          | 2/100 [00:00<00:11,  8.70it/s]\u001b[A\n",
      "  3%|                                         | 3/100 [00:00<00:15,  6.14it/s]\u001b[A\n",
      "  4%|                                         | 4/100 [00:00<00:18,  5.33it/s]\u001b[A\n",
      "  5%|                                        | 5/100 [00:00<00:19,  4.94it/s]\u001b[A\n",
      "  6%|                                        | 6/100 [00:01<00:19,  4.71it/s]\u001b[A\n",
      "  7%|                                        | 7/100 [00:01<00:20,  4.61it/s]\u001b[A\n",
      "  8%|                                       | 8/100 [00:01<00:20,  4.52it/s]\u001b[A\n",
      "  9%|                                       | 9/100 [00:01<00:20,  4.46it/s]\u001b[A\n",
      " 10%|                                     | 10/100 [00:02<00:20,  4.41it/s]\u001b[A\n",
      " 11%|                                     | 11/100 [00:02<00:20,  4.40it/s]\u001b[A\n",
      " 12%|                                     | 12/100 [00:02<00:20,  4.38it/s]\u001b[A\n",
      " 13%|                                    | 13/100 [00:02<00:19,  4.38it/s]\u001b[A\n",
      " 14%|                                    | 14/100 [00:02<00:19,  4.39it/s]\u001b[A\n",
      " 15%|                                   | 15/100 [00:03<00:19,  4.37it/s]\u001b[A\n",
      " 16%|                                   | 16/100 [00:03<00:19,  4.36it/s]\u001b[A\n",
      " 17%|                                  | 17/100 [00:03<00:19,  4.36it/s]\u001b[A\n",
      " 18%|                                  | 18/100 [00:03<00:18,  4.36it/s]\u001b[A\n",
      " 19%|                                  | 19/100 [00:04<00:18,  4.36it/s]\u001b[A\n",
      " 20%|                                 | 20/100 [00:04<00:18,  4.36it/s]\u001b[A\n",
      " 21%|                                 | 21/100 [00:04<00:18,  4.35it/s]\u001b[A\n",
      " 22%|                                | 22/100 [00:04<00:17,  4.35it/s]\u001b[A\n",
      " 23%|                                | 23/100 [00:05<00:17,  4.36it/s]\u001b[A\n",
      " 24%|                                | 24/100 [00:05<00:17,  4.34it/s]\u001b[A\n",
      " 25%|                               | 25/100 [00:05<00:17,  4.35it/s]\u001b[A\n",
      " 26%|                               | 26/100 [00:05<00:16,  4.37it/s]\u001b[A\n",
      " 27%|                              | 27/100 [00:05<00:16,  4.37it/s]\u001b[A\n",
      " 28%|                              | 28/100 [00:06<00:16,  4.38it/s]\u001b[A\n",
      " 29%|                             | 29/100 [00:06<00:16,  4.36it/s]\u001b[A\n",
      " 30%|                             | 30/100 [00:06<00:16,  4.35it/s]\u001b[A\n",
      " 31%|                             | 31/100 [00:06<00:15,  4.35it/s]\u001b[A\n",
      " 32%|                            | 32/100 [00:07<00:15,  4.34it/s]\u001b[A\n",
      " 33%|                            | 33/100 [00:07<00:15,  4.35it/s]\u001b[A\n",
      " 34%|                           | 34/100 [00:07<00:15,  4.34it/s]\u001b[A\n",
      " 35%|                           | 35/100 [00:07<00:14,  4.36it/s]\u001b[A\n",
      " 36%|                           | 36/100 [00:08<00:14,  4.35it/s]\u001b[A\n",
      " 37%|                          | 37/100 [00:08<00:14,  4.36it/s]\u001b[A\n",
      " 38%|                          | 38/100 [00:08<00:14,  4.35it/s]\u001b[A\n",
      " 39%|                         | 39/100 [00:08<00:14,  4.34it/s]\u001b[A\n",
      " 40%|                         | 40/100 [00:08<00:13,  4.34it/s]\u001b[A\n",
      " 41%|                        | 41/100 [00:09<00:13,  4.35it/s]\u001b[A\n",
      " 42%|                        | 42/100 [00:09<00:13,  4.36it/s]\u001b[A\n",
      " 43%|                        | 43/100 [00:09<00:13,  4.36it/s]\u001b[A\n",
      " 44%|                       | 44/100 [00:09<00:12,  4.38it/s]\u001b[A\n",
      " 45%|                       | 45/100 [00:10<00:12,  4.37it/s]\u001b[A\n",
      " 46%|                      | 46/100 [00:10<00:12,  4.37it/s]\u001b[A\n",
      " 47%|                      | 47/100 [00:10<00:12,  4.38it/s]\u001b[A\n",
      " 48%|                     | 48/100 [00:10<00:11,  4.37it/s]\u001b[A\n",
      " 49%|                     | 49/100 [00:11<00:11,  4.37it/s]\u001b[A\n",
      " 50%|                     | 50/100 [00:11<00:11,  4.37it/s]\u001b[A\n",
      " 51%|                    | 51/100 [00:11<00:11,  4.36it/s]\u001b[A\n",
      " 52%|                    | 52/100 [00:11<00:10,  4.38it/s]\u001b[A\n",
      " 53%|                   | 53/100 [00:11<00:10,  4.37it/s]\u001b[A\n",
      " 54%|                   | 54/100 [00:12<00:10,  4.38it/s]\u001b[A\n",
      " 55%|                   | 55/100 [00:12<00:10,  4.37it/s]\u001b[A\n",
      " 56%|                  | 56/100 [00:12<00:10,  4.35it/s]\u001b[A\n",
      " 57%|                  | 57/100 [00:12<00:09,  4.35it/s]\u001b[A\n",
      " 58%|                 | 58/100 [00:13<00:09,  4.37it/s]\u001b[A\n",
      " 59%|                 | 59/100 [00:13<00:09,  4.37it/s]\u001b[A\n",
      " 60%|                | 60/100 [00:13<00:09,  4.37it/s]\u001b[A\n",
      " 61%|                | 61/100 [00:13<00:08,  4.39it/s]\u001b[A\n",
      " 62%|                | 62/100 [00:13<00:08,  4.37it/s]\u001b[A\n",
      " 63%|               | 63/100 [00:14<00:08,  4.36it/s]\u001b[A\n",
      " 64%|               | 64/100 [00:14<00:08,  4.36it/s]\u001b[A\n",
      " 65%|              | 65/100 [00:14<00:08,  4.35it/s]\u001b[A\n",
      " 66%|              | 66/100 [00:14<00:07,  4.36it/s]\u001b[A\n",
      " 67%|             | 67/100 [00:15<00:07,  4.35it/s]\u001b[A\n",
      " 68%|             | 68/100 [00:15<00:07,  4.35it/s]\u001b[A\n",
      " 69%|             | 69/100 [00:15<00:07,  4.36it/s]\u001b[A\n",
      " 70%|            | 70/100 [00:15<00:06,  4.37it/s]\u001b[A\n",
      " 71%|            | 71/100 [00:16<00:06,  4.35it/s]\u001b[A\n",
      " 72%|           | 72/100 [00:16<00:06,  4.35it/s]\u001b[A\n",
      " 73%|           | 73/100 [00:16<00:06,  4.35it/s]\u001b[A\n",
      " 74%|           | 74/100 [00:16<00:05,  4.36it/s]\u001b[A\n",
      " 75%|          | 75/100 [00:16<00:05,  4.35it/s]\u001b[A\n",
      " 76%|          | 76/100 [00:17<00:05,  4.37it/s]\u001b[A\n",
      " 77%|         | 77/100 [00:17<00:05,  4.34it/s]\u001b[A\n",
      " 78%|         | 78/100 [00:17<00:05,  4.34it/s]\u001b[A\n",
      " 79%|        | 79/100 [00:17<00:04,  4.34it/s]\u001b[A\n",
      " 80%|        | 80/100 [00:18<00:04,  4.34it/s]\u001b[A\n",
      " 81%|        | 81/100 [00:18<00:04,  4.35it/s]\u001b[A\n",
      " 82%|       | 82/100 [00:18<00:04,  4.35it/s]\u001b[A\n",
      " 83%|       | 83/100 [00:18<00:03,  4.35it/s]\u001b[A\n",
      " 84%|      | 84/100 [00:19<00:03,  4.34it/s]\u001b[A\n",
      " 85%|      | 85/100 [00:19<00:03,  4.36it/s]\u001b[A\n",
      " 86%|      | 86/100 [00:19<00:03,  4.38it/s]\u001b[A\n",
      " 87%|     | 87/100 [00:19<00:02,  4.38it/s]\u001b[A\n",
      " 88%|     | 88/100 [00:19<00:02,  4.35it/s]\u001b[A\n",
      " 89%|    | 89/100 [00:20<00:02,  4.36it/s]\u001b[A\n",
      " 90%|    | 90/100 [00:20<00:02,  4.34it/s]\u001b[A\n",
      " 91%|   | 91/100 [00:20<00:02,  4.36it/s]\u001b[A\n",
      " 92%|   | 92/100 [00:20<00:01,  4.36it/s]\u001b[A\n",
      " 93%|   | 93/100 [00:21<00:01,  4.36it/s]\u001b[A\n",
      " 94%|  | 94/100 [00:21<00:01,  4.35it/s]\u001b[A\n",
      " 95%|  | 95/100 [00:21<00:01,  4.36it/s]\u001b[A\n",
      " 96%| | 96/100 [00:21<00:00,  4.36it/s]\u001b[A\n",
      " 97%| | 97/100 [00:22<00:00,  4.37it/s]\u001b[A\n",
      " 98%|| 98/100 [00:22<00:00,  4.38it/s]\u001b[A\n",
      " 99%|| 99/100 [00:22<00:00,  4.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.4205589294433594, 'eval_runtime': 22.9471, 'eval_samples_per_second': 8.716, 'eval_steps_per_second': 4.358, 'epoch': 1.92}\n",
      " 64%|              | 600/936 [58:11<31:06,  5.55s/it]\n",
      "100%|| 100/100 [00:22<00:00,  4.39it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3984] 2025-05-09 00:15:21,741 >> Saving model checkpoint to /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-600\n",
      "[INFO|configuration_utils.py:693] 2025-05-09 00:15:21,910 >> loading configuration file config.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
      "[INFO|configuration_utils.py:765] 2025-05-09 00:15:21,911 >> Model config Qwen3Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-05-09 00:15:22,274 >> tokenizer config file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-05-09 00:15:22,275 >> Special tokens file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-600/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-05-09 00:15:23,264 >> tokenizer config file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-05-09 00:15:23,265 >> Special tokens file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/special_tokens_map.json\n",
      "[INFO|trainer.py:4083] 2025-05-09 00:15:23,459 >> Deleting older checkpoint [/kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-200] due to args.save_total_limit\n",
      "{'loss': 0.4305, 'grad_norm': 0.39568260312080383, 'learning_rate': 2.6030108474997854e-05, 'epoch': 2.08}\n",
      "{'loss': 0.4095, 'grad_norm': 0.5491315126419067, 'learning_rate': 1.8307382788172876e-05, 'epoch': 2.24}\n",
      " 75%|         | 700/936 [1:07:26<21:50,  5.55s/it][INFO|trainer.py:4307] 2025-05-09 00:24:36,979 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-05-09 00:24:36,980 >>   Num examples = 200\n",
      "[INFO|trainer.py:4312] 2025-05-09 00:24:36,980 >>   Batch size = 1\n",
      "\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|                                          | 2/100 [00:00<00:11,  8.76it/s]\u001b[A\n",
      "  3%|                                         | 3/100 [00:00<00:15,  6.15it/s]\u001b[A\n",
      "  4%|                                         | 4/100 [00:00<00:17,  5.34it/s]\u001b[A\n",
      "  5%|                                        | 5/100 [00:00<00:19,  4.93it/s]\u001b[A\n",
      "  6%|                                        | 6/100 [00:01<00:19,  4.73it/s]\u001b[A\n",
      "  7%|                                        | 7/100 [00:01<00:20,  4.60it/s]\u001b[A\n",
      "  8%|                                       | 8/100 [00:01<00:20,  4.52it/s]\u001b[A\n",
      "  9%|                                       | 9/100 [00:01<00:20,  4.47it/s]\u001b[A\n",
      " 10%|                                     | 10/100 [00:02<00:20,  4.41it/s]\u001b[A\n",
      " 11%|                                     | 11/100 [00:02<00:20,  4.39it/s]\u001b[A\n",
      " 12%|                                     | 12/100 [00:02<00:20,  4.39it/s]\u001b[A\n",
      " 13%|                                    | 13/100 [00:02<00:19,  4.38it/s]\u001b[A\n",
      " 14%|                                    | 14/100 [00:02<00:19,  4.36it/s]\u001b[A\n",
      " 15%|                                   | 15/100 [00:03<00:19,  4.36it/s]\u001b[A\n",
      " 16%|                                   | 16/100 [00:03<00:19,  4.36it/s]\u001b[A\n",
      " 17%|                                  | 17/100 [00:03<00:19,  4.35it/s]\u001b[A\n",
      " 18%|                                  | 18/100 [00:03<00:18,  4.36it/s]\u001b[A\n",
      " 19%|                                  | 19/100 [00:04<00:18,  4.36it/s]\u001b[A\n",
      " 20%|                                 | 20/100 [00:04<00:18,  4.37it/s]\u001b[A\n",
      " 21%|                                 | 21/100 [00:04<00:18,  4.35it/s]\u001b[A\n",
      " 22%|                                | 22/100 [00:04<00:17,  4.35it/s]\u001b[A\n",
      " 23%|                                | 23/100 [00:05<00:17,  4.37it/s]\u001b[A\n",
      " 24%|                                | 24/100 [00:05<00:17,  4.38it/s]\u001b[A\n",
      " 25%|                               | 25/100 [00:05<00:17,  4.36it/s]\u001b[A\n",
      " 26%|                               | 26/100 [00:05<00:16,  4.36it/s]\u001b[A\n",
      " 27%|                              | 27/100 [00:05<00:16,  4.34it/s]\u001b[A\n",
      " 28%|                              | 28/100 [00:06<00:16,  4.33it/s]\u001b[A\n",
      " 29%|                             | 29/100 [00:06<00:16,  4.36it/s]\u001b[A\n",
      " 30%|                             | 30/100 [00:06<00:16,  4.37it/s]\u001b[A\n",
      " 31%|                             | 31/100 [00:06<00:15,  4.36it/s]\u001b[A\n",
      " 32%|                            | 32/100 [00:07<00:15,  4.35it/s]\u001b[A\n",
      " 33%|                            | 33/100 [00:07<00:15,  4.35it/s]\u001b[A\n",
      " 34%|                           | 34/100 [00:07<00:15,  4.36it/s]\u001b[A\n",
      " 35%|                           | 35/100 [00:07<00:14,  4.35it/s]\u001b[A\n",
      " 36%|                           | 36/100 [00:08<00:14,  4.36it/s]\u001b[A\n",
      " 37%|                          | 37/100 [00:08<00:14,  4.36it/s]\u001b[A\n",
      " 38%|                          | 38/100 [00:08<00:14,  4.38it/s]\u001b[A\n",
      " 39%|                         | 39/100 [00:08<00:13,  4.37it/s]\u001b[A\n",
      " 40%|                         | 40/100 [00:08<00:13,  4.36it/s]\u001b[A\n",
      " 41%|                        | 41/100 [00:09<00:13,  4.36it/s]\u001b[A\n",
      " 42%|                        | 42/100 [00:09<00:13,  4.35it/s]\u001b[A\n",
      " 43%|                        | 43/100 [00:09<00:13,  4.36it/s]\u001b[A\n",
      " 44%|                       | 44/100 [00:09<00:12,  4.37it/s]\u001b[A\n",
      " 45%|                       | 45/100 [00:10<00:12,  4.36it/s]\u001b[A\n",
      " 46%|                      | 46/100 [00:10<00:12,  4.36it/s]\u001b[A\n",
      " 47%|                      | 47/100 [00:10<00:12,  4.38it/s]\u001b[A\n",
      " 48%|                     | 48/100 [00:10<00:11,  4.36it/s]\u001b[A\n",
      " 49%|                     | 49/100 [00:11<00:11,  4.37it/s]\u001b[A\n",
      " 50%|                     | 50/100 [00:11<00:11,  4.37it/s]\u001b[A\n",
      " 51%|                    | 51/100 [00:11<00:11,  4.36it/s]\u001b[A\n",
      " 52%|                    | 52/100 [00:11<00:11,  4.36it/s]\u001b[A\n",
      " 53%|                   | 53/100 [00:11<00:10,  4.36it/s]\u001b[A\n",
      " 54%|                   | 54/100 [00:12<00:10,  4.36it/s]\u001b[A\n",
      " 55%|                   | 55/100 [00:12<00:10,  4.34it/s]\u001b[A\n",
      " 56%|                  | 56/100 [00:12<00:10,  4.33it/s]\u001b[A\n",
      " 57%|                  | 57/100 [00:12<00:09,  4.34it/s]\u001b[A\n",
      " 58%|                 | 58/100 [00:13<00:09,  4.38it/s]\u001b[A\n",
      " 59%|                 | 59/100 [00:13<00:09,  4.36it/s]\u001b[A\n",
      " 60%|                | 60/100 [00:13<00:09,  4.36it/s]\u001b[A\n",
      " 61%|                | 61/100 [00:13<00:08,  4.38it/s]\u001b[A\n",
      " 62%|                | 62/100 [00:13<00:08,  4.38it/s]\u001b[A\n",
      " 63%|               | 63/100 [00:14<00:08,  4.35it/s]\u001b[A\n",
      " 64%|               | 64/100 [00:14<00:08,  4.34it/s]\u001b[A\n",
      " 65%|              | 65/100 [00:14<00:08,  4.33it/s]\u001b[A\n",
      " 66%|              | 66/100 [00:14<00:07,  4.32it/s]\u001b[A\n",
      " 67%|             | 67/100 [00:15<00:07,  4.32it/s]\u001b[A\n",
      " 68%|             | 68/100 [00:15<00:07,  4.34it/s]\u001b[A\n",
      " 69%|             | 69/100 [00:15<00:07,  4.33it/s]\u001b[A\n",
      " 70%|            | 70/100 [00:15<00:06,  4.35it/s]\u001b[A\n",
      " 71%|            | 71/100 [00:16<00:06,  4.35it/s]\u001b[A\n",
      " 72%|           | 72/100 [00:16<00:06,  4.35it/s]\u001b[A\n",
      " 73%|           | 73/100 [00:16<00:06,  4.35it/s]\u001b[A\n",
      " 74%|           | 74/100 [00:16<00:05,  4.35it/s]\u001b[A\n",
      " 75%|          | 75/100 [00:16<00:05,  4.35it/s]\u001b[A\n",
      " 76%|          | 76/100 [00:17<00:05,  4.36it/s]\u001b[A\n",
      " 77%|         | 77/100 [00:17<00:05,  4.36it/s]\u001b[A\n",
      " 78%|         | 78/100 [00:17<00:05,  4.34it/s]\u001b[A\n",
      " 79%|        | 79/100 [00:17<00:04,  4.33it/s]\u001b[A\n",
      " 80%|        | 80/100 [00:18<00:04,  4.33it/s]\u001b[A\n",
      " 81%|        | 81/100 [00:18<00:04,  4.35it/s]\u001b[A\n",
      " 82%|       | 82/100 [00:18<00:04,  4.35it/s]\u001b[A\n",
      " 83%|       | 83/100 [00:18<00:03,  4.34it/s]\u001b[A\n",
      " 84%|      | 84/100 [00:19<00:03,  4.33it/s]\u001b[A\n",
      " 85%|      | 85/100 [00:19<00:03,  4.34it/s]\u001b[A\n",
      " 86%|      | 86/100 [00:19<00:03,  4.35it/s]\u001b[A\n",
      " 87%|     | 87/100 [00:19<00:02,  4.34it/s]\u001b[A\n",
      " 88%|     | 88/100 [00:19<00:02,  4.35it/s]\u001b[A\n",
      " 89%|    | 89/100 [00:20<00:02,  4.35it/s]\u001b[A\n",
      " 90%|    | 90/100 [00:20<00:02,  4.35it/s]\u001b[A\n",
      " 91%|   | 91/100 [00:20<00:02,  4.34it/s]\u001b[A\n",
      " 92%|   | 92/100 [00:20<00:01,  4.35it/s]\u001b[A\n",
      " 93%|   | 93/100 [00:21<00:01,  4.35it/s]\u001b[A\n",
      " 94%|  | 94/100 [00:21<00:01,  4.35it/s]\u001b[A\n",
      " 95%|  | 95/100 [00:21<00:01,  4.34it/s]\u001b[A\n",
      " 96%| | 96/100 [00:21<00:00,  4.34it/s]\u001b[A\n",
      " 97%| | 97/100 [00:22<00:00,  4.34it/s]\u001b[A\n",
      " 98%|| 98/100 [00:22<00:00,  4.36it/s]\u001b[A\n",
      " 99%|| 99/100 [00:22<00:00,  4.36it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.42073535919189453, 'eval_runtime': 22.9712, 'eval_samples_per_second': 8.707, 'eval_steps_per_second': 4.353, 'epoch': 2.24}\n",
      " 75%|         | 700/936 [1:07:49<21:50,  5.55s/it]\n",
      "100%|| 100/100 [00:22<00:00,  4.38it/s]\u001b[A\n",
      "{'loss': 0.4012, 'grad_norm': 0.7001336812973022, 'learning_rate': 1.1684457192655206e-05, 'epoch': 2.4}\n",
      "{'loss': 0.4105, 'grad_norm': 0.5802578926086426, 'learning_rate': 6.3911610561486366e-06, 'epoch': 2.56}\n",
      " 85%|     | 800/936 [1:17:06<12:36,  5.56s/it][INFO|trainer.py:4307] 2025-05-09 00:34:16,750 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-05-09 00:34:16,750 >>   Num examples = 200\n",
      "[INFO|trainer.py:4312] 2025-05-09 00:34:16,751 >>   Batch size = 1\n",
      "\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|                                          | 2/100 [00:00<00:11,  8.78it/s]\u001b[A\n",
      "  3%|                                         | 3/100 [00:00<00:15,  6.19it/s]\u001b[A\n",
      "  4%|                                         | 4/100 [00:00<00:18,  5.32it/s]\u001b[A\n",
      "  5%|                                        | 5/100 [00:00<00:19,  4.93it/s]\u001b[A\n",
      "  6%|                                        | 6/100 [00:01<00:19,  4.76it/s]\u001b[A\n",
      "  7%|                                        | 7/100 [00:01<00:20,  4.62it/s]\u001b[A\n",
      "  8%|                                       | 8/100 [00:01<00:20,  4.52it/s]\u001b[A\n",
      "  9%|                                       | 9/100 [00:01<00:20,  4.47it/s]\u001b[A\n",
      " 10%|                                     | 10/100 [00:02<00:20,  4.42it/s]\u001b[A\n",
      " 11%|                                     | 11/100 [00:02<00:20,  4.40it/s]\u001b[A\n",
      " 12%|                                     | 12/100 [00:02<00:20,  4.37it/s]\u001b[A\n",
      " 13%|                                    | 13/100 [00:02<00:19,  4.38it/s]\u001b[A\n",
      " 14%|                                    | 14/100 [00:02<00:19,  4.35it/s]\u001b[A\n",
      " 15%|                                   | 15/100 [00:03<00:19,  4.35it/s]\u001b[A\n",
      " 16%|                                   | 16/100 [00:03<00:19,  4.35it/s]\u001b[A\n",
      " 17%|                                  | 17/100 [00:03<00:19,  4.35it/s]\u001b[A\n",
      " 18%|                                  | 18/100 [00:03<00:18,  4.35it/s]\u001b[A\n",
      " 19%|                                  | 19/100 [00:04<00:18,  4.35it/s]\u001b[A\n",
      " 20%|                                 | 20/100 [00:04<00:18,  4.35it/s]\u001b[A\n",
      " 21%|                                 | 21/100 [00:04<00:18,  4.35it/s]\u001b[A\n",
      " 22%|                                | 22/100 [00:04<00:17,  4.35it/s]\u001b[A\n",
      " 23%|                                | 23/100 [00:05<00:17,  4.36it/s]\u001b[A\n",
      " 24%|                                | 24/100 [00:05<00:17,  4.37it/s]\u001b[A\n",
      " 25%|                               | 25/100 [00:05<00:17,  4.36it/s]\u001b[A\n",
      " 26%|                               | 26/100 [00:05<00:16,  4.35it/s]\u001b[A\n",
      " 27%|                              | 27/100 [00:05<00:16,  4.36it/s]\u001b[A\n",
      " 28%|                              | 28/100 [00:06<00:16,  4.37it/s]\u001b[A\n",
      " 29%|                             | 29/100 [00:06<00:16,  4.38it/s]\u001b[A\n",
      " 30%|                             | 30/100 [00:06<00:15,  4.38it/s]\u001b[A\n",
      " 31%|                             | 31/100 [00:06<00:15,  4.37it/s]\u001b[A\n",
      " 32%|                            | 32/100 [00:07<00:15,  4.35it/s]\u001b[A\n",
      " 33%|                            | 33/100 [00:07<00:15,  4.36it/s]\u001b[A\n",
      " 34%|                           | 34/100 [00:07<00:15,  4.35it/s]\u001b[A\n",
      " 35%|                           | 35/100 [00:07<00:14,  4.35it/s]\u001b[A\n",
      " 36%|                           | 36/100 [00:08<00:14,  4.35it/s]\u001b[A\n",
      " 37%|                          | 37/100 [00:08<00:14,  4.35it/s]\u001b[A\n",
      " 38%|                          | 38/100 [00:08<00:14,  4.35it/s]\u001b[A\n",
      " 39%|                         | 39/100 [00:08<00:13,  4.37it/s]\u001b[A\n",
      " 40%|                         | 40/100 [00:08<00:13,  4.36it/s]\u001b[A\n",
      " 41%|                        | 41/100 [00:09<00:13,  4.36it/s]\u001b[A\n",
      " 42%|                        | 42/100 [00:09<00:13,  4.37it/s]\u001b[A\n",
      " 43%|                        | 43/100 [00:09<00:13,  4.36it/s]\u001b[A\n",
      " 44%|                       | 44/100 [00:09<00:12,  4.38it/s]\u001b[A\n",
      " 45%|                       | 45/100 [00:10<00:12,  4.37it/s]\u001b[A\n",
      " 46%|                      | 46/100 [00:10<00:12,  4.38it/s]\u001b[A\n",
      " 47%|                      | 47/100 [00:10<00:12,  4.38it/s]\u001b[A\n",
      " 48%|                     | 48/100 [00:10<00:11,  4.38it/s]\u001b[A\n",
      " 49%|                     | 49/100 [00:11<00:11,  4.37it/s]\u001b[A\n",
      " 50%|                     | 50/100 [00:11<00:11,  4.35it/s]\u001b[A\n",
      " 51%|                    | 51/100 [00:11<00:11,  4.34it/s]\u001b[A\n",
      " 52%|                    | 52/100 [00:11<00:11,  4.33it/s]\u001b[A\n",
      " 53%|                   | 53/100 [00:11<00:10,  4.35it/s]\u001b[A\n",
      " 54%|                   | 54/100 [00:12<00:10,  4.36it/s]\u001b[A\n",
      " 55%|                   | 55/100 [00:12<00:10,  4.34it/s]\u001b[A\n",
      " 56%|                  | 56/100 [00:12<00:10,  4.34it/s]\u001b[A\n",
      " 57%|                  | 57/100 [00:12<00:09,  4.34it/s]\u001b[A\n",
      " 58%|                 | 58/100 [00:13<00:09,  4.37it/s]\u001b[A\n",
      " 59%|                 | 59/100 [00:13<00:09,  4.38it/s]\u001b[A\n",
      " 60%|                | 60/100 [00:13<00:09,  4.36it/s]\u001b[A\n",
      " 61%|                | 61/100 [00:13<00:08,  4.37it/s]\u001b[A\n",
      " 62%|                | 62/100 [00:14<00:08,  4.35it/s]\u001b[A\n",
      " 63%|               | 63/100 [00:14<00:08,  4.35it/s]\u001b[A\n",
      " 64%|               | 64/100 [00:14<00:08,  4.35it/s]\u001b[A\n",
      " 65%|              | 65/100 [00:14<00:08,  4.36it/s]\u001b[A\n",
      " 66%|              | 66/100 [00:14<00:07,  4.34it/s]\u001b[A\n",
      " 67%|             | 67/100 [00:15<00:07,  4.35it/s]\u001b[A\n",
      " 68%|             | 68/100 [00:15<00:07,  4.36it/s]\u001b[A\n",
      " 69%|             | 69/100 [00:15<00:07,  4.36it/s]\u001b[A\n",
      " 70%|            | 70/100 [00:15<00:06,  4.36it/s]\u001b[A\n",
      " 71%|            | 71/100 [00:16<00:06,  4.36it/s]\u001b[A\n",
      " 72%|           | 72/100 [00:16<00:06,  4.37it/s]\u001b[A\n",
      " 73%|           | 73/100 [00:16<00:06,  4.38it/s]\u001b[A\n",
      " 74%|           | 74/100 [00:16<00:05,  4.38it/s]\u001b[A\n",
      " 75%|          | 75/100 [00:16<00:05,  4.36it/s]\u001b[A\n",
      " 76%|          | 76/100 [00:17<00:05,  4.37it/s]\u001b[A\n",
      " 77%|         | 77/100 [00:17<00:05,  4.35it/s]\u001b[A\n",
      " 78%|         | 78/100 [00:17<00:05,  4.34it/s]\u001b[A\n",
      " 79%|        | 79/100 [00:17<00:04,  4.34it/s]\u001b[A\n",
      " 80%|        | 80/100 [00:18<00:04,  4.34it/s]\u001b[A\n",
      " 81%|        | 81/100 [00:18<00:04,  4.37it/s]\u001b[A\n",
      " 82%|       | 82/100 [00:18<00:04,  4.36it/s]\u001b[A\n",
      " 83%|       | 83/100 [00:18<00:03,  4.35it/s]\u001b[A\n",
      " 84%|      | 84/100 [00:19<00:03,  4.35it/s]\u001b[A\n",
      " 85%|      | 85/100 [00:19<00:03,  4.36it/s]\u001b[A\n",
      " 86%|      | 86/100 [00:19<00:03,  4.36it/s]\u001b[A\n",
      " 87%|     | 87/100 [00:19<00:02,  4.35it/s]\u001b[A\n",
      " 88%|     | 88/100 [00:19<00:02,  4.36it/s]\u001b[A\n",
      " 89%|    | 89/100 [00:20<00:02,  4.36it/s]\u001b[A\n",
      " 90%|    | 90/100 [00:20<00:02,  4.35it/s]\u001b[A\n",
      " 91%|   | 91/100 [00:20<00:02,  4.34it/s]\u001b[A\n",
      " 92%|   | 92/100 [00:20<00:01,  4.36it/s]\u001b[A\n",
      " 93%|   | 93/100 [00:21<00:01,  4.37it/s]\u001b[A\n",
      " 94%|  | 94/100 [00:21<00:01,  4.33it/s]\u001b[A\n",
      " 95%|  | 95/100 [00:21<00:01,  4.36it/s]\u001b[A\n",
      " 96%| | 96/100 [00:21<00:00,  4.36it/s]\u001b[A\n",
      " 97%| | 97/100 [00:22<00:00,  4.34it/s]\u001b[A\n",
      " 98%|| 98/100 [00:22<00:00,  4.37it/s]\u001b[A\n",
      " 99%|| 99/100 [00:22<00:00,  4.36it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.41989433765411377, 'eval_runtime': 22.9435, 'eval_samples_per_second': 8.717, 'eval_steps_per_second': 4.359, 'epoch': 2.56}\n",
      " 85%|     | 800/936 [1:17:29<12:36,  5.56s/it]\n",
      "100%|| 100/100 [00:22<00:00,  4.37it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3984] 2025-05-09 00:34:39,699 >> Saving model checkpoint to /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-800\n",
      "[INFO|configuration_utils.py:693] 2025-05-09 00:34:39,967 >> loading configuration file config.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
      "[INFO|configuration_utils.py:765] 2025-05-09 00:34:39,969 >> Model config Qwen3Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-05-09 00:34:40,366 >> tokenizer config file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-05-09 00:34:40,367 >> Special tokens file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-800/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-05-09 00:34:41,624 >> tokenizer config file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-05-09 00:34:41,625 >> Special tokens file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/special_tokens_map.json\n",
      "[INFO|trainer.py:4083] 2025-05-09 00:34:41,838 >> Deleting older checkpoint [/kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-400] due to args.save_total_limit\n",
      "{'loss': 0.4099, 'grad_norm': 0.658608078956604, 'learning_rate': 2.611182823672931e-06, 'epoch': 2.72}\n",
      "{'loss': 0.4238, 'grad_norm': 0.6541095972061157, 'learning_rate': 4.7569564440128057e-07, 'epoch': 2.88}\n",
      " 96%| | 900/936 [1:26:48<03:20,  5.58s/it][INFO|trainer.py:4307] 2025-05-09 00:43:59,045 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-05-09 00:43:59,045 >>   Num examples = 200\n",
      "[INFO|trainer.py:4312] 2025-05-09 00:43:59,045 >>   Batch size = 1\n",
      "\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|                                          | 2/100 [00:00<00:11,  8.71it/s]\u001b[A\n",
      "  3%|                                         | 3/100 [00:00<00:15,  6.12it/s]\u001b[A\n",
      "  4%|                                         | 4/100 [00:00<00:18,  5.29it/s]\u001b[A\n",
      "  5%|                                        | 5/100 [00:00<00:19,  4.92it/s]\u001b[A\n",
      "  6%|                                        | 6/100 [00:01<00:19,  4.72it/s]\u001b[A\n",
      "  7%|                                        | 7/100 [00:01<00:20,  4.60it/s]\u001b[A\n",
      "  8%|                                       | 8/100 [00:01<00:20,  4.50it/s]\u001b[A\n",
      "  9%|                                       | 9/100 [00:01<00:20,  4.44it/s]\u001b[A\n",
      " 10%|                                     | 10/100 [00:02<00:20,  4.39it/s]\u001b[A\n",
      " 11%|                                     | 11/100 [00:02<00:20,  4.37it/s]\u001b[A\n",
      " 12%|                                     | 12/100 [00:02<00:20,  4.38it/s]\u001b[A\n",
      " 13%|                                    | 13/100 [00:02<00:19,  4.38it/s]\u001b[A\n",
      " 14%|                                    | 14/100 [00:02<00:19,  4.39it/s]\u001b[A\n",
      " 15%|                                   | 15/100 [00:03<00:19,  4.37it/s]\u001b[A\n",
      " 16%|                                   | 16/100 [00:03<00:19,  4.36it/s]\u001b[A\n",
      " 17%|                                  | 17/100 [00:03<00:19,  4.35it/s]\u001b[A\n",
      " 18%|                                  | 18/100 [00:03<00:18,  4.35it/s]\u001b[A\n",
      " 19%|                                  | 19/100 [00:04<00:18,  4.36it/s]\u001b[A\n",
      " 20%|                                 | 20/100 [00:04<00:18,  4.36it/s]\u001b[A\n",
      " 21%|                                 | 21/100 [00:04<00:18,  4.33it/s]\u001b[A\n",
      " 22%|                                | 22/100 [00:04<00:17,  4.34it/s]\u001b[A\n",
      " 23%|                                | 23/100 [00:05<00:17,  4.35it/s]\u001b[A\n",
      " 24%|                                | 24/100 [00:05<00:17,  4.34it/s]\u001b[A\n",
      " 25%|                               | 25/100 [00:05<00:17,  4.35it/s]\u001b[A\n",
      " 26%|                               | 26/100 [00:05<00:17,  4.34it/s]\u001b[A\n",
      " 27%|                              | 27/100 [00:05<00:16,  4.34it/s]\u001b[A\n",
      " 28%|                              | 28/100 [00:06<00:16,  4.34it/s]\u001b[A\n",
      " 29%|                             | 29/100 [00:06<00:16,  4.35it/s]\u001b[A\n",
      " 30%|                             | 30/100 [00:06<00:16,  4.33it/s]\u001b[A\n",
      " 31%|                             | 31/100 [00:06<00:15,  4.35it/s]\u001b[A\n",
      " 32%|                            | 32/100 [00:07<00:15,  4.34it/s]\u001b[A\n",
      " 33%|                            | 33/100 [00:07<00:15,  4.34it/s]\u001b[A\n",
      " 34%|                           | 34/100 [00:07<00:15,  4.35it/s]\u001b[A\n",
      " 35%|                           | 35/100 [00:07<00:14,  4.36it/s]\u001b[A\n",
      " 36%|                           | 36/100 [00:08<00:14,  4.36it/s]\u001b[A\n",
      " 37%|                          | 37/100 [00:08<00:14,  4.36it/s]\u001b[A\n",
      " 38%|                          | 38/100 [00:08<00:14,  4.36it/s]\u001b[A\n",
      " 39%|                         | 39/100 [00:08<00:14,  4.35it/s]\u001b[A\n",
      " 40%|                         | 40/100 [00:08<00:13,  4.34it/s]\u001b[A\n",
      " 41%|                        | 41/100 [00:09<00:13,  4.34it/s]\u001b[A\n",
      " 42%|                        | 42/100 [00:09<00:13,  4.35it/s]\u001b[A\n",
      " 43%|                        | 43/100 [00:09<00:13,  4.36it/s]\u001b[A\n",
      " 44%|                       | 44/100 [00:09<00:12,  4.36it/s]\u001b[A\n",
      " 45%|                       | 45/100 [00:10<00:12,  4.35it/s]\u001b[A\n",
      " 46%|                      | 46/100 [00:10<00:12,  4.34it/s]\u001b[A\n",
      " 47%|                      | 47/100 [00:10<00:12,  4.34it/s]\u001b[A\n",
      " 48%|                     | 48/100 [00:10<00:11,  4.34it/s]\u001b[A\n",
      " 49%|                     | 49/100 [00:11<00:11,  4.34it/s]\u001b[A\n",
      " 50%|                     | 50/100 [00:11<00:11,  4.35it/s]\u001b[A\n",
      " 51%|                    | 51/100 [00:11<00:11,  4.35it/s]\u001b[A\n",
      " 52%|                    | 52/100 [00:11<00:11,  4.36it/s]\u001b[A\n",
      " 53%|                   | 53/100 [00:11<00:10,  4.35it/s]\u001b[A\n",
      " 54%|                   | 54/100 [00:12<00:10,  4.34it/s]\u001b[A\n",
      " 55%|                   | 55/100 [00:12<00:10,  4.34it/s]\u001b[A\n",
      " 56%|                  | 56/100 [00:12<00:10,  4.35it/s]\u001b[A\n",
      " 57%|                  | 57/100 [00:12<00:09,  4.35it/s]\u001b[A\n",
      " 58%|                 | 58/100 [00:13<00:09,  4.38it/s]\u001b[A\n",
      " 59%|                 | 59/100 [00:13<00:09,  4.38it/s]\u001b[A\n",
      " 60%|                | 60/100 [00:13<00:09,  4.36it/s]\u001b[A\n",
      " 61%|                | 61/100 [00:13<00:08,  4.38it/s]\u001b[A\n",
      " 62%|                | 62/100 [00:14<00:08,  4.38it/s]\u001b[A\n",
      " 63%|               | 63/100 [00:14<00:08,  4.36it/s]\u001b[A\n",
      " 64%|               | 64/100 [00:14<00:08,  4.36it/s]\u001b[A\n",
      " 65%|              | 65/100 [00:14<00:08,  4.35it/s]\u001b[A\n",
      " 66%|              | 66/100 [00:14<00:07,  4.36it/s]\u001b[A\n",
      " 67%|             | 67/100 [00:15<00:07,  4.37it/s]\u001b[A\n",
      " 68%|             | 68/100 [00:15<00:07,  4.35it/s]\u001b[A\n",
      " 69%|             | 69/100 [00:15<00:07,  4.35it/s]\u001b[A\n",
      " 70%|            | 70/100 [00:15<00:06,  4.35it/s]\u001b[A\n",
      " 71%|            | 71/100 [00:16<00:06,  4.34it/s]\u001b[A\n",
      " 72%|           | 72/100 [00:16<00:06,  4.33it/s]\u001b[A\n",
      " 73%|           | 73/100 [00:16<00:06,  4.33it/s]\u001b[A\n",
      " 74%|           | 74/100 [00:16<00:06,  4.33it/s]\u001b[A\n",
      " 75%|          | 75/100 [00:17<00:05,  4.33it/s]\u001b[A\n",
      " 76%|          | 76/100 [00:17<00:05,  4.37it/s]\u001b[A\n",
      " 77%|         | 77/100 [00:17<00:05,  4.37it/s]\u001b[A\n",
      " 78%|         | 78/100 [00:17<00:05,  4.38it/s]\u001b[A\n",
      " 79%|        | 79/100 [00:17<00:04,  4.37it/s]\u001b[A\n",
      " 80%|        | 80/100 [00:18<00:04,  4.36it/s]\u001b[A\n",
      " 81%|        | 81/100 [00:18<00:04,  4.34it/s]\u001b[A\n",
      " 82%|       | 82/100 [00:18<00:04,  4.36it/s]\u001b[A\n",
      " 83%|       | 83/100 [00:18<00:03,  4.35it/s]\u001b[A\n",
      " 84%|      | 84/100 [00:19<00:03,  4.35it/s]\u001b[A\n",
      " 85%|      | 85/100 [00:19<00:03,  4.36it/s]\u001b[A\n",
      " 86%|      | 86/100 [00:19<00:03,  4.36it/s]\u001b[A\n",
      " 87%|     | 87/100 [00:19<00:02,  4.36it/s]\u001b[A\n",
      " 88%|     | 88/100 [00:20<00:02,  4.35it/s]\u001b[A\n",
      " 89%|    | 89/100 [00:20<00:02,  4.35it/s]\u001b[A\n",
      " 90%|    | 90/100 [00:20<00:02,  4.35it/s]\u001b[A\n",
      " 91%|   | 91/100 [00:20<00:02,  4.35it/s]\u001b[A\n",
      " 92%|   | 92/100 [00:20<00:01,  4.35it/s]\u001b[A\n",
      " 93%|   | 93/100 [00:21<00:01,  4.37it/s]\u001b[A\n",
      " 94%|  | 94/100 [00:21<00:01,  4.36it/s]\u001b[A\n",
      " 95%|  | 95/100 [00:21<00:01,  4.35it/s]\u001b[A\n",
      " 96%| | 96/100 [00:21<00:00,  4.33it/s]\u001b[A\n",
      " 97%| | 97/100 [00:22<00:00,  4.33it/s]\u001b[A\n",
      " 98%|| 98/100 [00:22<00:00,  4.37it/s]\u001b[A\n",
      " 99%|| 99/100 [00:22<00:00,  4.37it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.4182172417640686, 'eval_runtime': 22.9797, 'eval_samples_per_second': 8.703, 'eval_steps_per_second': 4.352, 'epoch': 2.88}\n",
      " 96%| | 900/936 [1:27:11<03:20,  5.58s/it]\n",
      "100%|| 100/100 [00:22<00:00,  4.39it/s]\u001b[A\n",
      "100%|| 936/936 [1:30:32<00:00,  5.57s/it][INFO|trainer.py:3984] 2025-05-09 00:47:42,370 >> Saving model checkpoint to /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-936\n",
      "[INFO|configuration_utils.py:693] 2025-05-09 00:47:42,644 >> loading configuration file config.json from cache at /kaggle/working/drive/MyDrive/llm-finetuning/hf_home/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
      "[INFO|configuration_utils.py:765] 2025-05-09 00:47:42,646 >> Model config Qwen3Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-05-09 00:47:43,009 >> tokenizer config file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-936/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-05-09 00:47:43,010 >> Special tokens file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-936/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-05-09 00:47:43,975 >> tokenizer config file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-05-09 00:47:43,976 >> Special tokens file saved in /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/special_tokens_map.json\n",
      "[INFO|trainer.py:4083] 2025-05-09 00:47:44,175 >> Deleting older checkpoint [/kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-600] due to args.save_total_limit\n",
      "[INFO|trainer.py:2681] 2025-05-09 00:47:44,319 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2910] 2025-05-09 00:47:44,320 >> Loading best model from /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-800 (score: 0.4182172417640686).\n",
      "^C\n",
      "W0509 01:25:33.863000 2181 torch/distributed/elastic/agent/server/api.py:704] Received 2 death signal, shutting down workers\n",
      "W0509 01:25:33.864000 2181 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2183 closing signal SIGINT\n",
      "W0509 01:25:33.864000 2181 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2184 closing signal SIGINT\n"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli train /kaggle/working/LLaMA-Factory/examples/train_lora/real_estate_qwen3_lora.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T01:43:27.200762Z",
     "iopub.status.busy": "2025-05-09T01:43:27.200090Z",
     "iopub.status.idle": "2025-05-09T01:43:27.358286Z",
     "shell.execute_reply": "2025-05-09T01:43:27.357568Z",
     "shell.execute_reply.started": "2025-05-09T01:43:27.200729Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adapter_config.json\t   README.md\t\t    tokenizer_config.json\n",
      "adapter_model.safetensors  rng_state_0.pth\t    tokenizer.json\n",
      "added_tokens.json\t   rng_state_1.pth\t    trainer_state.json\n",
      "merges.txt\t\t   scheduler.pt\t\t    training_args.bin\n",
      "optimizer.pt\t\t   special_tokens_map.json  vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gk-WO3ebi5k"
   },
   "source": [
    "<div style=\"\n",
    "    border: 1px solid #dfe1e5;\n",
    "    border-radius: 8px;\n",
    "    padding: 15px;\n",
    "    margin: 10px 0;\n",
    "    background-color: var(--colab-primary-surface-color, #f8f9fa);\n",
    "    color: var(--colab-primary-text-color, #202124);\n",
    "    box-shadow: 0 1px 2px 0 rgba(60,64,67,0.3), 0 1px 3px 1px rgba(60,64,67,0.15);\n",
    "\">\n",
    "\n",
    "---\n",
    "### **Summary**\n",
    "---\n",
    "\n",
    "> Best model is **`checkpoint-800`** (score: 0.4182172417640686)\n",
    "\n",
    "* **Model:** `Qwen/Qwen3-0.6B`\n",
    "* **Device:** use Kaggle with 2xT4 GPU\n",
    "* **Precision:** `torch.bfloat16`\n",
    "* **Model Configuration Highlights**:\n",
    "   * Hidden size: `1536`\n",
    "   * Layers: `28`\n",
    "   * Heads: `12`\n",
    "   * Max Position Embeddings: `32,768`\n",
    "   * Attention Dropout: `0.0`\n",
    "   * Torch Dtype: `bfloat16`\n",
    "   * Model Type: `qwen3`\n",
    "\n",
    "* **Dataset**: I took a small sample (5000/200 for train/val) due to a shortage of resources and time.\n",
    "   * Given Training set: `2,201,006 examples` loaded from `llm_train_data.jsonl`\n",
    "   * Given Validation set: `22.2k examples` from `llm_val_data.jsonl`\n",
    "\n",
    "* **Training**:\n",
    "   * Training examples = 5000\n",
    "   * Num Epochs = 3\n",
    "   * Total optimization steps = 936\n",
    "   * Each 100 steps, do an evaluation on 200 validation sample.\n",
    "   * **Trainable params**: 40,370,176 || all params: 636,420,096 || trainable%: 6.3433\n",
    "\n",
    "* **Monitoring with Wandb**\n",
    "  *   Data is saved locally in /kaggle/working/LLaMA-Factory/wandb/run-20250508_231709-vbdtlxqp\n",
    "  *  View project at https://wandb.ai/debi2023-group-3/llamafactory\n",
    "  *  View run at https://wandb.ai/debi2023-group-3/llamafactory/runs/vbdtlxqp\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsXFiHK5bi5k"
   },
   "source": [
    "### **Push the Model to Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "12802164d7844ee9b7c319e6d6d96307",
      "665404b8770a4e35a2867ea853ca04d1",
      "aa091653d7f844be9c8e2bca5d557ac3"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T01:44:23.650115Z",
     "iopub.status.busy": "2025-05-09T01:44:23.649518Z",
     "iopub.status.idle": "2025-05-09T01:44:33.072719Z",
     "shell.execute_reply": "2025-05-09T01:44:33.071928Z",
     "shell.execute_reply.started": "2025-05-09T01:44:23.650093Z"
    },
    "id": "T801oev6bi5l",
    "outputId": "b9a45778-21cd-40ef-d0e1-af6c57ddf301",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fe1d9fe77e43cfafce836c19a82884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73879d86599b4a02bb329faff38ffca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75cfefa0d0a453883dca6fafb07313f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# task_name: \"Real Estate Price Prediction\"\n",
    "# task_type: \"text-generation\"\n",
    "base_model = \"Qwen/Qwen3-0.6B\"\n",
    "adapter_path= \"heba1998/llama_factory_output\"\n",
    "# \"/kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-800\"\n",
    "\n",
    "# Load base model and merge adapter\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model)\n",
    "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "\n",
    "model = model.merge_and_unload()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJDUklKobi5l"
   },
   "source": [
    "---\n",
    "## **Model Serving**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Serving Using LlaMa-Factory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T12:10:20.548165Z",
     "iopub.status.busy": "2025-05-09T12:10:20.547751Z",
     "iopub.status.idle": "2025-05-09T12:10:20.681869Z",
     "shell.execute_reply": "2025-05-09T12:10:20.680160Z",
     "shell.execute_reply.started": "2025-05-09T12:10:20.548139Z"
    },
    "id": "_9hvuAl_MfOa",
    "outputId": "d400bc29-0972-4180-decd-3425707d98c1",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3_full_sft.yaml  llama3.yaml     real_estate_qwen3_0_6B_hf.yaml\n",
      "llama3_lora_sft.yaml  qwen2_5vl.yaml  real_estate_qwen3_0_6B_vllm.yaml\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/LLaMA-Factory/examples/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:10:21.777178Z",
     "iopub.status.busy": "2025-05-09T12:10:21.776542Z",
     "iopub.status.idle": "2025-05-09T12:10:21.902882Z",
     "shell.execute_reply": "2025-05-09T12:10:21.901697Z",
     "shell.execute_reply.started": "2025-05-09T12:10:21.777120Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name_or_path: meta-llama/Meta-Llama-3-8B-Instruct\n",
      "adapter_name_or_path: saves/llama3-8b/lora/sft\n",
      "template: llama3\n",
      "infer_backend: huggingface  # choices: [huggingface, vllm, sglang]\n",
      "trust_remote_code: true\n"
     ]
    }
   ],
   "source": [
    "!cat /kaggle/working/LLaMA-Factory/examples/inference/llama3_lora_sft.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-09T12:10:34.556618Z",
     "iopub.status.busy": "2025-05-09T12:10:34.556149Z",
     "iopub.status.idle": "2025-05-09T12:10:34.566262Z",
     "shell.execute_reply": "2025-05-09T12:10:34.564402Z",
     "shell.execute_reply.started": "2025-05-09T12:10:34.556571Z"
    },
    "id": "1gDe19CiMWvL",
    "outputId": "1f4ca820-04c5-4186-bb75-33148168c2da",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/LLaMA-Factory/examples/inference/real_estate_qwen3_0_6B_hf.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/LLaMA-Factory/examples/inference/real_estate_qwen3_0_6B_hf.yaml\n",
    "\n",
    "model_name_or_path: Qwen/Qwen3-0.6B\n",
    "adapter_name_or_path: /kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-800\n",
    "template: qwen3\n",
    "finetuning_type: lora\n",
    "infer_backend: huggingface\n",
    "trust_remote_code: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T01:56:53.628834Z",
     "iopub.status.busy": "2025-05-09T01:56:53.628540Z",
     "iopub.status.idle": "2025-05-09T01:57:09.278986Z",
     "shell.execute_reply": "2025-05-09T01:57:09.278242Z",
     "shell.execute_reply.started": "2025-05-09T01:56:53.628814Z"
    },
    "id": "hVt0loe6L2OD",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746755819.373180    2901 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746755819.380552    2901 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Unknown command: infer.\n",
      "----------------------------------------------------------------------\n",
      "| Usage:                                                             |\n",
      "|   llamafactory-cli api -h: launch an OpenAI-style API server       |\n",
      "|   llamafactory-cli chat -h: launch a chat interface in CLI         |\n",
      "|   llamafactory-cli eval -h: evaluate models                        |\n",
      "|   llamafactory-cli export -h: merge LoRA adapters and export model |\n",
      "|   llamafactory-cli train -h: train models                          |\n",
      "|   llamafactory-cli webchat -h: launch a chat interface in Web UI   |\n",
      "|   llamafactory-cli webui: launch LlamaBoard                        |\n",
      "|   llamafactory-cli version: show version info                      |\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli infer /kaggle/working/LLaMA-Factory/examples/inference/real_estate_qwen3_0_6B_hf.yaml --share true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T01:57:27.216971Z",
     "iopub.status.busy": "2025-05-09T01:57:27.215930Z",
     "iopub.status.idle": "2025-05-09T01:59:07.829683Z",
     "shell.execute_reply": "2025-05-09T01:59:07.828738Z",
     "shell.execute_reply.started": "2025-05-09T01:57:27.216935Z"
    },
    "id": "rJvMI_pzOBMH",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746755852.874652    2921 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746755852.881414    2921 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Visit http://ip:port for Web UI, e.g., http://127.0.0.1:7860\n",
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "^C\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli webui /kaggle/working/LLaMA-Factory/examples/inference/real_estate_qwen3_0_6B_hf.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Serving Using vLLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !rm -r /kaggle/working/vllm\n",
    "# !nvidia-smi\n",
    "# !pip cache purge\n",
    "# !pip install ninja\n",
    "# !export XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "# !export TF_CPP_MIN_LOG_LEVEL=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtkgtS6CTgck",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# virtual env\n",
    "!export UV_LINK_MODE=copy\n",
    "!uv venv vllm --python 3.12 --seed\n",
    "!source vllm/bin/activate\n",
    "!pip install --upgrade pip\n",
    "\n",
    "!uv pip install --system -qU transformers==4.48.3 datasets==3.2.0 optimum==1.24.0\n",
    "!uv pip install --system -qU vllm==0.7.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:36:36.212860Z",
     "iopub.status.busy": "2025-05-09T12:36:36.211720Z",
     "iopub.status.idle": "2025-05-09T12:36:36.219891Z",
     "shell.execute_reply": "2025-05-09T12:36:36.218871Z",
     "shell.execute_reply.started": "2025-05-09T12:36:36.212811Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu124\n",
      "CUDA available: cpu\n",
      "vLLM imported successfully\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# print(\"PyTorch version:\", torch.__version__)\n",
    "# print(\"CUDA available:\", \"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "\n",
    "# from vllm import LLM\n",
    "# print(\"vLLM imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_data(row):\n",
    "    \"\"\"Generate prompt for LLM inference\"\"\"\n",
    "    description = \"\\n\" + \"\\n\".join([\n",
    "        \"A house listing in the USA with the following details:\",\n",
    "        f\"- Status: {row['status']}\",\n",
    "        f\"- Bedroom: {row['bed']}\",\n",
    "        f\"- Bathroom: {row['bath']}\",\n",
    "        f\"- Land size: {row['acre_lot']} acres\",\n",
    "        f\"- Location: {row['city']}, {row['state']} {row['zip_code']}\",\n",
    "        f\"- House size: {row['house_size']} sqft\",\n",
    "        \"Predict the final sale price in $.\",\n",
    "        \"Response format (JSON):\",\n",
    "        json.dumps(ResponseSchema.model_json_schema(), indent=2),\n",
    "        \"Response:\"\n",
    "    ])\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:38:11.116133Z",
     "iopub.status.busy": "2025-05-09T12:38:11.115749Z",
     "iopub.status.idle": "2025-05-09T12:38:38.485949Z",
     "shell.execute_reply": "2025-05-09T12:38:38.484785Z",
     "shell.execute_reply.started": "2025-05-09T12:38:11.116103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_model_id = \"Qwen/Qwen3-0.6\"\n",
    "adapter_model_id = \"/kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-800\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "!vllm serve \"{base_model_id}\" \\\n",
    "              --dtype=half \\\n",
    "              # --gpu-memory-utilization 0.8 \\\n",
    "              --device auto \\\n",
    "              --max_lora_rank 64 \\\n",
    "              --enable-lora \\\n",
    "              --lora-modules real-estate-qwen=\"{adapter_model_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:08:41.060051Z",
     "iopub.status.busy": "2025-05-09T12:08:41.059737Z",
     "iopub.status.idle": "2025-05-09T12:08:41.324571Z",
     "shell.execute_reply": "2025-05-09T12:08:41.322645Z",
     "shell.execute_reply.started": "2025-05-09T12:08:41.060029Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/2889127676.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m llm_response = requests.post(\"http://localhost:8000/v1/completions\", json={\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvllm_model_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"max_tokens\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"temperature\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prompt' is not defined"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "\n",
    "# vllm_model_id = \"real-estate-qwen3-lora\"\n",
    "\n",
    "# llm_response = requests.post(\"http://localhost:8000/v1/completions\", json={\n",
    "#     \"model\": vllm_model_id,\n",
    "#     \"prompt\": prompt,\n",
    "#     \"max_tokens\": 1000,\n",
    "#     \"temperature\": 0.3\n",
    "# })\n",
    "\n",
    "# llm_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:26:25.345618Z",
     "iopub.status.busy": "2025-05-09T12:26:25.345154Z",
     "iopub.status.idle": "2025-05-09T12:26:25.451197Z",
     "shell.execute_reply": "2025-05-09T12:26:25.450031Z",
     "shell.execute_reply.started": "2025-05-09T12:26:25.345589Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to infer device type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/601587199.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# \"/kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-800\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m llm = LLM(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Qwen/Qwen3-0.6\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0menable_lora\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm/utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                     )\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_overrides, mm_processor_kwargs, task, override_pooler_config, compilation_config, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# to avoid import order issues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_engine_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         self.llm_engine = self.engine_class.from_engine_args(\n\u001b[0m\u001b[1;32m    243\u001b[0m             engine_args, usage_context=UsageContext.LLM_CLASS)\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm/engine/llm_engine.py\u001b[0m in \u001b[0;36mfrom_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;34m\"\"\"Creates an LLM engine from the engine arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;31m# Create the engine configs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0mengine_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_engine_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musage_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m         \u001b[0mexecutor_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_executor_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;31m# Create the LLM engine.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm/engine/arg_utils.py\u001b[0m in \u001b[0;36mcreate_engine_config\u001b[0;34m(self, usage_context)\u001b[0m\n\u001b[1;32m   1072\u001b[0m             f\", but got {self.cpu_offload_gb}\")\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m         \u001b[0mdevice_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeviceConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm/config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m   1624\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_platform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to infer device type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0;31m# Device type is assigned explicitly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to infer device type"
     ]
    }
   ],
   "source": [
    "# from vllm import LLM, SamplingParams\n",
    "# from vllm.lora.request import LoRARequest\n",
    "\n",
    "# adaptor_path = \"/kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-800\"\n",
    "# # \"heba1998/llama_factory_output/last-checkpoint\"\n",
    "# # \"/kaggle/working/drive/MyDrive/llm-finetuning/llama_factory_output/checkpoint-800\"\n",
    "\n",
    "# llm = LLM(\n",
    "#     model=\"Qwen/Qwen3-0.6\", \n",
    "#     enable_lora=True,\n",
    "#     lora_modules=[{\n",
    "#     \"lora_name\": \"real_estate_qwen3\",\n",
    "#     \"lora_path\": adaptor_path,\n",
    "#     \"lora_scope\": \"all\"\n",
    "#     }]\n",
    "#  )\n",
    "# sampling_params = SamplingParams(temperature=0.7,top_p=0.9)\n",
    "# lora_request = LoRARequest(\"real_estate_qwen3\", 1, adaptor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhzrmhPJTpxh"
   },
   "outputs": [],
   "source": [
    "# from typing import Dict\n",
    "# import json_repair\n",
    "\n",
    "# def predict_price(prompt):\n",
    "#   \"\"\"Predict price using vLLM\"\"\"\n",
    "#     if tabular:\n",
    "#         prompt = translate_data(prompt)\n",
    "    \n",
    "#     outputs = llm.generate([prompt], \n",
    "#                          sampling_params, \n",
    "#                          lora_request=real_estate_adaptor)\n",
    "#     response_dict = json_repair.loads(outputs[0].outputs[0].text)\n",
    "#     validated = ResponseSchema(**response_dict)\n",
    "#     price = validated.model_dump()[\"estimated_house_price\"] if validated else 0\n",
    "    \n",
    "#     return validated.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5blV8DiUA6y"
   },
   "outputs": [],
   "source": [
    "# import streamlit as st\n",
    "\n",
    "# st.title(\"Real Estate Price Prediction (vLLM)\")\n",
    "\n",
    "# # Input fields\n",
    "# status = st.selectbox(\"Status\", [\"For Sale\", \"Sold\", \"Pending\"])\n",
    "# bed = st.number_input(\"Bedroom\", min_value=0.0, step=1.0)\n",
    "# bath = st.number_input(\"Bathroom\", min_value=0.0, step=1.0)\n",
    "# acre_lot = st.number_input(\"Land size (acres)\", min_value=0.0, step=0.1)\n",
    "# house_size = st.number_input(\"House size (sqft)\", min_value=0.0, step=1.0)\n",
    "# city = st.text_input(\"City\")\n",
    "# state = st.text_input(\"State\")\n",
    "# zip_code = st.text_input(\"Zip code\")\n",
    "\n",
    "# features = {\n",
    "#             \"status\": status,\n",
    "#             \"bed\": bed,\n",
    "#             \"bath\": bath,\n",
    "#             \"acre_lot\": acre_lot,\n",
    "#             \"house_size\": house_size,\n",
    "#             \"city\": city,\n",
    "#             \"state\": state,\n",
    "#             \"zip_code\": zip_code\n",
    "#         }\n",
    "\n",
    "# # Predict button\n",
    "# if st.button(\"Predict price\"):\n",
    "#     with st.spinner(\"Predicting...\"):\n",
    "#         result = predict_price(features)\n",
    "#     st.json(result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7Hi0hW8Tbi5H",
    "_l-cfEqOVzuF",
    "HUyiLlkSVfnP",
    "13KHoOjC-PVh",
    "o-B1psKPpKQ9",
    "m7GkWQCm44Ne",
    "bTAas15G8piS",
    "4Q--kqVkczCv"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3202774,
     "sourceId": 7981839,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7348439,
     "sourceId": 11718898,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 238628299,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 238658297,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0343daed947f4752b166f1a6ac6b3068": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "04967a17f83b48bba671009974b3f3fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d0d3a6006c54b398672ec051e1b1192",
      "placeholder": "",
      "style": "IPY_MODEL_e3c650cfad064124bfce73af34dfa287",
      "value": "text_val_data.jsonl:100%"
     }
    },
    "04ae22956f4b4ea980bc8cfa35247597": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "098840716b3041cfb04bf817b22bf2e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b5c9971a7a74a709ba12a45e0571a9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18627bf677d74c66809645161dd508c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23fe842d1a434777809cc312a270f9e1",
      "placeholder": "",
      "style": "IPY_MODEL_b8f9278c94364df3bc733bcbcd401914",
      "value": "22233/0[00:00&lt;00:00,86244.27examples/s]"
     }
    },
    "23fe842d1a434777809cc312a270f9e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25763e3764344d4ebe8575b7a67da9f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6225dac29a5544cd8bbb26539b51c2c0",
      "placeholder": "",
      "style": "IPY_MODEL_46ac53497f044a6e83dbc2923ed8e7f3",
      "value": "Generatingvalidationsplit:"
     }
    },
    "25a4bd95d7a146a0923bde8fab986831": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2797905ed9b746ae8327a59802043da2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a544e7a9981d47d5838915637dcb58c4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9da6489ad384c32b33410058cd9b69e",
      "value": 1
     }
    },
    "33e79ae3d0c544e1a0b24fd90290a309": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_0b5c9971a7a74a709ba12a45e0571a9f",
      "placeholder": "",
      "style": "IPY_MODEL_8560fb4c5cce4f1a8f101a333df92ba3",
      "value": ""
     }
    },
    "37f1ebd4d3bd4b8db0b7c7fc14994e75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8ebdbe9fddae4051ac532e3ac3f0f9af"
      ],
      "layout": "IPY_MODEL_4559112d1244427a88b5452de06cdff8"
     }
    },
    "39d267ea88d342b18131c6fee44b94a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a8b4c0ea74c4e838300bdeca96c987e",
      "max": 1658018906,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c682ff05651045138f79176ff037b8f2",
      "value": 1658018906
     }
    },
    "3a92ea749e414c85b11461279687756f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c4fb661a8584eeebbabc0f5553b7259": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edeb5fd8f29a4420a2459b5266708331",
      "placeholder": "",
      "style": "IPY_MODEL_69688de478a94a7386f46cf346857004",
      "value": "Generatingvalidationsplit:"
     }
    },
    "3d0d3a6006c54b398672ec051e1b1192": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d699244258a48079f8195a893d6be6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55aba028f2e24dcb8b4e5dc5115d69f9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0343daed947f4752b166f1a6ac6b3068",
      "value": 1
     }
    },
    "40a912e08c1841af9b56f36cbad0b881": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41f4aa4a5a87409bbae5f9ccb563df37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c4fb661a8584eeebbabc0f5553b7259",
       "IPY_MODEL_450a0ee993b045fcaa4f1d835c99a01a",
       "IPY_MODEL_18627bf677d74c66809645161dd508c9"
      ],
      "layout": "IPY_MODEL_981c384646ee409db52bbccbff56f23b"
     }
    },
    "43c4fd4ef16844f8ae7939d51264ca5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "450a0ee993b045fcaa4f1d835c99a01a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cb3c815686f40c680d88aa1a8282fcd",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6d701af891854fd6b4f05bd1593e0df0",
      "value": 1
     }
    },
    "4559112d1244427a88b5452de06cdff8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "46ac53497f044a6e83dbc2923ed8e7f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "473be151316348fd87cf03259b5b6673": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Username:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_4f77648c920a48e09d65694bf5e9845f",
      "placeholder": "",
      "style": "IPY_MODEL_aac8fd67cf7649b2a5aa5323286d5840",
      "value": "hebamo7amed"
     }
    },
    "4c7bf3cf0ff54ef887514f359e461966": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e14a698850b84346a6cbb8de30ef212b",
      "placeholder": "",
      "style": "IPY_MODEL_d166cd8b8a6246f59905520c495f2464",
      "value": "README.md:100%"
     }
    },
    "4f77648c920a48e09d65694bf5e9845f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "511c3e8e5d7b46b8a37759b634cfeed9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55aba028f2e24dcb8b4e5dc5115d69f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "57c036f53bd943fb850c7f0d7cc3992b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a35c333e6d24f4783ecbc7e33fa96a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5a8b4c0ea74c4e838300bdeca96c987e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bb78e48096441e1bba9c1db08556a18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d4bb354a080c4abaa40089a0c964a198",
       "IPY_MODEL_3d699244258a48079f8195a893d6be6b",
       "IPY_MODEL_a65d72b3455c4d318b16418311234e16"
      ],
      "layout": "IPY_MODEL_b82d86dd23284f7bb3a8472b5492b3de"
     }
    },
    "6132ba7a78ad434f98a79aa496d56ff7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25763e3764344d4ebe8575b7a67da9f9",
       "IPY_MODEL_2797905ed9b746ae8327a59802043da2",
       "IPY_MODEL_9ade7d1143ea40c69e4e82e3900ab12e"
      ],
      "layout": "IPY_MODEL_40a912e08c1841af9b56f36cbad0b881"
     }
    },
    "6225dac29a5544cd8bbb26539b51c2c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62cf41512c404a65acef2cac0ef6314f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "632f91249df74f80b53f86aec3f46d69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "676879a090174233b4c4f00a83222159": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b26f563360dc460c8e1ff8f9f0778069",
       "IPY_MODEL_39d267ea88d342b18131c6fee44b94a3",
       "IPY_MODEL_e86db4ccf47e4af09db5a13c945d98f9"
      ],
      "layout": "IPY_MODEL_8124b64e84d84127b441f399eff526d6"
     }
    },
    "6786fc60749b44d1b2e8fd26667f001a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69688de478a94a7386f46cf346857004": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6ca9284ca9414faeb4fcb45e50ed44f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9511d32d63ab407ca4c35b8ff0f6bee5",
       "IPY_MODEL_b6e14f1678974665a2b2d21760467b80",
       "IPY_MODEL_df857533519542a9ad46fd8da47f523f"
      ],
      "layout": "IPY_MODEL_57c036f53bd943fb850c7f0d7cc3992b"
     }
    },
    "6d701af891854fd6b4f05bd1593e0df0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6db89663543942009233df993e0ab4a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775974e59f9c4f5cb650bed70c44f8f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "787e5615593140b6a2b241d3b8304934": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91fa5d7b2be543668aa18ac211b50886",
      "placeholder": "",
      "style": "IPY_MODEL_098840716b3041cfb04bf817b22bf2e6",
      "value": "31.0/31.0[00:00&lt;00:00,1.36kB/s]"
     }
    },
    "797fad3b3dfa4154adbbb111fdbbfa33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d9ee638f0da47368576d9484613d04a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "7ebeca0960c14b52b2b9a0e0aaab1928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_04967a17f83b48bba671009974b3f3fa",
       "IPY_MODEL_c1728c9511af4afdbec6f101a7b6fc27",
       "IPY_MODEL_d88c2859fc6e455886ee5761c7a52894"
      ],
      "layout": "IPY_MODEL_6db89663543942009233df993e0ab4a7"
     }
    },
    "8124b64e84d84127b441f399eff526d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8560fb4c5cce4f1a8f101a333df92ba3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e885a061f5f469d8a8b2ef490e33fb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ebdbe9fddae4051ac532e3ac3f0f9af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca171247cd934886ab1081c6d9199e0a",
      "placeholder": "",
      "style": "IPY_MODEL_797fad3b3dfa4154adbbb111fdbbfa33",
      "value": "Kaggle credentials successfully validated."
     }
    },
    "91fa5d7b2be543668aa18ac211b50886": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9394ab345edb42488f47e9cad84e84c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9b7d45df6f74a3cb0cb72ec476030c5",
      "placeholder": "",
      "style": "IPY_MODEL_3a92ea749e414c85b11461279687756f",
      "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
     }
    },
    "9511d32d63ab407ca4c35b8ff0f6bee5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afe9fb7456c54d63927839f30a82caa8",
      "placeholder": "",
      "style": "IPY_MODEL_e252bd65e8694bba8670401cf84a3136",
      "value": "Generatingtrainsplit:"
     }
    },
    "981c384646ee409db52bbccbff56f23b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ade7d1143ea40c69e4e82e3900ab12e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae6901b08a6748b1a2d3db21a5246c71",
      "placeholder": "",
      "style": "IPY_MODEL_511c3e8e5d7b46b8a37759b634cfeed9",
      "value": "200/0[00:00&lt;00:00,3726.10examples/s]"
     }
    },
    "9cb3c815686f40c680d88aa1a8282fcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "9edb9852718e4b079828cae843ff23ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9eef36cd3a2f42c5a7ec735ccaf976b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "a490e95392394ae2a8d9e6318317dd84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a544e7a9981d47d5838915637dcb58c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "a5cba89fc6cb45c1ba53b1d3d568b940": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a65d72b3455c4d318b16418311234e16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04ae22956f4b4ea980bc8cfa35247597",
      "placeholder": "",
      "style": "IPY_MODEL_d5a7b32aa85f454f8748dfe200ae61aa",
      "value": "5000/0[00:00&lt;00:00,31734.98examples/s]"
     }
    },
    "aac8fd67cf7649b2a5aa5323286d5840": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae5fe864854f4641b205bb4851c05832": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43c4fd4ef16844f8ae7939d51264ca5e",
      "placeholder": "",
      "style": "IPY_MODEL_fdac369ebf8c4df68b4419e86fd33c3b",
      "value": "\n<b>Thank You</b></center>"
     }
    },
    "ae6901b08a6748b1a2d3db21a5246c71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afe9fb7456c54d63927839f30a82caa8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b26f563360dc460c8e1ff8f9f0778069": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_775974e59f9c4f5cb650bed70c44f8f8",
      "placeholder": "",
      "style": "IPY_MODEL_ff22dc9ccc0a403599a55c456013c3cb",
      "value": "text_train_data.jsonl:100%"
     }
    },
    "b4c4f9884a93471ba4dab5210bd84099": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_62cf41512c404a65acef2cac0ef6314f",
      "style": "IPY_MODEL_9eef36cd3a2f42c5a7ec735ccaf976b1",
      "tooltip": ""
     }
    },
    "b547fd3848474319a288dd917a47aa3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6e14f1678974665a2b2d21760467b80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d9ee638f0da47368576d9484613d04a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dcce7f4bd6a244e0abdfbb69baa319a5",
      "value": 1
     }
    },
    "b82d86dd23284f7bb3a8472b5492b3de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8f9278c94364df3bc733bcbcd401914": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba654c4509674c4795bac2502012f205": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf8453d7f84d437f922360a5fae73de2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25a4bd95d7a146a0923bde8fab986831",
      "placeholder": "",
      "style": "IPY_MODEL_fa40c553329a4b92b56f4a655374c78b",
      "value": "Connecting..."
     }
    },
    "c1728c9511af4afdbec6f101a7b6fc27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba654c4509674c4795bac2502012f205",
      "max": 16702532,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5cba89fc6cb45c1ba53b1d3d568b940",
      "value": 16702532
     }
    },
    "c682ff05651045138f79176ff037b8f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c822a0a968b04614bf180f6955841907": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9b7d45df6f74a3cb0cb72ec476030c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca171247cd934886ab1081c6d9199e0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccd024d40290428383f95dc94592782b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d166cd8b8a6246f59905520c495f2464": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4bb354a080c4abaa40089a0c964a198": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6786fc60749b44d1b2e8fd26667f001a",
      "placeholder": "",
      "style": "IPY_MODEL_8e885a061f5f469d8a8b2ef490e33fb6",
      "value": "Generatingtrainsplit:"
     }
    },
    "d5a7b32aa85f454f8748dfe200ae61aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d88c2859fc6e455886ee5761c7a52894": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccd024d40290428383f95dc94592782b",
      "placeholder": "",
      "style": "IPY_MODEL_a490e95392394ae2a8d9e6318317dd84",
      "value": "16.7M/16.7M[00:03&lt;00:00,76.4MB/s]"
     }
    },
    "d952bd3306d34e4dbcff925ca819c0f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dcce7f4bd6a244e0abdfbb69baa319a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "df857533519542a9ad46fd8da47f523f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b547fd3848474319a288dd917a47aa3d",
      "placeholder": "",
      "style": "IPY_MODEL_c822a0a968b04614bf180f6955841907",
      "value": "2201006/0[00:43&lt;00:00,51235.33examples/s]"
     }
    },
    "e14a698850b84346a6cbb8de30ef212b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e252bd65e8694bba8670401cf84a3136": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3c650cfad064124bfce73af34dfa287": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e86db4ccf47e4af09db5a13c945d98f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_632f91249df74f80b53f86aec3f46d69",
      "placeholder": "",
      "style": "IPY_MODEL_d952bd3306d34e4dbcff925ca819c0f4",
      "value": "1.66G/1.66G[00:12&lt;00:00,94.3MB/s]"
     }
    },
    "ebb0423da11d4097bd0d08f195d7d008": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef9a9f38d0ef4e89aa1be0f1d5c2e553",
      "max": 31,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a35c333e6d24f4783ecbc7e33fa96a5",
      "value": 31
     }
    },
    "edeb5fd8f29a4420a2459b5266708331": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef9a9f38d0ef4e89aa1be0f1d5c2e553": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9da6489ad384c32b33410058cd9b69e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa40c553329a4b92b56f4a655374c78b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdac369ebf8c4df68b4419e86fd33c3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "feed144772414889b09faed42497067c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4c7bf3cf0ff54ef887514f359e461966",
       "IPY_MODEL_ebb0423da11d4097bd0d08f195d7d008",
       "IPY_MODEL_787e5615593140b6a2b241d3b8304934"
      ],
      "layout": "IPY_MODEL_9edb9852718e4b079828cae843ff23ea"
     }
    },
    "ff22dc9ccc0a403599a55c456013c3cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
